{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNisEngEyj+ED7g7hbVOfbA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holly-hewitt/Abnormal-Infant-Movement-Detection/blob/main/Final/Trial%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "ccTIgFEYxBu0",
        "outputId": "9acc88f2-dc09-4093-be2d-f420396d25d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import libraries\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.enable_eager_execution(tf.ConfigProto(log_device_placement=True))\n",
        "#tf.test.gpu_device_name()\n",
        "#tf.config.run_functions_eagerly(True)\n",
        "\n",
        "#!pip install optuna\n",
        "#!pip install optuna-integration\n",
        "\n",
        "import tensorflow as tf\n",
        "# Standard library imports\n",
        "import datetime\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "# Third-party imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Keras/TensorFlow imports\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D, Normalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# open accelData pickle\n",
        "with open('drive/MyDrive/Pickles/accelData.pickle', 'rb') as handle:\n",
        "    accelData = pickle.load(handle)\n",
        "\n",
        "# Remove time column from accelData Measurements\n",
        "for i in range(len(accelData['Measurements'])):\n",
        "    accelData['Measurements'][i] = accelData['Measurements'][i].iloc[:, 1:]\n",
        "\n",
        "# Necessary imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "for i in range(1):\n",
        "    K = 14\n",
        "\n",
        "    # Split some of the longer trials in half\n",
        "    numRowsAccel = [df.shape[0] for df in accelData['Measurements']]\n",
        "    sortedIndices = np.argsort(numRowsAccel)\n",
        "\n",
        "    # Get the indices of the top k dataframes\n",
        "    topKIndices = sortedIndices[-K:]\n",
        "\n",
        "    # Get the top k dataframes\n",
        "    topKDataframes = [accelData['Measurements'][i] for i in topKIndices]\n",
        "\n",
        "    # Get the top k corresponding months, IDs, labels\n",
        "    topKMonths = [accelData['Month'][i] for i in topKIndices]\n",
        "    topKCodes = [accelData['Code'][i] for i in topKIndices]\n",
        "    topKAbnormal = [accelData['Abnormal'][i] for i in topKIndices]\n",
        "    topKAIMS = [accelData['AIMS'][i] for i in topKIndices]\n",
        "    topKOptimality = [accelData['Optimality'][i] for i in topKIndices]\n",
        "\n",
        "    # Remove the dataframes from accelData\n",
        "    for i in sorted(topKIndices, reverse=True):\n",
        "        del accelData['Measurements'][i]\n",
        "        del accelData['Month'][i]\n",
        "        del accelData['Code'][i]\n",
        "        del accelData['Abnormal'][i]\n",
        "        del accelData['AIMS'][i]\n",
        "        del accelData['Optimality'][i]\n",
        "\n",
        "    # Split the top k dataframes into two and reinsert into structure\n",
        "    for i in range(len(topKDataframes)):\n",
        "        df = topKDataframes[i]\n",
        "        month = topKMonths[i]\n",
        "        code = topKCodes[i]\n",
        "        abnormal = topKAbnormal[i]\n",
        "        aims = topKAIMS[i]\n",
        "        optimality = topKOptimality[i]\n",
        "\n",
        "        first_half = df.iloc[0:df.shape[0]//2]\n",
        "        second_half = df.iloc[df.shape[0]//2:df.shape[0]]\n",
        "\n",
        "        # Append the first and second halves to accelData\n",
        "        accelData['Measurements'].append(first_half)\n",
        "        accelData['Measurements'].append(second_half)\n",
        "\n",
        "        # Append the corresponding values for month, code, abnormal, aims, and optimality\n",
        "        accelData['Month'].extend([month, month])\n",
        "        accelData['Code'].extend([code, code])\n",
        "        accelData['Abnormal'].extend([abnormal, abnormal])\n",
        "        accelData['AIMS'].extend([aims, aims])\n",
        "        accelData['Optimality'].extend([optimality, optimality])\n",
        "\n",
        "    # PLot histogram of length of trials\n",
        "    lengths = [len(accelData['Measurements'][i]) for i in range(len(accelData['Measurements']))]\n",
        "    plt.hist(lengths, bins=20)\n",
        "    plt.title(\"Length of Trials\")\n",
        "    plt.xlabel(\"Length\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "    # Memory management\n",
        "    del numRowsAccel, sortedIndices, topKIndices, topKDataframes, topKMonths, topKCodes, topKAbnormal, topKAIMS, topKOptimality, first_half, second_half, df, month, code, abnormal, aims, optimality\n",
        "\n",
        "# start making visualizations of the data.\n",
        "try:\n",
        "    i = accelData['Abnormal'].index(0.5)\n",
        "\n",
        "    del accelData['Measurements'][i], accelData['Month'][i], accelData['Code'][i], accelData['Abnormal'][i], accelData['AIMS'][i], accelData['Optimality'][i]\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "# get specific rows from dataframes in accelData Measurements\n",
        "RA_cols = ['AccXRA', 'AccYRA', 'AccZRA']\n",
        "LA_cols = ['AccXLA', 'AccYLA', 'AccZLA']\n",
        "RW_cols = ['AccXRW', 'AccYRW', 'AccZRW']\n",
        "LW_cols = ['AccXLW', 'AccYLW', 'AccZLW']\n",
        "\n",
        "\n",
        "sum_cols = ['AccSumRA', 'AccSumLA', 'AccSumRW', 'AccSumLW']\n",
        "\n",
        "#sum = [df[sum_cols] for df in accelData['Measurements']]\n",
        "\n",
        "abnormal = accelData['Abnormal']\n",
        "AIMS = accelData['AIMS']\n",
        "Optimality = accelData['Optimality']\n",
        "measurements = accelData['Measurements']\n",
        "months = accelData['Month']\n",
        "codes = accelData['Code']\n",
        "\n",
        "\n",
        "measurements_nosum_cols = ['AccXRA', 'AccYRA', 'AccZRA', 'AccXLA', 'AccYLA', 'AccZLA', 'AccXRW', 'AccYRW', 'AccZRW', 'AccXLW', 'AccYLW', 'AccZLW']\n",
        "measurements_nosum = [df[measurements_nosum_cols] for df in accelData['Measurements']]\n",
        "\n",
        "del accelData"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standardised = []\n",
        "for df in measurements_nosum:\n",
        "    scaler = StandardScaler()\n",
        "    array = scaler.fit_transform(df)\n",
        "    standardised_df = pd.DataFrame(array, columns=df.columns, index=df.index)\n",
        "    standardised.append(standardised_df)\n",
        "\n",
        "normalised = []\n",
        "for df in measurements_nosum:\n",
        "    scaler = MinMaxScaler()\n",
        "    array = scaler.fit_transform(df)  # Fit and transform the data\n",
        "    normalised_df = pd.DataFrame(array, columns=df.columns, index=df.index)  # Create a new DataFrame\n",
        "    normalised.append(normalised_df)"
      ],
      "metadata": {
        "id": "cywHcdSTyV6z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad standardised data with zeros using keras.utils.pad_sequences\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "padded_standardised = pad_sequences(standardised, padding='post', value=0)\n",
        "padded_normalised = pad_sequences(normalised, padding='post', value=0)\n"
      ],
      "metadata": {
        "id": "cG521P1Gyop_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce size of padded_standardised and padded_normalised by mean smoothing and downsampling\n",
        "\n",
        "smoothed_padded_standardised = []\n",
        "for array in padded_standardised:\n",
        "    # Convert numpy array to pandas DataFrame\n",
        "    df = pd.DataFrame(array)\n",
        "\n",
        "    # Apply mean smoothing\n",
        "    smoothed_df = df.rolling(window=10).mean()\n",
        "\n",
        "    # Fill NaN values with the original values (could consider other imputation methods as well)\n",
        "    smoothed_df = smoothed_df.fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "    # Downsampler\n",
        "    smoothed_df = smoothed_df.iloc[::10, :].reset_index(drop=True)\n",
        "\n",
        "    # Convert DataFrame back to numpy array if needed\n",
        "    smoothed_array = smoothed_df.to_numpy()\n",
        "\n",
        "    smoothed_padded_standardised.append(smoothed_array)\n",
        "\n",
        "print(smoothed_padded_standardised[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfgJhhfriF_J",
        "outputId": "c86b33d0-7951-471e-c593-1f74957c8b3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19301, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing clasification using crossfold validation\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from keras.layers import Masking, LSTM, SimpleRNN, Bidirectional, GRU\n",
        "\n",
        "# Set the mixed precision policy\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# define models\n",
        "def create_CNN_model():\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0, input_shape=(padded_standardised[0].shape)))\n",
        "    input_shape = padded_standardised[0].shape\n",
        "   # Convolutional Layer 1\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Flattening the layers\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense Layer 1\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_LSTM_model():\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0, input_shape=(padded_standardised[0].shape)))\n",
        "\n",
        "    # LSTM layer, does not return sequences to match the output shape\n",
        "    model.add(LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2,\n",
        "                   kernel_regularizer=l2(0.01)))\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_GRU_model():\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0, input_shape=(smoothed_padded_standardised[0].shape)))\n",
        "    model.add(GRU(64, input_shape=(padded_standardised[0].shape)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_RNN_model():\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(32, input_shape=(padded_standardised[0].shape)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model_with_gradient_accumulation(model, train_data, epochs=10, accumulation_steps=4):\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "    metrics = {'accuracy': tf.keras.metrics.BinaryAccuracy()}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nStart of Epoch {epoch+1}\")\n",
        "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "        # Initialize gradient accumulation variables\n",
        "        accumulated_gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n",
        "\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_data):\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = model(x_batch_train, training=True)\n",
        "                loss_value = loss_fn(y_batch_train, logits) / accumulation_steps\n",
        "\n",
        "            gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "            accumulated_gradients = [(acc_grad + grad) for acc_grad, grad in zip(accumulated_gradients, gradients)]\n",
        "\n",
        "            # Apply gradients if step is at accumulation step or last step\n",
        "            if (step + 1) % accumulation_steps == 0 or step == len(train_data) - 1:\n",
        "                optimizer.apply_gradients(zip(accumulated_gradients, model.trainable_variables))\n",
        "                # Reset accumulated gradients after update\n",
        "                accumulated_gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n",
        "\n",
        "            epoch_loss_avg.update_state(loss_value * accumulation_steps)  # Correct loss scaling\n",
        "            metrics['accuracy'].update_state(y_batch_train, logits)\n",
        "\n",
        "            if step % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Step {step}, Loss: {epoch_loss_avg.result().numpy()}, Accuracy: {metrics['accuracy'].result().numpy()}\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1} finished. Loss: {epoch_loss_avg.result().numpy()}, Accuracy: {metrics['accuracy'].result().numpy()}\")\n",
        "        metrics['accuracy'].reset_states()\n",
        "\n",
        "\n",
        "\n",
        "# Assess model performance on data\n",
        "def assess_model(train_data, model_fn, verbose=False):\n",
        "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    str_codes = [str(x) for x in codes]\n",
        "    unique_codes = np.unique(str_codes)\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    false_positive_rates = []\n",
        "    specificity_scores = []\n",
        "\n",
        "    for train_index, test_index in outer_cv.split(unique_codes):\n",
        "\n",
        "        # Update progress\n",
        "        fold += 1\n",
        "\n",
        "        # Split data into train and test\n",
        "        train_codes = unique_codes[train_index]\n",
        "        test_codes = unique_codes[test_index]\n",
        "\n",
        "        train_measurements = np.array([df for i, df in enumerate(train_data) if str_codes[i] in train_codes])\n",
        "        test_measurements = np.array([df for i, df in enumerate(train_data) if str_codes[i] in test_codes])\n",
        "\n",
        "        train_abnormal = np.array([abnormal for i, abnormal in enumerate(abnormal) if str_codes[i] in train_codes])\n",
        "        test_abnormal = np.array([abnormal for i, abnormal in enumerate(abnormal) if str_codes[i] in test_codes])\n",
        "\n",
        "        # Train the model\n",
        "        model = model_fn()\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
        "        model.fit(train_measurements, train_abnormal, epochs=10, batch_size=1, callbacks=callbacks, validation_split=0.1)\n",
        "\n",
        "        # Calculate metrics\n",
        "        predictions = model.predict(test_measurements)\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "        accuracy = accuracy_score(test_abnormal, predictions.round())\n",
        "        precision = precision_score(test_abnormal, predictions.round())\n",
        "        recall = recall_score(test_abnormal, predictions.round())\n",
        "\n",
        "        false_positives = np.logical_and(predictions > 0.5, test_abnormal == 0).sum()\n",
        "        true_negatives = np.logical_and(predictions <= 0.5, test_abnormal == 0).sum()\n",
        "        total_negatives = (test_abnormal == 0).sum()\n",
        "\n",
        "        specificity = true_negatives / (true_negatives + false_positives)\n",
        "        false_positive_rate = false_positives / (false_positives + true_negatives)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Results for fold:\", fold)\n",
        "            print(f\"Accuracy: {accuracy}, Recall: {recall}, False Positives: {false_positive_rate}, Specificity: {specificity}, Precision: {precision}.\")\n",
        "\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        false_positive_rates.append(false_positive_rate)\n",
        "        specificity_scores.append(specificity)\n",
        "\n",
        "    # find average of each score\n",
        "    avg_accuracy = np.mean(accuracy_scores)\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "    avg_false_positive_rate = np.mean(false_positive_rates)\n",
        "    avg_specificity = np.mean(specificity_scores)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Results for all folds:\")\n",
        "        print(f\"Accuracy: {avg_accuracy}, Recall: {avg_recall}, False Positive Rate: {avg_false_positive_rate}, Specificity: {avg_specificity}, Precision: {avg_precision}.\")\n",
        "\n",
        "    return avg_accuracy, avg_precision, avg_recall, avg_false_positive_rate, avg_specificity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LvwlM7PDxROn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_results = assess_model(smoothed_padded_standardised, create_GRU_model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "FPaLAJffZMQk",
        "outputId": "79727f65-af01-48c8-f997-78a7a7251048"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "116/116 [==============================] - 1344s 12s/step - loss: 0.6596 - accuracy: 0.5948 - val_loss: 0.5461 - val_accuracy: 0.8462\n",
            "Epoch 2/10\n",
            " 12/116 [==>...........................] - ETA: 20:44 - loss: 0.5475 - accuracy: 0.8333"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f6b599bce889>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGRU_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmoothed_padded_standardised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_GRU_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-d52327d7fa9d>\u001b[0m in \u001b[0;36massess_model\u001b[0;34m(train_data, model_fn, verbose)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_measurements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_abnormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_test = assess_model(padded_standardised, create_CNN_model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "ux-hGjRLaIZh",
        "outputId": "cf370ad2-0db0-443b-b03f-178afdcc5463"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "116/116 [==============================] - 12s 47ms/step - loss: 107.0005 - accuracy: 0.5431 - val_loss: 0.3460 - val_accuracy: 0.8462\n",
            "Epoch 2/10\n",
            "116/116 [==============================] - 3s 27ms/step - loss: 6.1778 - accuracy: 0.7328 - val_loss: 5.4115 - val_accuracy: 0.8462\n",
            "Epoch 3/10\n",
            "116/116 [==============================] - 3s 28ms/step - loss: 5.7655 - accuracy: 0.7414 - val_loss: 0.4681 - val_accuracy: 0.8462\n",
            "Epoch 4/10\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 1.9925 - accuracy: 0.6983 - val_loss: 0.6138 - val_accuracy: 0.8462\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-388737c9bb5d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCNN_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_CNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-51922c5e9dc7>\u001b[0m in \u001b[0;36massess_model\u001b[0;34m(model_fn, verbose)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_measurements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m           )\n\u001b[1;32m    917\u001b[0m       )\n\u001b[0;32m--> 918\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    919\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_results = assess_model(create_LSTM_model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amMWg-ybXCZN",
        "outputId": "a6db2c96-3754-4dfa-f07a-12d89a64395f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  1/116 [..............................] - ETA: 7:15:52 - loss: 0.9720 - accuracy: 0.0000e+00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_results = assess_model(create_CNN_model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id7odwA11h2R",
        "outputId": "255eca1b-492b-4e75-a526-d6c8e460d5fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "116/116 [==============================] - 6s 29ms/step - loss: 112.5667 - accuracy: 0.5431 - val_loss: 18.3750 - val_accuracy: 0.8462\n",
            "Epoch 2/10\n",
            "116/116 [==============================] - 2s 19ms/step - loss: 14.6570 - accuracy: 0.7328 - val_loss: 2.8237 - val_accuracy: 0.8462\n",
            "Epoch 3/10\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.6379 - accuracy: 0.7672 - val_loss: 3.6751 - val_accuracy: 0.8462\n",
            "Epoch 4/10\n",
            "116/116 [==============================] - 2s 18ms/step - loss: 2.6539 - accuracy: 0.7500 - val_loss: 2.9866 - val_accuracy: 0.8462\n",
            "Epoch 5/10\n",
            "116/116 [==============================] - 2s 20ms/step - loss: 0.5497 - accuracy: 0.7500 - val_loss: 2.9411 - val_accuracy: 0.8462\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Results for fold: 1\n",
            "Accuracy: 0.3870967741935484, Recall: 0.1111111111111111, False Positives: 0.16129032258064516, Specificity: 0.8387096774193549, Precision: 0.4.\n",
            "Epoch 1/10\n",
            "112/112 [==============================] - 5s 29ms/step - loss: 80.1792 - accuracy: 0.5446 - val_loss: 25.5770 - val_accuracy: 0.4615\n",
            "Epoch 2/10\n",
            "112/112 [==============================] - 2s 19ms/step - loss: 11.8218 - accuracy: 0.6250 - val_loss: 8.4147 - val_accuracy: 0.6923\n",
            "Epoch 3/10\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 3.0144 - accuracy: 0.6071 - val_loss: 9.1767 - val_accuracy: 0.6923\n",
            "Epoch 4/10\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 2.3248 - accuracy: 0.6964 - val_loss: 9.2568 - val_accuracy: 0.6923\n",
            "Epoch 5/10\n",
            "112/112 [==============================] - 2s 19ms/step - loss: 2.6188 - accuracy: 0.6518 - val_loss: 2.3607 - val_accuracy: 0.7692\n",
            "Epoch 6/10\n",
            "112/112 [==============================] - 2s 19ms/step - loss: 0.9420 - accuracy: 0.6250 - val_loss: 0.9416 - val_accuracy: 0.7692\n",
            "Epoch 7/10\n",
            "112/112 [==============================] - 2s 19ms/step - loss: 1.0590 - accuracy: 0.6786 - val_loss: 0.5746 - val_accuracy: 0.7692\n",
            "Epoch 8/10\n",
            "112/112 [==============================] - 2s 19ms/step - loss: 0.8317 - accuracy: 0.6786 - val_loss: 0.4841 - val_accuracy: 0.6923\n",
            "Epoch 9/10\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.4704 - accuracy: 0.6964 - val_loss: 0.4880 - val_accuracy: 0.6923\n",
            "Epoch 10/10\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.4884 - accuracy: 0.6875 - val_loss: 0.5098 - val_accuracy: 0.6923\n",
            "2/2 [==============================] - 1s 150ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for fold: 2\n",
            "Accuracy: 0.6857142857142857, Recall: 0.0, False Positives: 0.0, Specificity: 1.0, Precision: 0.0.\n",
            "Epoch 1/10\n",
            "109/109 [==============================] - 5s 28ms/step - loss: 149.1734 - accuracy: 0.5505 - val_loss: 98.4688 - val_accuracy: 0.3077\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 32.3774 - accuracy: 0.6514 - val_loss: 3.6919 - val_accuracy: 0.6154\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 1.7816 - accuracy: 0.6972 - val_loss: 0.4264 - val_accuracy: 0.6923\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 1.7007 - accuracy: 0.6881 - val_loss: 0.5829 - val_accuracy: 0.6923\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 6.9361 - accuracy: 0.7156 - val_loss: 0.4821 - val_accuracy: 0.6923\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.4805 - accuracy: 0.7156 - val_loss: 0.4997 - val_accuracy: 0.6923\n",
            "2/2 [==============================] - 1s 214ms/step\n",
            "Results for fold: 3\n",
            "Accuracy: 0.6578947368421053, Recall: 0.5, False Positives: 0.34210526315789475, Specificity: 0.6578947368421053, Precision: 0.3076923076923077.\n",
            "Epoch 1/10\n",
            "114/114 [==============================] - 5s 30ms/step - loss: 163.6926 - accuracy: 0.5175 - val_loss: 13.8340 - val_accuracy: 0.7692\n",
            "Epoch 2/10\n",
            "114/114 [==============================] - 2s 20ms/step - loss: 3.9275 - accuracy: 0.6842 - val_loss: 12.4193 - val_accuracy: 0.8462\n",
            "Epoch 3/10\n",
            "114/114 [==============================] - 2s 20ms/step - loss: 0.6211 - accuracy: 0.6930 - val_loss: 4.0365 - val_accuracy: 0.8462\n",
            "Epoch 4/10\n",
            "114/114 [==============================] - 2s 20ms/step - loss: 0.5819 - accuracy: 0.6491 - val_loss: 2.1852 - val_accuracy: 0.7692\n",
            "Epoch 5/10\n",
            "114/114 [==============================] - 2s 20ms/step - loss: 0.5911 - accuracy: 0.6579 - val_loss: 1.7995 - val_accuracy: 0.7692\n",
            "Epoch 6/10\n",
            "114/114 [==============================] - 2s 20ms/step - loss: 0.5089 - accuracy: 0.6667 - val_loss: 1.4039 - val_accuracy: 0.7692\n",
            "Epoch 7/10\n",
            "114/114 [==============================] - 2s 18ms/step - loss: 1.1421 - accuracy: 0.6579 - val_loss: 1.4363 - val_accuracy: 0.7692\n",
            "Epoch 8/10\n",
            "114/114 [==============================] - 2s 18ms/step - loss: 15.3959 - accuracy: 0.6404 - val_loss: 30.3594 - val_accuracy: 0.8462\n",
            "Epoch 9/10\n",
            "114/114 [==============================] - 2s 20ms/step - loss: 0.6209 - accuracy: 0.6667 - val_loss: 25.9784 - val_accuracy: 0.7692\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "Results for fold: 4\n",
            "Accuracy: 0.5454545454545454, Recall: 0.09090909090909091, False Positives: 0.18181818181818182, Specificity: 0.8181818181818182, Precision: 0.16666666666666666.\n",
            "Epoch 1/10\n",
            "123/123 [==============================] - 6s 30ms/step - loss: 54.3958 - accuracy: 0.5528 - val_loss: 1.4427 - val_accuracy: 0.5714\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 2s 19ms/step - loss: 13.7886 - accuracy: 0.6911 - val_loss: 0.6379 - val_accuracy: 0.7143\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 2s 19ms/step - loss: 2.0937 - accuracy: 0.7154 - val_loss: 0.6347 - val_accuracy: 0.7143\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 2s 19ms/step - loss: 0.7686 - accuracy: 0.7480 - val_loss: 0.6303 - val_accuracy: 0.7143\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 2s 19ms/step - loss: 0.6371 - accuracy: 0.6992 - val_loss: 0.6258 - val_accuracy: 0.7143\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 2s 19ms/step - loss: 1.0067 - accuracy: 0.7073 - val_loss: 0.6226 - val_accuracy: 0.7143\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 2s 17ms/step - loss: 10.6497 - accuracy: 0.7154 - val_loss: 20.9056 - val_accuracy: 0.7143\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 2s 20ms/step - loss: 3.2610 - accuracy: 0.7398 - val_loss: 0.6168 - val_accuracy: 0.7143\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 2s 18ms/step - loss: 2.7116 - accuracy: 0.7236 - val_loss: 7.3238 - val_accuracy: 0.7143\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 2s 19ms/step - loss: 2.9920 - accuracy: 0.7317 - val_loss: 0.6112 - val_accuracy: 0.7143\n",
            "1/1 [==============================] - 1s 825ms/step\n",
            "Results for fold: 5\n",
            "Accuracy: 0.5652173913043478, Recall: 0.09090909090909091, False Positives: 0.043478260869565216, Specificity: 0.9565217391304348, Precision: 1.0.\n",
            "Results for all folds:\n",
            "Accuracy: 0.5682755467017665, Recall: 0.1585858585858586, False Positive Rate: 0.1457384056852574, Specificity: 0.8542615943147427, Precision: 0.3748717948717949.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_results = assess_model(create_CNN_model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDp9IsKtJ_hO",
        "outputId": "097a8667-23a3-4c00-fe14-b05140a969df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "116/116 [==============================] - 6s 30ms/step - loss: 92.0830 - accuracy: 0.6207 - val_loss: 52.4231 - val_accuracy: 0.8462\n",
            "Epoch 2/10\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 29.6752 - accuracy: 0.6552 - val_loss: 30.9231 - val_accuracy: 0.8462\n",
            "Epoch 3/10\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 13.4238 - accuracy: 0.7414 - val_loss: 23.9736 - val_accuracy: 0.6923\n",
            "Epoch 4/10\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 8.0575 - accuracy: 0.7414 - val_loss: 0.4659 - val_accuracy: 0.8462\n",
            "Epoch 5/10\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 0.5042 - accuracy: 0.7500 - val_loss: 0.4619 - val_accuracy: 0.8462\n",
            "Epoch 6/10\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 3.9805 - accuracy: 0.7759 - val_loss: 0.4084 - val_accuracy: 0.8462\n",
            "Epoch 7/10\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 3.0433 - accuracy: 0.7586 - val_loss: 0.3147 - val_accuracy: 0.9231\n",
            "Epoch 8/10\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 1.5450 - accuracy: 0.7500 - val_loss: 0.2959 - val_accuracy: 0.9231\n",
            "Epoch 9/10\n",
            "116/116 [==============================] - 2s 21ms/step - loss: 3.9913 - accuracy: 0.7414 - val_loss: 8.8832 - val_accuracy: 0.8462\n",
            "Epoch 10/10\n",
            "116/116 [==============================] - 2s 21ms/step - loss: 0.5075 - accuracy: 0.7672 - val_loss: 9.0133 - val_accuracy: 0.8462\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Results for fold: 1\n",
            "Accuracy: 0.45161290322580644, Recall: 0.05555555555555555, False Positives: 0.03225806451612903, Specificity: 0.967741935483871, Precision: 1.0.\n",
            "Epoch 1/10\n",
            "112/112 [==============================] - 6s 35ms/step - loss: 180.0878 - accuracy: 0.5536 - val_loss: 51.1382 - val_accuracy: 0.3077\n",
            "Epoch 2/10\n",
            "112/112 [==============================] - 3s 23ms/step - loss: 9.4634 - accuracy: 0.5179 - val_loss: 30.1659 - val_accuracy: 0.3077\n",
            "Epoch 3/10\n",
            "112/112 [==============================] - 3s 23ms/step - loss: 0.5504 - accuracy: 0.6696 - val_loss: 1.4781 - val_accuracy: 0.7692\n",
            "Epoch 4/10\n",
            "112/112 [==============================] - 3s 23ms/step - loss: 0.5198 - accuracy: 0.6696 - val_loss: 0.4339 - val_accuracy: 0.7692\n",
            "Epoch 5/10\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 0.4882 - accuracy: 0.6786 - val_loss: 1.3653 - val_accuracy: 0.6923\n",
            "Epoch 6/10\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 1.1124 - accuracy: 0.6786 - val_loss: 11.1062 - val_accuracy: 0.6923\n",
            "Epoch 7/10\n",
            "112/112 [==============================] - 3s 24ms/step - loss: 1.6405 - accuracy: 0.6429 - val_loss: 14.2792 - val_accuracy: 0.6923\n",
            "2/2 [==============================] - 2s 366ms/step\n",
            "Results for fold: 2\n",
            "Accuracy: 0.6285714285714286, Recall: 0.45454545454545453, False Positives: 0.34285714285714286, Specificity: 0.6571428571428571, Precision: 0.4166666666666667.\n",
            "Epoch 1/10\n",
            "109/109 [==============================] - 6s 35ms/step - loss: 121.9813 - accuracy: 0.4495 - val_loss: 20.7641 - val_accuracy: 0.7692\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 3s 23ms/step - loss: 18.7290 - accuracy: 0.5872 - val_loss: 14.1250 - val_accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 3s 23ms/step - loss: 8.2810 - accuracy: 0.6147 - val_loss: 2.2434 - val_accuracy: 0.6923\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 3s 23ms/step - loss: 1.1246 - accuracy: 0.6606 - val_loss: 0.5330 - val_accuracy: 0.6923\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 3s 24ms/step - loss: 0.5023 - accuracy: 0.6697 - val_loss: 0.5325 - val_accuracy: 0.6923\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 3s 23ms/step - loss: 0.5342 - accuracy: 0.6330 - val_loss: 0.5320 - val_accuracy: 0.6923\n",
            "Epoch 7/10\n",
            "109/109 [==============================] - 3s 23ms/step - loss: 0.5086 - accuracy: 0.6606 - val_loss: 0.5314 - val_accuracy: 0.6923\n",
            "Epoch 8/10\n",
            "109/109 [==============================] - 3s 23ms/step - loss: 0.5213 - accuracy: 0.6422 - val_loss: 0.5311 - val_accuracy: 0.6923\n",
            "Epoch 9/10\n",
            "109/109 [==============================] - 2s 22ms/step - loss: 0.5085 - accuracy: 0.6606 - val_loss: 0.5311 - val_accuracy: 0.6923\n",
            "Epoch 10/10\n",
            "109/109 [==============================] - 2s 21ms/step - loss: 0.5533 - accuracy: 0.6422 - val_loss: 0.5313 - val_accuracy: 0.6923\n",
            "2/2 [==============================] - 1s 269ms/step\n",
            "Results for fold: 3\n",
            "Accuracy: 0.7894736842105263, Recall: 0.125, False Positives: 0.05263157894736842, Specificity: 0.9473684210526315, Precision: 0.5.\n",
            "Epoch 1/10\n",
            "114/114 [==============================] - 6s 29ms/step - loss: 83.8876 - accuracy: 0.5526 - val_loss: 136.4567 - val_accuracy: 0.2308\n",
            "Epoch 2/10\n",
            "114/114 [==============================] - 3s 23ms/step - loss: 0.6984 - accuracy: 0.5351 - val_loss: 26.5024 - val_accuracy: 0.3077\n",
            "Epoch 3/10\n",
            "114/114 [==============================] - 2s 21ms/step - loss: 5.2701 - accuracy: 0.6316 - val_loss: 29.5152 - val_accuracy: 0.7692\n",
            "Epoch 4/10\n",
            "114/114 [==============================] - 2s 21ms/step - loss: 4.2350 - accuracy: 0.6579 - val_loss: 28.2913 - val_accuracy: 0.7692\n",
            "Epoch 5/10\n",
            "114/114 [==============================] - 3s 23ms/step - loss: 0.5635 - accuracy: 0.6579 - val_loss: 23.6111 - val_accuracy: 0.7692\n",
            "Epoch 6/10\n",
            "114/114 [==============================] - 2s 21ms/step - loss: 0.5691 - accuracy: 0.6491 - val_loss: 24.1112 - val_accuracy: 0.7692\n",
            "Epoch 7/10\n",
            "114/114 [==============================] - 2s 21ms/step - loss: 0.5613 - accuracy: 0.6667 - val_loss: 25.4209 - val_accuracy: 0.7692\n",
            "Epoch 8/10\n",
            "114/114 [==============================] - 3s 24ms/step - loss: 0.5490 - accuracy: 0.6667 - val_loss: 26.1282 - val_accuracy: 0.7692\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "Results for fold: 4\n",
            "Accuracy: 0.6363636363636364, Recall: 0.0, False Positives: 0.030303030303030304, Specificity: 0.9696969696969697, Precision: 0.0.\n",
            "Epoch 1/10\n",
            "123/123 [==============================] - 6s 34ms/step - loss: 96.0177 - accuracy: 0.5528 - val_loss: 20.8326 - val_accuracy: 0.7143\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 3s 23ms/step - loss: 4.4424 - accuracy: 0.6829 - val_loss: 6.9435 - val_accuracy: 0.5714\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 3s 23ms/step - loss: 8.1068 - accuracy: 0.7073 - val_loss: 5.5725 - val_accuracy: 0.7143\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 3s 23ms/step - loss: 0.8985 - accuracy: 0.7398 - val_loss: 0.7773 - val_accuracy: 0.7143\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 3s 21ms/step - loss: 0.5050 - accuracy: 0.7317 - val_loss: 1.1882 - val_accuracy: 0.7143\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 3s 21ms/step - loss: 0.5947 - accuracy: 0.7073 - val_loss: 0.9686 - val_accuracy: 0.7143\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 3s 23ms/step - loss: 1.4996 - accuracy: 0.7236 - val_loss: 2.2813 - val_accuracy: 0.7143\n",
            "1/1 [==============================] - 1s 983ms/step\n",
            "Results for fold: 5\n",
            "Accuracy: 0.5217391304347826, Recall: 0.0, False Positives: 0.0, Specificity: 1.0, Precision: 0.0.\n",
            "Results for all folds:\n",
            "Accuracy: 0.6055521565612361, Recall: 0.127020202020202, False Positive Rate: 0.09160996332473412, Specificity: 0.9083900366752659, Precision: 0.38333333333333336.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_results = assess_model(create_CNN_model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Cu3TNd5-FQ",
        "outputId": "ff0a4174-6e01-4020-e606-85d936941a22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "116/116 [==============================] - 7s 45ms/step - loss: 254.5429 - accuracy: 0.5776 - val_loss: 39.8462 - val_accuracy: 0.8462\n",
            "Epoch 2/10\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 120.0346 - accuracy: 0.7069 - val_loss: 4.6328 - val_accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 13.4113 - accuracy: 0.7586 - val_loss: 0.5272 - val_accuracy: 0.8462\n",
            "Epoch 4/10\n",
            "116/116 [==============================] - 3s 28ms/step - loss: 8.0287 - accuracy: 0.7414 - val_loss: 0.5705 - val_accuracy: 0.8462\n",
            "Epoch 5/10\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 14.8329 - accuracy: 0.7672 - val_loss: 0.2675 - val_accuracy: 0.8462\n",
            "Epoch 6/10\n",
            "116/116 [==============================] - 3s 28ms/step - loss: 0.4498 - accuracy: 0.8103 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
            "Epoch 7/10\n",
            "116/116 [==============================] - 3s 28ms/step - loss: 0.4956 - accuracy: 0.7845 - val_loss: 0.5015 - val_accuracy: 0.8462\n",
            "Epoch 8/10\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.5578 - accuracy: 0.7500 - val_loss: 0.4952 - val_accuracy: 0.8462\n",
            "1/1 [==============================] - 1s 895ms/step\n",
            "Results for fold: 1\n",
            "Accuracy: 0.3870967741935484, Recall: 0.1111111111111111, False Positives: 0.16129032258064516, Specificity: 0.8387096774193549, Precision: 0.4.\n",
            "Epoch 1/10\n",
            "112/112 [==============================] - 7s 45ms/step - loss: 203.9303 - accuracy: 0.5446 - val_loss: 39.2452 - val_accuracy: 0.6923\n",
            "Epoch 2/10\n",
            "112/112 [==============================] - 4s 32ms/step - loss: 9.8743 - accuracy: 0.6875 - val_loss: 0.4411 - val_accuracy: 0.6923\n",
            "Epoch 3/10\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 7.6003 - accuracy: 0.5982 - val_loss: 0.5527 - val_accuracy: 0.6923\n",
            "Epoch 4/10\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 7.2225 - accuracy: 0.6696 - val_loss: 0.7192 - val_accuracy: 0.6154\n",
            "Epoch 5/10\n",
            "112/112 [==============================] - 4s 32ms/step - loss: 0.6044 - accuracy: 0.6518 - val_loss: 0.6144 - val_accuracy: 0.6923\n",
            "2/2 [==============================] - 1s 105ms/step\n",
            "Results for fold: 2\n",
            "Accuracy: 0.5142857142857142, Recall: 0.36363636363636365, False Positives: 0.4, Specificity: 0.6, Precision: 0.2857142857142857.\n",
            "Epoch 1/10\n",
            "109/109 [==============================] - 7s 43ms/step - loss: 181.4121 - accuracy: 0.5505 - val_loss: 13.1812 - val_accuracy: 0.8462\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 45.3014 - accuracy: 0.6789 - val_loss: 0.6409 - val_accuracy: 0.3846\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 5.0930 - accuracy: 0.5138 - val_loss: 0.5864 - val_accuracy: 0.6923\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 4.0416 - accuracy: 0.5963 - val_loss: 0.5869 - val_accuracy: 0.4615\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 0.5094 - accuracy: 0.4862 - val_loss: 0.5867 - val_accuracy: 0.6923\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 3s 32ms/step - loss: 0.5327 - accuracy: 0.6147 - val_loss: 0.5867 - val_accuracy: 0.6923\n",
            "2/2 [==============================] - 1s 183ms/step\n",
            "Results for fold: 3\n",
            "Accuracy: 0.7631578947368421, Recall: 0.125, False Positives: 0.07894736842105263, Specificity: 0.9210526315789473, Precision: 0.3333333333333333.\n",
            "Epoch 1/10\n",
            "114/114 [==============================] - 7s 44ms/step - loss: 189.4925 - accuracy: 0.6316 - val_loss: 112.7981 - val_accuracy: 0.2308\n",
            "Epoch 2/10\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 37.2699 - accuracy: 0.6140 - val_loss: 9.8890 - val_accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 25.2611 - accuracy: 0.6667 - val_loss: 0.6869 - val_accuracy: 0.7692\n",
            "Epoch 4/10\n",
            "114/114 [==============================] - 3s 27ms/step - loss: 0.5509 - accuracy: 0.6667 - val_loss: 0.7285 - val_accuracy: 0.7692\n",
            "Epoch 5/10\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 1.1585 - accuracy: 0.6930 - val_loss: 0.6308 - val_accuracy: 0.7692\n",
            "Epoch 6/10\n",
            "114/114 [==============================] - 3s 27ms/step - loss: 9.8120 - accuracy: 0.6754 - val_loss: 0.6752 - val_accuracy: 0.7692\n",
            "Epoch 7/10\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.5256 - accuracy: 0.6754 - val_loss: 0.6668 - val_accuracy: 0.7692\n",
            "Epoch 8/10\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 28.2464 - accuracy: 0.6930 - val_loss: 0.6209 - val_accuracy: 0.7692\n",
            "Epoch 9/10\n",
            "114/114 [==============================] - 3s 27ms/step - loss: 7.2489 - accuracy: 0.6930 - val_loss: 17.3991 - val_accuracy: 0.7692\n",
            "Epoch 10/10\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 24.1115 - accuracy: 0.6667 - val_loss: 111.0385 - val_accuracy: 0.3077\n",
            "2/2 [==============================] - 0s 44ms/step\n",
            "Results for fold: 4\n",
            "Accuracy: 0.42424242424242425, Recall: 0.36363636363636365, False Positives: 0.48484848484848486, Specificity: 0.5151515151515151, Precision: 0.25.\n",
            "Epoch 1/10\n",
            "123/123 [==============================] - 7s 40ms/step - loss: 159.4086 - accuracy: 0.5366 - val_loss: 93.6496 - val_accuracy: 0.3571\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 4s 31ms/step - loss: 37.1198 - accuracy: 0.6423 - val_loss: 57.2777 - val_accuracy: 0.7143\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 4s 31ms/step - loss: 3.3671 - accuracy: 0.7398 - val_loss: 26.0161 - val_accuracy: 0.7143\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 4s 31ms/step - loss: 2.3808 - accuracy: 0.7480 - val_loss: 13.3193 - val_accuracy: 0.7143\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 4s 31ms/step - loss: 1.4241 - accuracy: 0.7236 - val_loss: 0.6330 - val_accuracy: 0.7143\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 3s 27ms/step - loss: 13.8949 - accuracy: 0.7480 - val_loss: 10.4571 - val_accuracy: 0.7143\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 4s 31ms/step - loss: 5.1519 - accuracy: 0.7561 - val_loss: 0.6255 - val_accuracy: 0.7143\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 4s 31ms/step - loss: 0.4780 - accuracy: 0.7642 - val_loss: 0.6219 - val_accuracy: 0.7143\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 4s 31ms/step - loss: 3.4134 - accuracy: 0.7317 - val_loss: 0.5738 - val_accuracy: 0.7143\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 3s 27ms/step - loss: 0.5372 - accuracy: 0.7073 - val_loss: 0.6145 - val_accuracy: 0.7143\n",
            "1/1 [==============================] - 1s 687ms/step\n",
            "Results for fold: 5\n",
            "Accuracy: 0.5217391304347826, Recall: 0.0, False Positives: 0.0, Specificity: 1.0, Precision: 0.0.\n",
            "Results for all folds:\n",
            "Accuracy: 0.5221043875786624, Recall: 0.19267676767676767, False Positive Rate: 0.22501723517003652, Specificity: 0.7749827648299635, Precision: 0.2538095238095238.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}