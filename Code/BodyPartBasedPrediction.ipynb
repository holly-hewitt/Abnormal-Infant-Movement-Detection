{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform body part based prediction: Based on \n",
    "# Ho, E.S.L., McCay, K.D., Sakkos, D., Woo, W.L., Marcroft, C., Dulson, P., Embleton, N.D., 2021. \n",
    "# Towards Explainable Abnormal Infant Movements Identification: A Body-part Based Prediction and Visualisation Framework, \n",
    "# in: 2021 IEEE EMBS International Conference on Biomedical and Health Informatics (BHI). \n",
    "# Presented at the 2021 IEEE EMBS International Conference on Biomedical and Health Informatics (BHI), \n",
    "# pp. 1â€“4. https://doi.org/10.1109/BHI50953.2021.9508603\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data from pickles\n",
    "with open('drive/MyDrive/Pickles/X_smoothed_mean_norm.pickle', 'rb') as handle:\n",
    "    X_smoothed_mean_norm = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AccXRA    AccYRA    AccZRA    AccXLA    AccYLA    AccZLA    AccXRW  \\\n",
      "0      0.910473  0.024397 -5.176289 -0.559843  3.420900 -4.765396 -3.138499   \n",
      "1      1.036153  0.005995 -5.023745 -0.558799  3.408857 -4.766926 -2.831541   \n",
      "2      1.032857  0.194585 -4.841748 -0.560481  3.408845 -4.766155 -2.921978   \n",
      "3      1.018236  0.196418 -5.382666 -0.560568  3.408325 -4.763335 -2.849972   \n",
      "4      1.119276  1.241573 -4.833676 -0.561957  3.405383 -4.770709 -2.745618   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "19296  0.730245 -0.130767 -0.530644 -0.721722  0.051651 -0.540139 -0.433730   \n",
      "19297  0.730245 -0.130767 -0.530644 -0.721722  0.051651 -0.540139 -0.433730   \n",
      "19298  0.730245 -0.130767 -0.530644 -0.721722  0.051651 -0.540139 -0.433730   \n",
      "19299  0.730245 -0.130767 -0.530644 -0.721722  0.051651 -0.540139 -0.433730   \n",
      "19300  0.730245 -0.130767 -0.530644 -0.721722  0.051651 -0.540139 -0.433730   \n",
      "\n",
      "         AccYRW    AccZRW    AccXLW    AccYLW    AccZLW  AccSumRA  AccSumLA  \\\n",
      "0      1.012602 -1.869969  0.412716  0.310640 -3.345527  1.343327  1.314284   \n",
      "1      1.262602 -1.999231  0.413445  0.310226 -3.344663  1.287685  1.313046   \n",
      "2      1.193416 -1.928140  0.417113  0.308987 -3.354410  1.211540  1.312663   \n",
      "3      1.108757 -1.896729  0.411326  0.303997 -3.362826  1.453025  1.311557   \n",
      "4      1.215171 -2.103003  0.441627  0.308666 -3.354774  1.410002  1.313684   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "19296  0.163182 -0.414754  0.058075  0.577712 -0.234308 -0.741678 -0.739366   \n",
      "19297  0.163182 -0.414754  0.058075  0.577712 -0.234308 -0.741678 -0.739366   \n",
      "19298  0.163182 -0.414754  0.058075  0.577712 -0.234308 -0.741678 -0.739366   \n",
      "19299  0.163182 -0.414754  0.058075  0.577712 -0.234308 -0.741678 -0.739366   \n",
      "19300  0.163182 -0.414754  0.058075  0.577712 -0.234308 -0.741678 -0.739366   \n",
      "\n",
      "       AccSumRW  AccSumLW  \n",
      "0      1.400513  1.323351  \n",
      "1      1.327243  1.322878  \n",
      "2      1.329195  1.329651  \n",
      "3      1.265507  1.334901  \n",
      "4      1.317685  1.332393  \n",
      "...         ...       ...  \n",
      "19296 -0.741212 -0.741652  \n",
      "19297 -0.741212 -0.741652  \n",
      "19298 -0.741212 -0.741652  \n",
      "19299 -0.741212 -0.741652  \n",
      "19300 -0.741212 -0.741652  \n",
      "\n",
      "[19301 rows x 16 columns]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(X_smoothed_mean_norm[0])\n",
    "print(type(X_smoothed_mean_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RA will be a df with the cols AccXRA, AccYRA, AccZRA, AccSumRA extracted from X_smoothed_mean_norm\n",
    "RA = [pd.DataFrame(trial, columns=['AccXRA', 'AccYRA', 'AccZRA', 'AccSumRA']) for trial in X_smoothed_mean_norm]\n",
    "RW = [pd.DataFrame(trial, columns=['AccXRW', 'AccYRW', 'AccZRW', 'AccSumRW']) for trial in X_smoothed_mean_norm]\n",
    "LA = [pd.DataFrame(trial, columns=['AccXLA', 'AccYLA', 'AccZLA', 'AccSumLA']) for trial in X_smoothed_mean_norm]\n",
    "LW = [pd.DataFrame(trial, columns=['AccXLW', 'AccYLW', 'AccZLW', 'AccSumLW']) for trial in X_smoothed_mean_norm]\n",
    "\n",
    "# Save the dataframes to pickle\n",
    "with open('drive/MyDrive/Pickles/RA.pickle', 'wb') as handle:\n",
    "    pickle.dump(RA, handle)\n",
    "with open('drive/MyDrive/Pickles/RW.pickle', 'wb') as handle:\n",
    "    pickle.dump(RW, handle)\n",
    "with open('drive/MyDrive/Pickles/LA.pickle', 'wb') as handle:\n",
    "    pickle.dump(LA, handle)\n",
    "with open('drive/MyDrive/Pickles/LW.pickle', 'wb') as handle:\n",
    "    pickle.dump(LW, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in labels\n",
    "with open('drive/MyDrive/Pickles/abnormal_encoded.pickle', 'rb') as handle:\n",
    "    abnormal_encoded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(abnormal_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def create_cnn_model(shape, filters=32, kernel_size=3, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=shape))  # Adjust the input_shape to match your dataset\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(19301, 16)))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)) )  # Reduced the number of neurons in the dense layer\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fold 1/5\n",
      "\n",
      "Training on dataset: RA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FEA69035E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE00327EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE006230D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "\n",
      "Training on dataset: RW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE006238B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE007509D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE104101F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "\n",
      "Training on dataset: LA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE10496798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FEA60CB048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE003E13A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "\n",
      "Training on dataset: LW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE10477F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE8174B8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FEA6075828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "\n",
      "Fold 1 results:\n",
      "Accuracy: 0.5455, Sensitivity: 0.5722, Precision: 0.6071\n",
      "\n",
      "Starting fold 2/5\n",
      "\n",
      "Training on dataset: RA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE81924A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FEA4E32558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE813AAB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "\n",
      "Training on dataset: RW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE815518B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE819B3168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FEA5F1D5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "\n",
      "Training on dataset: LA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE000A30D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE0032F5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE0014BAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "\n",
      "Training on dataset: LW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FEA607F8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FEA6083F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE0038E558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "\n",
      "Fold 2 results:\n",
      "Accuracy: 0.6875, Sensitivity: 0.6473, Precision: 0.6320\n",
      "\n",
      "Starting fold 3/5\n",
      "\n",
      "Training on dataset: RA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE0014B798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE0DC1F828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE0DCC3D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "\n",
      "Training on dataset: RW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE0DD0D678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE0DC1F5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FEA6083288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "\n",
      "Training on dataset: LA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE0DCA60D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE00005558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FEA5FDB948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "\n",
      "Training on dataset: LW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FEA5FDBDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE81551948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FEA4E32F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "\n",
      "Fold 3 results:\n",
      "Accuracy: 0.7812, Sensitivity: 0.7057, Precision: 0.6875\n",
      "\n",
      "Starting fold 4/5\n",
      "\n",
      "Training on dataset: RA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE813AAEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE007E3168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE815C3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "\n",
      "Training on dataset: RW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE815C30D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE811C4948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE003E6F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "\n",
      "Training on dataset: LA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE816E7EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE8187D1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE0075CF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "\n",
      "Training on dataset: LW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE00356048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FEA61C9AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE00419828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "\n",
      "Fold 4 results:\n",
      "Accuracy: 0.6562, Sensitivity: 0.6250, Precision: 0.6299\n",
      "\n",
      "Starting fold 5/5\n",
      "\n",
      "Training on dataset: RA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE00249C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE104E3558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE06DA2A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "\n",
      "Training on dataset: RW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE06DFED38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE06F65828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FEA61C9318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "\n",
      "Training on dataset: LA\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FE00258678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE00750C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE006F0AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "\n",
      "Training on dataset: LW\n",
      "Starting training...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FEA60CB168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FE8174BEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE815C3828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "\n",
      "Fold 5 results:\n",
      "Accuracy: 0.6250, Sensitivity: 0.5385, Precision: 0.8065\n",
      "\n",
      "Final aggregated results across all folds:\n",
      "Accuracy: Mean = 0.6591, Std = 0.0772\n",
      "Sensitivity: Mean = 0.6177, Std = 0.0584\n",
      "Precision: Mean = 0.6726, Std = 0.0720\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Masking\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def train_and_evaluate(dataset_names, create_model_fn, class_weights):\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(outer_cv.split(np.arange(len(abnormal_encoded)))):\n",
    "        print(f'\\nStarting fold {fold + 1}/{outer_cv.n_splits}')\n",
    "        \n",
    "        fold_predictions = []\n",
    "        Y_test_fold = None\n",
    "\n",
    "        for dataset_name in dataset_names:\n",
    "            print(f'\\nTraining on dataset: {dataset_name}')\n",
    "\n",
    "            with open(f'drive/MyDrive/Pickles/{dataset_name}.pickle', 'rb') as handle:\n",
    "                dataset = pickle.load(handle)\n",
    "            dataset = np.array(dataset)\n",
    "\n",
    "            X_train, X_test = dataset[train_index], dataset[test_index]\n",
    "            Y_train, Y_test = abnormal_encoded[train_index], abnormal_encoded[test_index]\n",
    "            X_train, Y_train, X_test, Y_test = map(lambda x: x.astype('float32'), [X_train, Y_train, X_test, Y_test])\n",
    "\n",
    "            if Y_test_fold is None:\n",
    "                Y_test_fold = Y_test\n",
    "\n",
    "            model = create_model_fn(X_train.shape[1:])\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "            class_weights_dict = compute_class_weights(Y_train) if class_weights else None\n",
    "\n",
    "            print('Starting training...')\n",
    "            history = model.fit(X_train, Y_train, epochs=15, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=0, class_weight=class_weights_dict)\n",
    "\n",
    "            print('Training completed.')\n",
    "            print('Evaluating model on test set...')\n",
    "            Y_pred = model.predict(X_test)\n",
    "            fold_predictions.append(Y_pred)\n",
    "\n",
    "        avg_predictions = np.mean(fold_predictions, axis=0)\n",
    "        Y_pred_classes = np.argmax(avg_predictions, axis=1)\n",
    "        Y_test_classes = np.argmax(Y_test_fold, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(Y_test_classes, Y_pred_classes)\n",
    "        sensitivity = recall_score(Y_test_classes, Y_pred_classes, average='macro')\n",
    "        precision = precision_score(Y_test_classes, Y_pred_classes, average='macro')\n",
    "\n",
    "        fold_result = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Precision': precision\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "\n",
    "        print(f'\\nFold {fold + 1} results:')\n",
    "        print(f'Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Precision: {precision:.4f}')\n",
    "\n",
    "    # Aggregate and print final results\n",
    "    final_results = aggregate_results(fold_results)\n",
    "    print('\\nFinal aggregated results across all folds:')\n",
    "    for metric, value in final_results.items():\n",
    "        print(f'{metric}: Mean = {value[\"mean\"]:.4f}, Std = {value[\"std\"]:.4f}')\n",
    "\n",
    "def compute_class_weights(Y_train):\n",
    "    Y_train_classes = np.argmax(Y_train, axis=1)\n",
    "    cw = compute_class_weight('balanced', classes=np.unique(Y_train_classes), y=Y_train_classes)\n",
    "    return dict(enumerate(cw))\n",
    "\n",
    "def aggregate_results(all_results):\n",
    "    # Calculate mean and standard deviation for each metric\n",
    "    aggregated = {}\n",
    "    for key in all_results[0].keys():\n",
    "        values = [result[key] for result in all_results]\n",
    "        aggregated[key] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values)\n",
    "        }\n",
    "    return aggregated\n",
    "\n",
    "def print_aggregated_results(aggregated_results):\n",
    "    for metric, stats in aggregated_results.items():\n",
    "        print(f\"{metric}: {stats['mean']} +/- {stats['std']}\")\n",
    "\n",
    "# Example usage\n",
    "# This assumes that `abnormal_encoded`, `create_model_fn`, and the dataset loading are properly defined\n",
    "dataset_names = ['RA', 'RW', 'LA', 'LW']  # Example dataset names\n",
    "\n",
    "results = train_and_evaluate(dataset_names, create_cnn_model, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37580\\2833262432.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Train the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mRA_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Print the name and gini importance of each feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         X, y = self._validate_data(\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         )\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m             raise ValueError(\n\u001b[0;32m    795\u001b[0m                 \u001b[1;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m             )\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# classify each body part and averag the results to classifiy the whole trial\n",
    "# RA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(RA), np.array(abnormal_encoded), test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a random forest classifier\n",
    "RA_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "RA_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(['AccXRA', 'AccYRA', 'AccZRA', 'AccSumRA'], RA_clf.feature_importances_):\n",
    "    print(feature)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred_RA = RA_clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred_RA))\n",
    "\n",
    "# Print the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_RA))\n",
    "\n",
    "# RW\n",
    "X_train, X_test, y_train, y_test = train_test_split(RW, abnormal_encoded, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a random forest classifier\n",
    "RW_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "RW_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(['AccXRW', 'AccYRW', 'AccZRW', 'AccSumRW'], RW_clf.feature_importances_):\n",
    "    print(feature)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred_RW = RW_clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_RW))\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, y_pred_RW))\n",
    "\n",
    "# LA\n",
    "X_train, X_test, y_train, y_test = train_test_split(LA, abnormal_encoded, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a random forest classifier\n",
    "LA_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "LA_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(['AccXLA', 'AccYLA', 'AccZLA', 'AccSumLA'], LA_clf.feature_importances_):\n",
    "    print(feature)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred_LA = LA_clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_LA))\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, y_pred_LA))\n",
    "\n",
    "# LW\n",
    "X_train, X_test, y_train, y_test = train_test_split(LW, abnormal_encoded, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a random forest classifier\n",
    "LW_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "LW_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(['AccXLW', 'AccYLW', 'AccZLW', 'AccSumLW'], LW_clf.feature_importances_):\n",
    "    print(feature)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred_LW = LW_clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_LW))\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, y_pred_LW))\n",
    "\n",
    "# Average the results of y_pred_RA, y_pred_RW, y_pred_LA, y_pred_LW to get the final prediction\n",
    "y_pred = (y_pred_RA + y_pred_RW + y_pred_LA + y_pred_LW) / 4\n",
    "print(y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
