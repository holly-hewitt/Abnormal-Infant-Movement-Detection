{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.enable_eager_execution(tf.ConfigProto(log_device_placement=True))\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "# Load accelData from pickle\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "# import pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D, Normalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# score imports\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "# class weight import\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "# open accelData pickle\n",
    "import pickle\n",
    "with open('drive/MyDrive/Pickles/accelData.pickle', 'rb') as handle:\n",
    "    accelData = pickle.load(handle)\n",
    "\n",
    "# Remove time column from accelData Measurements\n",
    "accelData['Measurements with Time'] = accelData['Measurements']\n",
    "\n",
    "for i in range(len(accelData['Measurements'])):\n",
    "    accelData['Measurements'][i] = accelData['Measurements'][i].iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(accelData['Abnormal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "#import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "def window_generator(data, labels, windowSize, stride, batch_size=128):\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "\n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        batch_windows = []\n",
    "\n",
    "        for i in np.random.permutation(len(data)):\n",
    "\n",
    "            batch_windows.append(data[i])            \n",
    "            batch_labels.append(labels[i])\n",
    "        \n",
    "            if len(batch_windows) == batch_size:\n",
    "\n",
    "                # normalize the batch\n",
    "                batch_windows_array = np.array(batch_windows)\n",
    "                batch_features= vectorized_normalization(batch_windows_array)\n",
    "\n",
    "                # PCA transform each window in the batch\n",
    "                #batch_features = PCA.transform(batch_features)\n",
    "\n",
    "                # Yield the batch data\n",
    "                yield np.array(batch_windows), np.array(batch_labels)\n",
    "                batch_features = []\n",
    "                batch_labels = []\n",
    "\n",
    "def vectorized_normalization(windows):\n",
    "    # Compute means and standard deviations for each window\n",
    "    means = windows.mean(axis=1, keepdims=True)\n",
    "    stds = windows.std(axis=1, keepdims=True)\n",
    "\n",
    "    # Normalize\n",
    "    normalized_windows = (windows - means) / stds\n",
    "\n",
    "    return normalized_windows\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    print(\"True negatives: \", tn)\n",
    "    fp = np.sum((y_true == 0) & (y_pred != 0))\n",
    "    print(\"False positives: \", fp)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    return specificity\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    l2_value = 0.01  # Example regularization factor for L2 regularization\n",
    "\n",
    "    model3 = Sequential([\n",
    "        Normalization(input_shape=input_shape),  # Uncommented and assuming normalization is configured correctly\n",
    "\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.5),\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model2 = Sequential([\n",
    "        #Normalization(input_shape=input_shape),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),  # Reduced filters\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),  # Removed one Conv1D and one Dropout layer for simplicity\n",
    "        Dense(64, activation='relu'),  # Reduced the size of the dense layer\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model4 = Sequential([\n",
    "        Normalization(input_shape=input_shape),  # Uncommented and assuming normalization is configured correctly\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),  # 'input_shape' is already defined in Normalization\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),  # Flattening the convolved features\n",
    "        \n",
    "        # Adding PCA-like layer: Dense layer with linear activation (or no activation) right after flattening\n",
    "        Dense(4, use_bias=False, activation=None),  # 'num_components' defines the reduced dimensionality\n",
    "        BatchNormalization(),  # Add Batch Normalization after PCA-like layer\n",
    "\n",
    "        Dense(32, activation='relu'),  # Continuing with the dense layers as before\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model = Sequential([\n",
    "        Normalization(input_shape=input_shape),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', kernel_regularizer=l2(l2_value)),  # Add L2 regularization to Conv1D\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        \n",
    "        # Adding PCA-like layer\n",
    "        Dense(4, use_bias=False, activation=None, kernel_regularizer=l2(l2_value)),  # Add L2 regularization to Dense layer\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(l2_value)),  # Add L2 regularization to Dense layer\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax', kernel_regularizer=l2(l2_value))  # Add L2 regularization to output layer\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', Precision(), Recall()],\n",
    "                  run_eagerly=False)\n",
    "    return model\n",
    "\n",
    "def createWindows(data, windowSize, stride):\n",
    "    windows = []\n",
    "    for i in range(0, len(data) - windowSize, stride):\n",
    "        windows.append(data[i:i+windowSize])\n",
    "    return windows\n",
    "    \n",
    "def batchWindowClassification(trials, labels, windowSize, stride, batch_size=100, verbose=False, percentage=0.25):\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trials, labels, test_size=0.3, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    if verbose:\n",
    "        # plot histogram showing distribution of labels\n",
    "        plt.hist(y_train)\n",
    "        # title\n",
    "        plt.title('Distribution of labels in training set')\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(y_test)\n",
    "        # title\n",
    "        plt.title('Distribution of labels in testing set')\n",
    "        plt.show()  \n",
    "\n",
    "        print(y_train)\n",
    "        print(y_test)\n",
    "\n",
    "    unique_labels = np.unique(np.concatenate((y_train, y_test, y_val)))\n",
    "    num_classes = len(unique_labels)\n",
    "    if verbose:\n",
    "        print(f\"Number of unique classes: {num_classes}\")\n",
    "\n",
    "    # Prepare labels for training\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(np.concatenate((y_train, y_test, y_val)))\n",
    "\n",
    "    # Split X_train into windows\n",
    "    trainWindows = []\n",
    "    trainWindowLabels = []\n",
    "    for i in range(len(X_train)):\n",
    "        windows = createWindows(X_train[i], windowSize, stride)\n",
    "        trainWindows.extend(windows)\n",
    "        labelArray = np.full(len(windows), y_train[i])\n",
    "        # Convert labelArray to a list\n",
    "        trainWindowLabels.extend(labelArray.tolist())\n",
    "\n",
    "    valWindows = []\n",
    "    valWindowLabels = []\n",
    "    for i in range(len(X_val)):\n",
    "        windows = createWindows(X_val[i], windowSize, stride)\n",
    "        valWindows.extend(windows)\n",
    "        labelArray = np.full(len(windows), y_val[i])\n",
    "        # Convert labelArray to a list\n",
    "        valWindowLabels.extend(labelArray.tolist())\n",
    "    \n",
    "    print(len(trainWindows))\n",
    "\n",
    "    # encode trainWindowLabels\n",
    "    encoded_trainWindowLabels = encoder.transform(trainWindowLabels)\n",
    "    encoded_trainWindowLabels = to_categorical(encoded_trainWindowLabels, num_classes=num_classes)\n",
    "\n",
    "    # encode valWindowLabels\n",
    "    encoded_valWindowLabels = encoder.transform(valWindowLabels)\n",
    "    encoded_valWindowLabels = to_categorical(encoded_valWindowLabels, num_classes=num_classes)\n",
    "\n",
    "    # Creating generators for training and validation\n",
    "    train_gen = window_generator(trainWindows, encoded_trainWindowLabels, windowSize, stride, batch_size=batch_size)\n",
    "    val_gen = window_generator(valWindows, encoded_valWindowLabels, windowSize, stride, batch_size=batch_size)\n",
    "\n",
    "    # Assuming `y_train` contains the original labels\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    model = build_model((windowSize, 16), 3)\n",
    "\n",
    "    # Adapting the Normalization layer with a batch of data from the training set\n",
    "    for X_batch, _ in window_generator(trainWindows, encoded_trainWindowLabels, windowSize, stride, batch_size=128):\n",
    "        model.layers[0].adapt(X_batch)  # Adapt the normalization layer\n",
    "        break \n",
    "\n",
    "    # Assume your model is named 'model' and is already defined\n",
    "    model.fit(train_gen, \n",
    "        #callbacks=[reduce_lr], \n",
    "        validation_data=(np.array(valWindows), encoded_valWindowLabels),\n",
    "        #validation_split=0.2,\n",
    "        steps_per_epoch=max(1, len(trainWindows) // batch_size), \n",
    "        #steps_per_epoch=100,\n",
    "        epochs=10, \n",
    "        verbose=1)\n",
    "        #callbacks=[tensorboard_callback]) #, class_weight=class_weights_dict)    \n",
    "\n",
    "    # Split X_test into windows, ensuring that the windows are segmented by trial\n",
    "    # Use nested list, where each element is a list of windows from a single trial\n",
    "    testWindows = []\n",
    "    testWindowLabels = []\n",
    "    for i in range(len(X_test)):\n",
    "        windows = createWindows(X_test[i], windowSize, stride)\n",
    "        testWindows.append(windows)\n",
    "        testWindowLabels.append(y_test[i])\n",
    "\n",
    "    # Encode test window labels\n",
    "    #encoder = LabelEncoder()\n",
    "    #encoder.fit(testWindowLabels)\n",
    "    encodedLabels = encoder.transform(testWindowLabels)\n",
    "    encodedLabels = to_categorical(encodedLabels)\n",
    "\n",
    "    # Predict the label of each window using the trained model\n",
    "    predictions = []\n",
    "    \n",
    "    for trial in testWindows:\n",
    "        trialPredictions = model.predict(np.array(trial))\n",
    "        predictions.append(trialPredictions)   \n",
    "\n",
    "    trial_pred = []\n",
    "    for i in range(len(predictions)):\n",
    "        normalCount = 0\n",
    "        borderLineCount = 0\n",
    "        abnormalCount = 0\n",
    "\n",
    "        for window in predictions[i]:\n",
    "            if np.argmax(window) == 0:\n",
    "                normalCount += 1\n",
    "            elif np.argmax(window) == 2:\n",
    "                abnormalCount += 1\n",
    "            else:\n",
    "                borderLineCount += 1\n",
    "              \n",
    "        # if more than percentage of the windows are classified as abnormal, classify the trial as abnormal\n",
    "        if abnormalCount / len(predictions[i]) > percentage:\n",
    "            trial_pred.append(1.0)\n",
    "        elif borderLineCount / len(predictions[i]) > percentage:\n",
    "            trial_pred.append(0.5)\n",
    "        else:\n",
    "            trial_pred.append(0.0)\n",
    "            \n",
    "    # Compare the classification to the true label and calculate the accuracy\n",
    "    print(trial_pred)\n",
    "    print(y_test)\n",
    "\n",
    "    # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
    "    accuracy = (accuracy_score(y_test, trial_pred))\n",
    "    sensitivity = (recall_score(y_test, trial_pred, average='macro'))\n",
    "    specificity = (specificity_score(np.array(y_test), np.array(trial_pred)))\n",
    "    false_positive_rate = (1 - specificity)\n",
    "    \n",
    "    precision = (precision_score(y_test, trial_pred, average='macro'))\n",
    "\n",
    "    results = {'accuracy': accuracy, 'sensitivity': sensitivity, 'false_positive_rate': false_positive_rate, 'specificity': specificity, 'precision': precision}\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Sensitivity: {sensitivity}')\n",
    "    print(f'False Positive Rate: {false_positive_rate}')\n",
    "    print(f'Specificity: {specificity}')\n",
    "    print(f'Precision: {precision}')    \n",
    "\n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4388\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CDB79258B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CDB79258B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CDB79A3048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CDB79A3048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 12s 343ms/step - loss: 8.0842 - accuracy: 0.5662\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 11s 328ms/step - loss: 0.7050 - accuracy: 0.6544\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 11s 323ms/step - loss: 0.5267 - accuracy: 0.7371\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 11s 321ms/step - loss: 0.4544 - accuracy: 0.7964\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 11s 324ms/step - loss: 0.3676 - accuracy: 0.8504\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 11s 321ms/step - loss: 0.3192 - accuracy: 0.8768\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 11s 329ms/step - loss: 0.2935 - accuracy: 0.8927\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 11s 328ms/step - loss: 0.2167 - accuracy: 0.9187\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 11s 328ms/step - loss: 0.1562 - accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 11s 336ms/step - loss: 0.1751 - accuracy: 0.9467\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CDB79DF8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CDB79DF8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "17 0 22\n",
      "0.0\n",
      "16 0 40\n",
      "1.0\n",
      "59 0 26\n",
      "0.0\n",
      "11 0 9\n",
      "1.0\n",
      "43 0 23\n",
      "1.0\n",
      "2 0 16\n",
      "1.0\n",
      "14 0 3\n",
      "0.0\n",
      "10 0 5\n",
      "0.0\n",
      "47 0 29\n",
      "0.0\n",
      "10 0 10\n",
      "1.0\n",
      "59 0 12\n",
      "1.0\n",
      "54 0 1\n",
      "0.0\n",
      "31 0 15\n",
      "0.0\n",
      "26 0 8\n",
      "0.0\n",
      "50 0 55\n",
      "0.0\n",
      "62 0 14\n",
      "0.0\n",
      "6 0 19\n",
      "1.0\n",
      "30 0 25\n",
      "0.0\n",
      "15 0 1\n",
      "0.0\n",
      "12 0 17\n",
      "1.0\n",
      "44 0 21\n",
      "0.0\n",
      "59 0 6\n",
      "1.0\n",
      "19 0 6\n",
      "0.0\n",
      "4 0 9\n",
      "0.0\n",
      "33 0 24\n",
      "0.0\n",
      "47 0 10\n",
      "1.0\n",
      "23 0 39\n",
      "0.0\n",
      "33 0 21\n",
      "0.0\n",
      "46 0 33\n",
      "0.0\n",
      "13 0 12\n",
      "0.0\n",
      "[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "accuracy, model = batchWindowClassification(accelData['Measurements'], accelData['Abnormal'], 5000, 2500, batch_size=128, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage: 0.1\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEE7879F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEE7879F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD4318F168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD4318F168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 15s 128ms/step - loss: 0.8951 - accuracy: 0.6716\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 13s 115ms/step - loss: 0.5019 - accuracy: 0.7647\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 0.4783 - accuracy: 0.7792\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 0.4639 - accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 13s 113ms/step - loss: 0.4217 - accuracy: 0.8021\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 13s 113ms/step - loss: 0.4069 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 0.4064 - accuracy: 0.8089\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 13s 114ms/step - loss: 0.3908 - accuracy: 0.8142\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 13s 115ms/step - loss: 0.3757 - accuracy: 0.8193\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 13s 114ms/step - loss: 0.3678 - accuracy: 0.8275\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB98ECD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB98ECD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "17/17 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "80 0 119\n",
      "0.0\n",
      "116 0 171\n",
      "1.0\n",
      "276 0 154\n",
      "0.0\n",
      "95 0 10\n",
      "1.0\n",
      "214 0 121\n",
      "1.0\n",
      "36 0 61\n",
      "1.0\n",
      "64 0 26\n",
      "0.0\n",
      "24 0 59\n",
      "0.0\n",
      "309 0 78\n",
      "0.0\n",
      "33 0 75\n",
      "1.0\n",
      "281 0 79\n",
      "1.0\n",
      "221 0 61\n",
      "0.0\n",
      "128 0 106\n",
      "0.0\n",
      "109 0 69\n",
      "0.0\n",
      "415 0 117\n",
      "0.0\n",
      "348 0 39\n",
      "0.0\n",
      "24 0 106\n",
      "1.0\n",
      "162 0 120\n",
      "0.0\n",
      "62 0 26\n",
      "0.0\n",
      "88 0 63\n",
      "1.0\n",
      "254 0 79\n",
      "0.0\n",
      "283 0 46\n",
      "1.0\n",
      "89 0 41\n",
      "0.0\n",
      "32 0 40\n",
      "0.0\n",
      "185 0 106\n",
      "0.0\n",
      "247 0 45\n",
      "1.0\n",
      "167 0 148\n",
      "0.0\n",
      "224 0 51\n",
      "0.0\n",
      "269 0 134\n",
      "0.0\n",
      "66 0 65\n",
      "0.0\n",
      "[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.3\n",
      "Accuracy: 0.3\n",
      "Percentage: 0.2\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CE9F7A8948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CE9F7A8948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CDF5F40438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CDF5F40438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 14s 122ms/step - loss: 0.9271 - accuracy: 0.6846\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 13s 116ms/step - loss: 0.5162 - accuracy: 0.7575\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 13s 117ms/step - loss: 0.4907 - accuracy: 0.7820\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 13s 118ms/step - loss: 0.4784 - accuracy: 0.7870\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 13s 113ms/step - loss: 0.4264 - accuracy: 0.8153\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 13s 115ms/step - loss: 0.4271 - accuracy: 0.8144\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 0.4078 - accuracy: 0.8219\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 13s 113ms/step - loss: 0.3781 - accuracy: 0.8359\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 13s 113ms/step - loss: 0.3863 - accuracy: 0.8292\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 0.3674 - accuracy: 0.8397\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB99978B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB99978B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "17/17 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "168 0 31\n",
      "0.0\n",
      "236 0 51\n",
      "1.0\n",
      "411 0 19\n",
      "0.0\n",
      "98 0 7\n",
      "1.0\n",
      "253 0 82\n",
      "1.0\n",
      "36 0 61\n",
      "1.0\n",
      "88 0 2\n",
      "0.0\n",
      "71 0 12\n",
      "0.0\n",
      "365 0 22\n",
      "0.0\n",
      "63 0 45\n",
      "1.0\n",
      "345 0 15\n",
      "1.0\n",
      "262 0 20\n",
      "0.0\n",
      "164 0 70\n",
      "0.0\n",
      "143 0 35\n",
      "0.0\n",
      "380 0 152\n",
      "0.0\n",
      "371 0 16\n",
      "0.0\n",
      "100 0 30\n",
      "1.0\n",
      "205 0 77\n",
      "0.0\n",
      "56 0 32\n",
      "0.0\n",
      "115 0 36\n",
      "1.0\n",
      "287 0 46\n",
      "0.0\n",
      "291 0 38\n",
      "1.0\n",
      "89 0 41\n",
      "0.0\n",
      "67 0 5\n",
      "0.0\n",
      "209 0 82\n",
      "0.0\n",
      "249 0 43\n",
      "1.0\n",
      "262 0 53\n",
      "0.0\n",
      "260 0 15\n",
      "0.0\n",
      "332 0 71\n",
      "0.0\n",
      "67 0 64\n",
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.6\n",
      "Accuracy: 0.6\n",
      "Percentage: 0.3\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CD6DD205E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CD6DD205E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD65731678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD65731678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 13s 118ms/step - loss: 1.2114 - accuracy: 0.6496\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 13s 120ms/step - loss: 0.5087 - accuracy: 0.7586\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 13s 118ms/step - loss: 0.4670 - accuracy: 0.7865\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 13s 116ms/step - loss: 0.4319 - accuracy: 0.8038\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 14s 125ms/step - loss: 0.4094 - accuracy: 0.8180\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 0.4015 - accuracy: 0.8223\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 0.3791 - accuracy: 0.8320\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 16s 140ms/step - loss: 0.3694 - accuracy: 0.8385\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 16s 140ms/step - loss: 0.3390 - accuracy: 0.8489\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 0.3423 - accuracy: 0.8491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB30D6168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB30D6168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "17/17 [==============================] - 0s 9ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "94 0 105\n",
      "0.0\n",
      "224 0 63\n",
      "1.0\n",
      "382 0 48\n",
      "0.0\n",
      "103 0 2\n",
      "1.0\n",
      "266 0 69\n",
      "1.0\n",
      "33 0 64\n",
      "1.0\n",
      "86 0 4\n",
      "0.0\n",
      "61 0 22\n",
      "0.0\n",
      "339 0 48\n",
      "0.0\n",
      "47 0 61\n",
      "1.0\n",
      "346 0 14\n",
      "1.0\n",
      "255 0 27\n",
      "0.0\n",
      "148 0 86\n",
      "0.0\n",
      "143 0 35\n",
      "0.0\n",
      "281 0 251\n",
      "0.0\n",
      "336 0 51\n",
      "0.0\n",
      "72 0 58\n",
      "1.0\n",
      "208 0 74\n",
      "0.0\n",
      "59 0 29\n",
      "0.0\n",
      "112 0 39\n",
      "1.0\n",
      "241 0 92\n",
      "0.0\n",
      "279 0 50\n",
      "1.0\n",
      "97 0 33\n",
      "0.0\n",
      "62 0 10\n",
      "0.0\n",
      "212 0 79\n",
      "0.0\n",
      "159 0 133\n",
      "1.0\n",
      "163 0 152\n",
      "0.0\n",
      "245 0 30\n",
      "0.0\n",
      "269 0 134\n",
      "0.0\n",
      "101 0 30\n",
      "0.0\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.6\n",
      "Accuracy: 0.6\n",
      "Percentage: 0.4\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEB31FBDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEB31FBDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CEDCD94DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CEDCD94DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 19s 168ms/step - loss: 0.8346 - accuracy: 0.6591\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.5064 - accuracy: 0.7606\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 18s 160ms/step - loss: 0.4802 - accuracy: 0.7767\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 18s 158ms/step - loss: 0.4417 - accuracy: 0.7932\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 19s 170ms/step - loss: 0.4346 - accuracy: 0.7970\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 15s 131ms/step - loss: 0.4445 - accuracy: 0.7954\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 15s 134ms/step - loss: 0.4226 - accuracy: 0.8110\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 17s 154ms/step - loss: 0.4005 - accuracy: 0.8082\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 0.3950 - accuracy: 0.8176\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 15s 133ms/step - loss: 0.3965 - accuracy: 0.8109\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB3160288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEB3160288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 10ms/step\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "17/17 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "169 0 30\n",
      "0.0\n",
      "168 0 119\n",
      "1.0\n",
      "405 0 25\n",
      "0.0\n",
      "105 0 0\n",
      "1.0\n",
      "249 0 86\n",
      "1.0\n",
      "58 0 39\n",
      "1.0\n",
      "87 0 3\n",
      "0.0\n",
      "73 0 10\n",
      "0.0\n",
      "376 0 11\n",
      "0.0\n",
      "69 0 39\n",
      "1.0\n",
      "355 0 5\n",
      "1.0\n",
      "250 0 32\n",
      "0.0\n",
      "204 0 30\n",
      "0.0\n",
      "150 0 28\n",
      "0.0\n",
      "366 0 166\n",
      "0.0\n",
      "362 0 25\n",
      "0.0\n",
      "64 0 66\n",
      "1.0\n",
      "223 0 59\n",
      "0.0\n",
      "87 0 1\n",
      "0.0\n",
      "123 0 28\n",
      "1.0\n",
      "317 0 16\n",
      "0.0\n",
      "303 0 26\n",
      "1.0\n",
      "126 0 4\n",
      "0.0\n",
      "70 0 2\n",
      "0.0\n",
      "269 0 22\n",
      "0.0\n",
      "257 0 35\n",
      "1.0\n",
      "246 0 69\n",
      "0.0\n",
      "260 0 15\n",
      "0.0\n",
      "363 0 40\n",
      "0.0\n",
      "119 0 12\n",
      "0.0\n",
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.7666666666666667\n",
      "Accuracy: 0.7666666666666667\n",
      "Percentage: 0.5\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEF73F9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEF73F9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CEBD38D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CEBD38D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 17s 144ms/step - loss: 1.0707 - accuracy: 0.6704\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 20s 180ms/step - loss: 0.5212 - accuracy: 0.7587\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 0.4773 - accuracy: 0.7801\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 14s 127ms/step - loss: 0.4728 - accuracy: 0.7900\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 16s 148ms/step - loss: 0.4367 - accuracy: 0.8009\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 17s 154ms/step - loss: 0.4269 - accuracy: 0.8111\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 16s 144ms/step - loss: 0.4059 - accuracy: 0.8193\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 16s 139ms/step - loss: 0.4115 - accuracy: 0.8202\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 16s 141ms/step - loss: 0.4037 - accuracy: 0.8249\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 0.4056 - accuracy: 0.8204\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CECC3ECD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CECC3ECD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 9ms/step\n",
      "9/9 [==============================] - 0s 13ms/step\n",
      "14/14 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 16ms/step\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "17/17 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 9ms/step\n",
      "11/11 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "115 0 84\n",
      "0.0\n",
      "126 0 161\n",
      "1.0\n",
      "333 0 97\n",
      "0.0\n",
      "51 0 54\n",
      "1.0\n",
      "239 0 96\n",
      "1.0\n",
      "4 0 93\n",
      "1.0\n",
      "81 0 9\n",
      "0.0\n",
      "31 0 52\n",
      "0.0\n",
      "291 0 96\n",
      "0.0\n",
      "26 0 82\n",
      "1.0\n",
      "250 0 110\n",
      "1.0\n",
      "238 0 44\n",
      "0.0\n",
      "139 0 95\n",
      "0.0\n",
      "107 0 71\n",
      "0.0\n",
      "223 0 309\n",
      "0.0\n",
      "338 0 49\n",
      "0.0\n",
      "43 0 87\n",
      "1.0\n",
      "176 0 106\n",
      "0.0\n",
      "42 0 46\n",
      "0.0\n",
      "66 0 85\n",
      "1.0\n",
      "185 0 148\n",
      "0.0\n",
      "186 0 143\n",
      "1.0\n",
      "62 0 68\n",
      "0.0\n",
      "60 0 12\n",
      "0.0\n",
      "130 0 161\n",
      "0.0\n",
      "112 0 180\n",
      "1.0\n",
      "177 0 138\n",
      "0.0\n",
      "226 0 49\n",
      "0.0\n",
      "291 0 112\n",
      "0.0\n",
      "67 0 64\n",
      "0.0\n",
      "[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.7333333333333333\n",
      "Accuracy: 0.7333333333333333\n",
      "Percentage: 0.6\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEE78F9C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEE78F9C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD48596EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD48596EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 17s 149ms/step - loss: 1.0575 - accuracy: 0.6821\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 16s 141ms/step - loss: 0.5027 - accuracy: 0.7666\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 13s 116ms/step - loss: 0.4696 - accuracy: 0.7820\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 13s 121ms/step - loss: 0.4292 - accuracy: 0.7997\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 14s 123ms/step - loss: 0.4131 - accuracy: 0.8088\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 13s 117ms/step - loss: 0.3889 - accuracy: 0.8278\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 13s 115ms/step - loss: 0.3730 - accuracy: 0.8363\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 13s 115ms/step - loss: 0.3946 - accuracy: 0.8213\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 13s 113ms/step - loss: 0.3814 - accuracy: 0.8333\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 0.3489 - accuracy: 0.8425\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD486A2EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD486A2EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "14/14 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "17/17 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "84 0 115\n",
      "0.0\n",
      "181 0 106\n",
      "1.0\n",
      "389 0 41\n",
      "0.0\n",
      "88 0 17\n",
      "1.0\n",
      "253 0 82\n",
      "1.0\n",
      "15 0 82\n",
      "1.0\n",
      "77 0 13\n",
      "0.0\n",
      "58 0 25\n",
      "0.0\n",
      "327 0 60\n",
      "0.0\n",
      "41 0 67\n",
      "1.0\n",
      "307 0 53\n",
      "1.0\n",
      "260 0 22\n",
      "0.0\n",
      "170 0 64\n",
      "0.0\n",
      "102 0 76\n",
      "0.0\n",
      "307 0 225\n",
      "0.0\n",
      "346 0 41\n",
      "0.0\n",
      "50 0 80\n",
      "1.0\n",
      "162 0 120\n",
      "0.0\n",
      "55 0 33\n",
      "0.0\n",
      "81 0 70\n",
      "1.0\n",
      "259 0 74\n",
      "0.0\n",
      "270 0 59\n",
      "1.0\n",
      "100 0 30\n",
      "0.0\n",
      "59 0 13\n",
      "0.0\n",
      "150 0 141\n",
      "0.0\n",
      "173 0 119\n",
      "1.0\n",
      "186 0 129\n",
      "0.0\n",
      "249 0 26\n",
      "0.0\n",
      "267 0 136\n",
      "0.0\n",
      "64 0 67\n",
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.7666666666666667\n",
      "Accuracy: 0.7666666666666667\n",
      "Percentage: 0.7\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CDF9E01288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CDF9E01288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD486A2678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD486A2678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 13s 118ms/step - loss: 0.8985 - accuracy: 0.6537\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 14s 121ms/step - loss: 0.5006 - accuracy: 0.7540\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 14s 125ms/step - loss: 0.4787 - accuracy: 0.7740\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 14s 126ms/step - loss: 0.4573 - accuracy: 0.7857\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 13s 118ms/step - loss: 0.4374 - accuracy: 0.7996\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 13s 117ms/step - loss: 0.4242 - accuracy: 0.8100\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 14s 125ms/step - loss: 0.4177 - accuracy: 0.8114\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 13s 117ms/step - loss: 0.3920 - accuracy: 0.8235\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 13s 120ms/step - loss: 0.3843 - accuracy: 0.8311\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 14s 129ms/step - loss: 0.3848 - accuracy: 0.8268\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD486870D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD486870D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "14/14 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "17/17 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 16ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "146 0 53\n",
      "0.0\n",
      "276 0 11\n",
      "1.0\n",
      "399 0 31\n",
      "0.0\n",
      "97 0 8\n",
      "1.0\n",
      "253 0 82\n",
      "1.0\n",
      "29 0 68\n",
      "1.0\n",
      "87 0 3\n",
      "0.0\n",
      "75 0 8\n",
      "0.0\n",
      "339 0 48\n",
      "0.0\n",
      "42 0 66\n",
      "1.0\n",
      "346 0 14\n",
      "1.0\n",
      "246 0 36\n",
      "0.0\n",
      "195 0 39\n",
      "0.0\n",
      "143 0 35\n",
      "0.0\n",
      "290 0 242\n",
      "0.0\n",
      "369 0 18\n",
      "0.0\n",
      "25 0 105\n",
      "1.0\n",
      "206 0 76\n",
      "0.0\n",
      "52 0 36\n",
      "0.0\n",
      "128 0 23\n",
      "1.0\n",
      "311 0 22\n",
      "0.0\n",
      "278 0 51\n",
      "1.0\n",
      "69 0 61\n",
      "0.0\n",
      "53 0 19\n",
      "0.0\n",
      "219 0 72\n",
      "0.0\n",
      "217 0 75\n",
      "1.0\n",
      "248 0 67\n",
      "0.0\n",
      "247 0 28\n",
      "0.0\n",
      "337 0 66\n",
      "0.0\n",
      "59 0 72\n",
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.7333333333333333\n",
      "Accuracy: 0.7333333333333333\n",
      "Percentage: 0.8\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CE9F7A8288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CE9F7A8288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CDB79CD0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CDB79CD0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.8944 - accuracy: 0.6784\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 21s 191ms/step - loss: 0.5121 - accuracy: 0.7544\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 16s 147ms/step - loss: 0.4714 - accuracy: 0.7743\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 17s 154ms/step - loss: 0.4448 - accuracy: 0.7895\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 15s 138ms/step - loss: 0.4232 - accuracy: 0.8044\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 16s 139ms/step - loss: 0.4086 - accuracy: 0.8145\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 16s 142ms/step - loss: 0.3892 - accuracy: 0.8210\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 15s 137ms/step - loss: 0.4097 - accuracy: 0.8093\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 15s 138ms/step - loss: 0.3845 - accuracy: 0.8223\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 13s 119ms/step - loss: 0.3853 - accuracy: 0.8220\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEBD2E0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEBD2E0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "14/14 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "17/17 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "104 0 95\n",
      "0.0\n",
      "250 0 37\n",
      "1.0\n",
      "393 0 37\n",
      "0.0\n",
      "97 0 8\n",
      "1.0\n",
      "240 0 95\n",
      "1.0\n",
      "26 0 71\n",
      "1.0\n",
      "89 0 1\n",
      "0.0\n",
      "38 0 45\n",
      "0.0\n",
      "281 0 106\n",
      "0.0\n",
      "53 0 55\n",
      "1.0\n",
      "301 0 59\n",
      "1.0\n",
      "245 0 37\n",
      "0.0\n",
      "179 0 55\n",
      "0.0\n",
      "131 0 47\n",
      "0.0\n",
      "396 0 136\n",
      "0.0\n",
      "377 0 10\n",
      "0.0\n",
      "59 0 71\n",
      "1.0\n",
      "188 0 94\n",
      "0.0\n",
      "74 0 14\n",
      "0.0\n",
      "110 0 41\n",
      "1.0\n",
      "254 0 79\n",
      "0.0\n",
      "289 0 40\n",
      "1.0\n",
      "126 0 4\n",
      "0.0\n",
      "57 0 15\n",
      "0.0\n",
      "192 0 99\n",
      "0.0\n",
      "274 0 18\n",
      "1.0\n",
      "231 0 84\n",
      "0.0\n",
      "248 0 27\n",
      "0.0\n",
      "247 0 156\n",
      "0.0\n",
      "83 0 48\n",
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.6666666666666666\n",
      "Accuracy: 0.6666666666666666\n",
      "Percentage: 0.9\n",
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEE78578B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CEE78578B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CEB9997D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CEB9997D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 15s 128ms/step - loss: 1.0103 - accuracy: 0.6768\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 13s 119ms/step - loss: 0.4959 - accuracy: 0.7683\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 13s 118ms/step - loss: 0.4612 - accuracy: 0.7872\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 13s 118ms/step - loss: 0.4320 - accuracy: 0.7959\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 13s 116ms/step - loss: 0.4100 - accuracy: 0.8103\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 13s 120ms/step - loss: 0.4378 - accuracy: 0.7989\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 13s 117ms/step - loss: 0.4028 - accuracy: 0.8075\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 13s 120ms/step - loss: 0.3911 - accuracy: 0.8204\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 13s 117ms/step - loss: 0.3720 - accuracy: 0.8309\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 13s 119ms/step - loss: 0.3791 - accuracy: 0.8291\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD6BFACA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD6BFACA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "17/17 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "167 0 32\n",
      "0.0\n",
      "152 0 135\n",
      "1.0\n",
      "389 0 41\n",
      "0.0\n",
      "101 0 4\n",
      "1.0\n",
      "264 0 71\n",
      "1.0\n",
      "52 0 45\n",
      "1.0\n",
      "79 0 11\n",
      "0.0\n",
      "56 0 27\n",
      "0.0\n",
      "340 0 47\n",
      "0.0\n",
      "65 0 43\n",
      "1.0\n",
      "345 0 15\n",
      "1.0\n",
      "229 0 53\n",
      "0.0\n",
      "202 0 32\n",
      "0.0\n",
      "127 0 51\n",
      "0.0\n",
      "403 0 129\n",
      "0.0\n",
      "358 0 29\n",
      "0.0\n",
      "44 0 86\n",
      "1.0\n",
      "200 0 82\n",
      "0.0\n",
      "87 0 1\n",
      "0.0\n",
      "122 0 29\n",
      "1.0\n",
      "301 0 32\n",
      "0.0\n",
      "301 0 28\n",
      "1.0\n",
      "124 0 6\n",
      "0.0\n",
      "66 0 6\n",
      "0.0\n",
      "237 0 54\n",
      "0.0\n",
      "272 0 20\n",
      "1.0\n",
      "236 0 79\n",
      "0.0\n",
      "245 0 30\n",
      "0.0\n",
      "364 0 39\n",
      "0.0\n",
      "118 0 13\n",
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy: 0.6666666666666666\n",
      "Accuracy: 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Percentage')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# experiment with different percentages\n",
    "percentages = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "accuracies = []\n",
    "for percentage in percentages:\n",
    "    print(f'Percentage: {percentage}')\n",
    "    accuracy, model = batchWindowClassification(accelData['Measurements'], accelData['Abnormal'], 1000, 500, batch_size=200, verbose=False, percentage=percentage)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "plt.plot(percentages, accuracies)\n",
    "plt.xlabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.6, 0.6, 0.7666666666666667, 0.7333333333333333, 0.7666666666666667, 0.7333333333333333, 0.6666666666666666, 0.6666666666666666]\n",
      "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "print(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CD3D6688B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CD3D6688B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD3A2AFB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CD3A2AFB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.9346 - accuracy: 0.6523\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.5183 - accuracy: 0.7448\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 14s 125ms/step - loss: 0.4934 - accuracy: 0.7643\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 14s 125ms/step - loss: 0.4686 - accuracy: 0.7786\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 14s 130ms/step - loss: 0.4241 - accuracy: 0.8015\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.4134 - accuracy: 0.8097\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 16s 140ms/step - loss: 0.4154 - accuracy: 0.8038\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 15s 132ms/step - loss: 0.4034 - accuracy: 0.8155\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.3990 - accuracy: 0.8188\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.3867 - accuracy: 0.8188\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CDB799B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CDB799B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "14/14 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "8/8 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "17/17 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "107 0 92\n",
      "0.0\n",
      "223 0 64\n",
      "1.0\n",
      "385 0 45\n",
      "0.0\n",
      "102 0 3\n",
      "1.0\n",
      "221 0 114\n",
      "1.0\n",
      "43 0 54\n",
      "1.0\n",
      "79 0 11\n",
      "0.0\n",
      "71 0 12\n",
      "0.0\n",
      "337 0 50\n",
      "0.0\n",
      "42 0 66\n",
      "1.0\n",
      "337 0 23\n",
      "1.0\n",
      "249 0 33\n",
      "0.0\n",
      "135 0 99\n",
      "0.0\n",
      "135 0 43\n",
      "0.0\n",
      "361 0 171\n",
      "0.0\n",
      "356 0 31\n",
      "0.0\n",
      "22 0 108\n",
      "1.0\n",
      "191 0 91\n",
      "0.0\n",
      "55 0 33\n",
      "0.0\n",
      "114 0 37\n",
      "1.0\n",
      "267 0 66\n",
      "0.0\n",
      "284 0 45\n",
      "1.0\n",
      "113 0 17\n",
      "0.0\n",
      "38 0 34\n",
      "0.0\n",
      "166 0 125\n",
      "0.0\n",
      "229 0 63\n",
      "1.0\n",
      "225 0 90\n",
      "0.0\n",
      "195 0 80\n",
      "0.0\n",
      "318 0 85\n",
      "0.0\n",
      "89 0 42\n",
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "True negatives:  20\n",
      "False positives:  0\n",
      "Accuracy: 0.7333333333333333\n",
      "Sensitivity: 0.6\n",
      "False Positive Rate: 0.0\n",
      "Specificity: 1.0\n",
      "Precision: 0.8571428571428572\n"
     ]
    }
   ],
   "source": [
    "results, model = batchWindowClassification(accelData['Measurements'], accelData['Abnormal'], 1000, 500, batch_size=200, verbose=False, percentage=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4388\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CF98271708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CF98271708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CF95A9C9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001CF95A9C9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "87/87 [==============================] - 14s 152ms/step - loss: 3.3563 - accuracy: 0.5745\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.5663 - accuracy: 0.6968\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 0.5254 - accuracy: 0.7554\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.4473 - accuracy: 0.7993\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 0.3706 - accuracy: 0.8561\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 0.2915 - accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 0.3122 - accuracy: 0.8931\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2228 - accuracy: 0.9177\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.1965 - accuracy: 0.9278\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.2618 - accuracy: 0.9292\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEC40B21F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CEC40B21F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "True negatives:  20\n",
      "False positives:  0\n",
      "Accuracy: 0.7\n",
      "Sensitivity: 0.55\n",
      "False Positive Rate: 0.0\n",
      "Specificity: 1.0\n",
      "Precision: 0.8448275862068966\n"
     ]
    }
   ],
   "source": [
    "results, model = batchWindowClassification(accelData['Measurements'], accelData['Abnormal'], 5000, 2500, batch_size=50, verbose=False, percentage=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001D0921BC048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001D0921BC048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D051926C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D051926C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.9284 - accuracy: 0.6755 - precision_2: 0.7016 - recall_2: 0.6055WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001CDF9DEEE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001CDF9DEEE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "89/89 [==============================] - 49s 549ms/step - loss: 0.9284 - accuracy: 0.6755 - precision_2: 0.7016 - recall_2: 0.6055 - val_loss: 0.8366 - val_accuracy: 0.5298 - val_precision_2: 0.5297 - val_recall_2: 0.5295\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - 21s 238ms/step - loss: 0.6442 - accuracy: 0.7446 - precision_2: 0.7492 - recall_2: 0.7350 - val_loss: 0.7975 - val_accuracy: 0.5420 - val_precision_2: 0.5429 - val_recall_2: 0.5390\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - 19s 219ms/step - loss: 0.6259 - accuracy: 0.7591 - precision_2: 0.7621 - recall_2: 0.7517 - val_loss: 0.8378 - val_accuracy: 0.5400 - val_precision_2: 0.5415 - val_recall_2: 0.5377\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - 19s 216ms/step - loss: 0.6212 - accuracy: 0.7642 - precision_2: 0.7671 - recall_2: 0.7573 - val_loss: 0.8175 - val_accuracy: 0.5804 - val_precision_2: 0.5813 - val_recall_2: 0.5755\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.6132 - accuracy: 0.7624 - precision_2: 0.7646 - recall_2: 0.7586 - val_loss: 0.8172 - val_accuracy: 0.6311 - val_precision_2: 0.6315 - val_recall_2: 0.6281\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - 20s 220ms/step - loss: 0.6073 - accuracy: 0.7658 - precision_2: 0.7681 - recall_2: 0.7611 - val_loss: 0.9993 - val_accuracy: 0.6021 - val_precision_2: 0.6022 - val_recall_2: 0.6010\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.6026 - accuracy: 0.7689 - precision_2: 0.7713 - recall_2: 0.7652 - val_loss: 0.9659 - val_accuracy: 0.6008 - val_precision_2: 0.6016 - val_recall_2: 0.5998\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - 19s 218ms/step - loss: 0.5989 - accuracy: 0.7701 - precision_2: 0.7720 - recall_2: 0.7662 - val_loss: 0.8230 - val_accuracy: 0.5985 - val_precision_2: 0.5980 - val_recall_2: 0.5944\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - 19s 218ms/step - loss: 0.5875 - accuracy: 0.7720 - precision_2: 0.7740 - recall_2: 0.7680 - val_loss: 0.9116 - val_accuracy: 0.5936 - val_precision_2: 0.5942 - val_recall_2: 0.5924\n",
      "Epoch 10/10\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.5871 - accuracy: 0.7736 - precision_2: 0.7756 - recall_2: 0.7705 - val_loss: 0.8897 - val_accuracy: 0.5856 - val_precision_2: 0.5855 - val_recall_2: 0.5839\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD424AC9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001CD424AC9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 8ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "14/14 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "17/17 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "True negatives:  20\n",
      "False positives:  0\n",
      "Accuracy: 0.7666666666666667\n",
      "Sensitivity: 0.65\n",
      "False Positive Rate: 0.0\n",
      "Specificity: 1.0\n",
      "Precision: 0.8703703703703703\n"
     ]
    }
   ],
   "source": [
    "results, model = batchWindowClassification(accelData['Measurements'], accelData['Abnormal'], 1000, 500, batch_size=250, verbose=False, percentage=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CD4316CDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001CD4316CDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D08E2B1708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D08E2B1708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.8411 - accuracy: 0.6685 - precision_3: 0.6839 - recall_3: 0.6304WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001D084232C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001D084232C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "149/149 [==============================] - 25s 159ms/step - loss: 0.8411 - accuracy: 0.6685 - precision_3: 0.6839 - recall_3: 0.6304 - val_loss: 0.8312 - val_accuracy: 0.5189 - val_precision_3: 0.5188 - val_recall_3: 0.5166\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 22s 147ms/step - loss: 0.6694 - accuracy: 0.7183 - precision_3: 0.7217 - recall_3: 0.7097 - val_loss: 0.8649 - val_accuracy: 0.5782 - val_precision_3: 0.5783 - val_recall_3: 0.5750\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 25s 171ms/step - loss: 0.6494 - accuracy: 0.7362 - precision_3: 0.7392 - recall_3: 0.7303 - val_loss: 0.8607 - val_accuracy: 0.5588 - val_precision_3: 0.5586 - val_recall_3: 0.5563\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 29s 195ms/step - loss: 0.6368 - accuracy: 0.7306 - precision_3: 0.7327 - recall_3: 0.7255 - val_loss: 0.9214 - val_accuracy: 0.5774 - val_precision_3: 0.5785 - val_recall_3: 0.5752\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 23s 154ms/step - loss: 0.6267 - accuracy: 0.7337 - precision_3: 0.7356 - recall_3: 0.7302 - val_loss: 0.8322 - val_accuracy: 0.5980 - val_precision_3: 0.5986 - val_recall_3: 0.5956\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 22s 146ms/step - loss: 0.6125 - accuracy: 0.7432 - precision_3: 0.7455 - recall_3: 0.7394 - val_loss: 0.8512 - val_accuracy: 0.5918 - val_precision_3: 0.5919 - val_recall_3: 0.5884\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 22s 145ms/step - loss: 0.6042 - accuracy: 0.7477 - precision_3: 0.7497 - recall_3: 0.7450 - val_loss: 0.8428 - val_accuracy: 0.5899 - val_precision_3: 0.5898 - val_recall_3: 0.5869\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 23s 155ms/step - loss: 0.5984 - accuracy: 0.7474 - precision_3: 0.7492 - recall_3: 0.7444 - val_loss: 0.8141 - val_accuracy: 0.5824 - val_precision_3: 0.5833 - val_recall_3: 0.5800\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 22s 145ms/step - loss: 0.5926 - accuracy: 0.7527 - precision_3: 0.7540 - recall_3: 0.7500 - val_loss: 0.8500 - val_accuracy: 0.5951 - val_precision_3: 0.5958 - val_recall_3: 0.5931\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 21s 139ms/step - loss: 0.5886 - accuracy: 0.7524 - precision_3: 0.7532 - recall_3: 0.7500 - val_loss: 0.8345 - val_accuracy: 0.6052 - val_precision_3: 0.6052 - val_recall_3: 0.6038\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001D067E38678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001D067E38678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "14/14 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "17/17 [==============================] - 0s 9ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "True negatives:  19\n",
      "False positives:  1\n",
      "Accuracy: 0.7\n",
      "Sensitivity: 0.575\n",
      "False Positive Rate: 0.050000000000000044\n",
      "Specificity: 0.95\n",
      "Precision: 0.6851851851851851\n"
     ]
    }
   ],
   "source": [
    "results, model = batchWindowClassification(accelData['Measurements'], accelData['Abnormal'], 1000, 500, batch_size=150, verbose=False, percentage=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101448\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001D0548AC0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x000001D0548AC0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D04D77FB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D04D77FB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 23/202 [==>...........................] - ETA: 3:04 - loss: 1.0305 - accuracy: 0.6243 - precision_5: 0.7045 - recall_5: 0.4465"
     ]
    }
   ],
   "source": [
    "# work out how many batches required for each trial if i want steps per epoch to be 100 (i.e. window number / batch size)\n",
    "# then use that number to calculate the number of windows to use for each trial\n",
    "# then use the same number of windows for each trial\n",
    "\n",
    "results, model = batchWindowClassification(accelData['Measurements'], accelData['Abnormal'], 100, 100, batch_size=500, verbose=False, percentage=0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
