{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holly-hewitt/Abnormal-Infant-Movement-Detection/blob/main/Code/AbnormalPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T4ilQacfTSVa"
      },
      "outputs": [],
      "source": [
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.enable_eager_execution(tf.ConfigProto(log_device_placement=False))\n",
        "#tf.test.gpu_device_name()\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Masking, LSTM, GRU\n",
        "from sklearn.model_selection import KFold\n",
        "# import early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from tensorflow.keras.layers import Input, Concatenate, Permute, Reshape, Multiply, Lambda, Add\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCwbTCmKTYQQ",
        "outputId": "ad0d662d-f7d6-45f3-b644-525c30e9d4ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def specificity_score(y_true, y_pred):\n",
        "\n",
        "    # Convert probabilities to binary predictions\n",
        "    y_pred_bin = np.argmax(y_pred, axis=1)\n",
        "    y_true_bin = np.argmax(y_true, axis=1)\n",
        "\n",
        "    tn = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n",
        "    fp = np.sum((y_true_bin == 0) & (y_pred_bin != 0))\n",
        "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
        "    return specificity\n",
        "\n",
        "def custom_performance_metric(accuracy, specificity, recall, precision, false_positive_rate, accuracy_weight=2):\n",
        "    \"\"\"\n",
        "    Calculate the custom performance metric including precision and with higher weight for accuracy.\n",
        "\n",
        "    Parameters:\n",
        "    - accuracy: The accuracy of the model.\n",
        "    - specificity: The specificity of the model.\n",
        "    - recall: The recall (sensitivity) of the model.\n",
        "    - precision: The precision of the model.\n",
        "    - false_positive_rate: The false positive rate of the model.\n",
        "    - accuracy_weight: The weight to give to accuracy in the metric calculation.\n",
        "\n",
        "    Returns:\n",
        "    - A float representing the custom performance metric.\n",
        "    \"\"\"\n",
        "    # Adjusted calculation to weight accuracy higher\n",
        "    weighted_accuracy = accuracy * accuracy_weight\n",
        "    total_weight = accuracy_weight + 1 + 1 + 1  # Adding the implicit weight of 1 for the other metrics\n",
        "    average_metric = (weighted_accuracy + specificity + recall + precision) / total_weight\n",
        "\n",
        "    # Subtract the false positive rate\n",
        "    custom_metric = average_metric - false_positive_rate\n",
        "\n",
        "    return custom_metric\n",
        "\n"
      ],
      "metadata": {
        "id": "g4GzeYlTUia-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BVVJb1gkTSVb"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(dataset_names, create_model_fn, class_weights):\n",
        "\n",
        "    dataset_results = {}\n",
        "\n",
        "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Find best dataset to train and test model on\n",
        "    #dataset_names = ['X_smoothed_mean_norm']\n",
        "\n",
        "    for dataset_name in dataset_names:\n",
        "\n",
        "        # Initialize variables to track the best model\n",
        "        best_model = None\n",
        "        best_performance = 0\n",
        "        best_model_details = ''\n",
        "\n",
        "\n",
        "         # Load in dataset from pickle\n",
        "        with open(f'drive/MyDrive/Pickles/{dataset_name}.pickle', 'rb') as handle:\n",
        "            dataset = pickle.load(handle)\n",
        "\n",
        "        dataset = np.array(dataset)\n",
        "\n",
        "        dataset_results[dataset_name] = {}\n",
        "\n",
        "        print(f'Working on dataset: {dataset_name}')\n",
        "\n",
        "        accuracies = []\n",
        "        sensitivities = []\n",
        "        false_positive_rates = []\n",
        "        specificities = []\n",
        "        precisions = []\n",
        "        performance = []\n",
        "\n",
        "        fold = 1\n",
        "\n",
        "        for train_index, test_index in outer_cv.split(dataset):\n",
        "\n",
        "            # Print current progress\n",
        "            print(f'Working on fold: {fold}')\n",
        "            fold += 1\n",
        "\n",
        "            X_train, X_test = dataset[train_index], dataset[test_index]\n",
        "            Y_train, Y_test = abnormal_encoded[train_index], abnormal_encoded[test_index]\n",
        "\n",
        "            X_train = X_train.astype('float32')\n",
        "            Y_train = Y_train.astype('float32')\n",
        "            X_test = X_test.astype('float32')\n",
        "            Y_test = Y_test.astype('float32')\n",
        "\n",
        "            model = create_model_fn(X_train.shape[1:])\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "            if class_weights:\n",
        "\n",
        "                Y_train_classes = np.argmax(Y_train, axis=1)\n",
        "\n",
        "                # Compute class weights\n",
        "                cw = class_weight.compute_class_weight('balanced',\n",
        "                                                    classes=np.unique(Y_train_classes),\n",
        "                                                    y=Y_train_classes)\n",
        "\n",
        "                class_weights_dict = dict(enumerate(cw))\n",
        "\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=15, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1, class_weight=class_weights_dict)\n",
        "\n",
        "            else:\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=15, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "            # Predict the test set\n",
        "            print('Predicting test set')\n",
        "            Y_pred = model.predict(X_test)\n",
        "\n",
        "            Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "            Y_test_classes = np.argmax(Y_test, axis=1)\n",
        "\n",
        "            # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
        "            accuracy = (accuracy_score(Y_test_classes, Y_pred_classes))\n",
        "            sensitivity = (recall_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "            false_positive_rate = (1 - specificity_score(Y_test, Y_pred))\n",
        "            specificity = (specificity_score(Y_test, Y_pred))\n",
        "            precision = (precision_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "\n",
        "            # Calculate the custom performance metric\n",
        "            model_performance = custom_performance_metric(accuracy, specificity, sensitivity, precision, false_positive_rate)\n",
        "\n",
        "            # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
        "            accuracies.append(accuracy)\n",
        "            sensitivities.append(sensitivity)\n",
        "            false_positive_rates.append(false_positive_rate)\n",
        "            specificities.append(specificity)\n",
        "            precisions.append(precision)\n",
        "            performance.append(model_performance)\n",
        "\n",
        "            print(f\"Model's custom performance metric: {model_performance}\")\n",
        "\n",
        "            # Update the best model if current model is better\n",
        "            if model_performance > best_performance:\n",
        "                best_performance = model_performance\n",
        "                best_model = model\n",
        "                best_model_details = f'{dataset_name}_fold_{fold}'\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        avg_sensitivity = np.mean(sensitivities)\n",
        "        avg_false_positive_rate = np.mean(false_positive_rates)\n",
        "        avg_specificity = np.mean(specificities)\n",
        "        avg_precision = np.mean(precisions)\n",
        "        avg_performance = np.mean(performance)\n",
        "\n",
        "        std_accuracy = np.std(accuracies)\n",
        "        std_sensitivity = np.std(sensitivities)\n",
        "        std_false_positive_rate = np.std(false_positive_rates)\n",
        "        std_specificity = np.std(specificities)\n",
        "        std_precision = np.std(precisions)\n",
        "        std_performance = np.std(performance)\n",
        "\n",
        "        dataset_results[dataset_name]['Accuracy'] = (avg_accuracy, std_accuracy)\n",
        "        dataset_results[dataset_name]['Sensitivity'] = (avg_sensitivity, std_sensitivity)\n",
        "        dataset_results[dataset_name]['False Positive Rate'] = (avg_false_positive_rate, std_false_positive_rate)\n",
        "        dataset_results[dataset_name]['Specificity'] = (avg_specificity, std_specificity)\n",
        "        dataset_results[dataset_name]['Precision'] = (avg_precision, std_precision)\n",
        "        dataset_results[dataset_name]['Performance'] = (avg_performance, std_performance)\n",
        "\n",
        "        if best_model:\n",
        "            model_save_path = f'models/best_model_{best_model_details}.keras'\n",
        "            print(f'Saving best model to {model_save_path}')\n",
        "            best_model.save(model_save_path)\n",
        "            print(f'Best Model Details: {best_model_details}, Performance: {best_performance}')\n",
        "\n",
        "        # Delete dataset to free up memory\n",
        "        del dataset\n",
        "        del Y_pred\n",
        "\n",
        "    for dataset_name, results in dataset_results.items():\n",
        "        print(f'Dataset: {dataset_name}')\n",
        "        for metric, (avg, std) in results.items():\n",
        "            print(f'{metric}: {avg} +/- {std}')\n",
        "        print('\\n')\n",
        "\n",
        "    return dataset_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gL1-AspcTSVb"
      },
      "outputs": [],
      "source": [
        "# Model functions\n",
        "\n",
        "def create_cnn_model(shape, filters=32, kernel_size=3, dropout_rate=0.8):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))  # Adjust the input_shape to match your dataset\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(19301, 16)))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)) )  # Reduced the number of neurons in the dense layer\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_lstm_model(shape, lstm_units=32, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(LSTM(lstm_units, return_sequences=False))  # 'return_sequences=False' because we only need the last output\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(lstm_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_gru_model(shape, gru_units=32, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(GRU(gru_units, return_sequences=False))  # return_sequences=False because we only need the last output\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(gru_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_lstm_model(shape, filters=32, kernel_size=3, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(LSTM(lstm_units, return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(lstm_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_gru_model(shape, filters=32, kernel_size=3, gru_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(GRU(gru_units, return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(gru_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_lstm_attention_model(shape, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    inputs = Input(shape=shape)\n",
        "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    attention = Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = Flatten()(attention)\n",
        "    attention = Activation('softmax')(attention)\n",
        "    attention = RepeatVector(lstm_units)(attention)\n",
        "    attention = Permute([2, 1])(attention)\n",
        "    sent_representation = Multiply()([lstm_out, attention])\n",
        "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(lstm_units,))(sent_representation)\n",
        "    dropout = Dropout(dropout_rate)(sent_representation)\n",
        "    dense = Dense(lstm_units, activation='relu')(dropout)\n",
        "    outputs = Dense(output_classes, activation='softmax')(dense)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Load in dataset from pickle\n",
        "with open('drive/MyDrive/Pickles/abnormal_encoded.pickle', 'rb') as handle:\n",
        "    abnormal_encoded = pickle.load(handle)\n",
        "dataset_results = {'X_smoothed_mean_norm_month': {}, 'X_smoothed_median_norm_month': {}, 'X_smoothed_mean_norm': {}, 'X_smoothed_median_norm': {}}"
      ],
      "metadata": {
        "id": "-YsRAY00UNnG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zVb3aj0TTSVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2684c2-9c55-4762-a129-add754ef9769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 73ms/step - loss: 64.3880 - accuracy: 0.5686 - val_loss: 51.4076 - val_accuracy: 0.2692\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 17.2277 - accuracy: 0.6471 - val_loss: 35.9825 - val_accuracy: 0.7308\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 11.8004 - accuracy: 0.6961 - val_loss: 19.0327 - val_accuracy: 0.6154\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 6.8147 - accuracy: 0.8529 - val_loss: 29.8845 - val_accuracy: 0.7308\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 2.4500 - accuracy: 0.9804 - val_loss: 19.6272 - val_accuracy: 0.7308\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 2.1828 - accuracy: 0.9608 - val_loss: 23.0009 - val_accuracy: 0.6923\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Model's custom performance metric: 0.560684666210982\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 45.3011 - accuracy: 0.4078 - val_loss: 31.9269 - val_accuracy: 0.1923\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 10.5797 - accuracy: 0.4272 - val_loss: 2.5670 - val_accuracy: 0.6923\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 3.0032 - accuracy: 0.6311 - val_loss: 2.8681 - val_accuracy: 0.8077\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 3.3687 - accuracy: 0.5728 - val_loss: 3.1248 - val_accuracy: 0.8077\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 3.2761 - accuracy: 0.5728 - val_loss: 3.1305 - val_accuracy: 0.8077\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "Model's custom performance metric: 0.628125\n",
            "Working on fold: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 185ms/step - loss: 47.2806 - accuracy: 0.4854 - val_loss: 9.2705 - val_accuracy: 0.6538\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 10.0177 - accuracy: 0.6602 - val_loss: 10.9711 - val_accuracy: 0.4615\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 5.4920 - accuracy: 0.7670 - val_loss: 12.7735 - val_accuracy: 0.7692\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 5.4368 - accuracy: 0.8738 - val_loss: 17.4143 - val_accuracy: 0.5385\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "Model's custom performance metric: -0.06999999999999995\n",
            "Working on fold: 4\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 94ms/step - loss: 56.4266 - accuracy: 0.5146 - val_loss: 117.9981 - val_accuracy: 0.3077\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 51.5782 - accuracy: 0.5728 - val_loss: 86.2441 - val_accuracy: 0.6923\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 17.5723 - accuracy: 0.7670 - val_loss: 42.1066 - val_accuracy: 0.5385\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 9.5699 - accuracy: 0.8155 - val_loss: 54.2412 - val_accuracy: 0.6923\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 6.7076 - accuracy: 0.8932 - val_loss: 34.3285 - val_accuracy: 0.6154\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 4.0674 - accuracy: 0.9126 - val_loss: 33.0882 - val_accuracy: 0.6154\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 2.1402 - accuracy: 0.9806 - val_loss: 35.9558 - val_accuracy: 0.6538\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 2.1915 - accuracy: 0.9806 - val_loss: 34.3381 - val_accuracy: 0.6154\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.8812 - accuracy: 1.0000 - val_loss: 31.4987 - val_accuracy: 0.6538\n",
            "Epoch 10/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.7745 - accuracy: 1.0000 - val_loss: 30.2515 - val_accuracy: 0.6154\n",
            "Epoch 11/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 1.6721 - accuracy: 1.0000 - val_loss: 29.5284 - val_accuracy: 0.6154\n",
            "Epoch 12/15\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.5761 - accuracy: 1.0000 - val_loss: 29.0643 - val_accuracy: 0.5769\n",
            "Epoch 13/15\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.4873 - accuracy: 1.0000 - val_loss: 28.7186 - val_accuracy: 0.5769\n",
            "Epoch 14/15\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.4058 - accuracy: 1.0000 - val_loss: 28.4193 - val_accuracy: 0.5769\n",
            "Epoch 15/15\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.3312 - accuracy: 1.0000 - val_loss: 28.1434 - val_accuracy: 0.5769\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Model's custom performance metric: 0.08522165387894287\n",
            "Working on fold: 5\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 22.3545 - accuracy: 0.5922 - val_loss: 17.1284 - val_accuracy: 0.7308\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 12.8587 - accuracy: 0.6796 - val_loss: 21.0933 - val_accuracy: 0.6538\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 4.7565 - accuracy: 0.8641 - val_loss: 25.6790 - val_accuracy: 0.5769\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 3.2567 - accuracy: 0.9417 - val_loss: 31.4517 - val_accuracy: 0.6538\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "Model's custom performance metric: 0.25651266174485987\n",
            "Saving best model to models/best_model_X_smoothed_mean_norm_fold_3.keras\n",
            "Best Model Details: X_smoothed_mean_norm_fold_3, Performance: 0.628125\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 37.4450 - accuracy: 0.5196 - val_loss: 14.2714 - val_accuracy: 0.3846\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 8.1744 - accuracy: 0.6667 - val_loss: 5.8863 - val_accuracy: 0.4615\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 3.1256 - accuracy: 0.7941 - val_loss: 5.4883 - val_accuracy: 0.6538\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 2.3706 - accuracy: 0.9608 - val_loss: 6.5279 - val_accuracy: 0.6154\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 2.2781 - accuracy: 0.9804 - val_loss: 8.0098 - val_accuracy: 0.6538\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 2.1523 - accuracy: 1.0000 - val_loss: 8.3953 - val_accuracy: 0.6538\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Model's custom performance metric: 0.46424452740242217\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 68ms/step - loss: 51.0776 - accuracy: 0.4466 - val_loss: 32.0326 - val_accuracy: 0.7692\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 16.6966 - accuracy: 0.7087 - val_loss: 58.1496 - val_accuracy: 0.7692\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 27.7076 - accuracy: 0.7379 - val_loss: 106.7913 - val_accuracy: 0.1923\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 32.1284 - accuracy: 0.6408 - val_loss: 47.2848 - val_accuracy: 0.7692\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "Model's custom performance metric: 0.6992965367965368\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 45.7417 - accuracy: 0.5243 - val_loss: 93.5714 - val_accuracy: 0.2308\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 32.9067 - accuracy: 0.6311 - val_loss: 42.2168 - val_accuracy: 0.2308\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 15.0366 - accuracy: 0.6602 - val_loss: 37.1939 - val_accuracy: 0.6923\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 9.5427 - accuracy: 0.7573 - val_loss: 19.8377 - val_accuracy: 0.5385\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 8.3835 - accuracy: 0.8252 - val_loss: 19.2202 - val_accuracy: 0.5769\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 7.5602 - accuracy: 0.8058 - val_loss: 21.2503 - val_accuracy: 0.6154\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 7.1614 - accuracy: 0.8641 - val_loss: 16.6817 - val_accuracy: 0.5769\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 4.7419 - accuracy: 0.8447 - val_loss: 19.2615 - val_accuracy: 0.5769\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 3.3494 - accuracy: 0.9612 - val_loss: 27.2852 - val_accuracy: 0.6923\n",
            "Epoch 10/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 2.0876 - accuracy: 1.0000 - val_loss: 18.8329 - val_accuracy: 0.5385\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Model's custom performance metric: 0.1386274509803921\n",
            "Working on fold: 4\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 99ms/step - loss: 73.3279 - accuracy: 0.4369 - val_loss: 109.7915 - val_accuracy: 0.3077\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 42.4471 - accuracy: 0.5825 - val_loss: 23.9585 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 13.3704 - accuracy: 0.7670 - val_loss: 53.5718 - val_accuracy: 0.6538\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 7.4419 - accuracy: 0.8252 - val_loss: 26.3081 - val_accuracy: 0.5769\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 3.0708 - accuracy: 0.9320 - val_loss: 25.1949 - val_accuracy: 0.5385\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "Model's custom performance metric: 0.5243177112742331\n",
            "Working on fold: 5\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 38.9581 - accuracy: 0.5437 - val_loss: 38.2001 - val_accuracy: 0.2308\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 11.5813 - accuracy: 0.7767 - val_loss: 25.0019 - val_accuracy: 0.6538\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 8.6992 - accuracy: 0.8350 - val_loss: 31.3767 - val_accuracy: 0.6923\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 3.8840 - accuracy: 0.9223 - val_loss: 38.8879 - val_accuracy: 0.6923\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 2.9960 - accuracy: 0.9612 - val_loss: 31.3818 - val_accuracy: 0.5769\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "Model's custom performance metric: 0.08447447805032937\n",
            "Saving best model to models/best_model_X_smoothed_mean_norm_month_fold_3.keras\n",
            "Best Model Details: X_smoothed_mean_norm_month_fold_3, Performance: 0.6992965367965368\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 67.6338 - accuracy: 0.4314 - val_loss: 56.5720 - val_accuracy: 0.2308\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 31.1650 - accuracy: 0.6667 - val_loss: 49.7528 - val_accuracy: 0.7308\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 16.5686 - accuracy: 0.6961 - val_loss: 24.7538 - val_accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 9.1338 - accuracy: 0.8431 - val_loss: 35.7336 - val_accuracy: 0.7308\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 3.4759 - accuracy: 0.9608 - val_loss: 23.5898 - val_accuracy: 0.8077\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 3.0490 - accuracy: 0.9706 - val_loss: 20.9600 - val_accuracy: 0.6923\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 2.3984 - accuracy: 0.9804 - val_loss: 23.5739 - val_accuracy: 0.8077\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.1101 - accuracy: 1.0000 - val_loss: 29.8432 - val_accuracy: 0.7308\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.2119 - accuracy: 0.9902 - val_loss: 23.0552 - val_accuracy: 0.8077\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Model's custom performance metric: 0.560684666210982\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 83ms/step - loss: 62.3097 - accuracy: 0.5340 - val_loss: 17.9244 - val_accuracy: 0.6923\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 26.0278 - accuracy: 0.6990 - val_loss: 68.9953 - val_accuracy: 0.3462\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 19.9299 - accuracy: 0.7476 - val_loss: 36.1138 - val_accuracy: 0.8077\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 4.8903 - accuracy: 0.9612 - val_loss: 31.7159 - val_accuracy: 0.6538\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "Model's custom performance metric: -0.15195887445887452\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 21.2685 - accuracy: 0.4951 - val_loss: 12.3361 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 6.9741 - accuracy: 0.7573 - val_loss: 14.7131 - val_accuracy: 0.6923\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 3.5319 - accuracy: 0.8641 - val_loss: 13.4266 - val_accuracy: 0.6923\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.6320 - accuracy: 0.9612 - val_loss: 10.0297 - val_accuracy: 0.6538\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 2.2146 - accuracy: 1.0000 - val_loss: 10.6825 - val_accuracy: 0.6538\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 2.1280 - accuracy: 1.0000 - val_loss: 10.9964 - val_accuracy: 0.6538\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.0131 - accuracy: 1.0000 - val_loss: 10.8871 - val_accuracy: 0.6538\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "Model's custom performance metric: 0.10414979757085019\n",
            "Working on fold: 4\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 61ms/step - loss: 33.8678 - accuracy: 0.3883 - val_loss: 13.5457 - val_accuracy: 0.6538\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 18.2910 - accuracy: 0.6796 - val_loss: 27.9276 - val_accuracy: 0.3846\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 18.8256 - accuracy: 0.6117 - val_loss: 41.0171 - val_accuracy: 0.6538\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 13.0690 - accuracy: 0.8155 - val_loss: 16.4359 - val_accuracy: 0.6154\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "Model's custom performance metric: 0.32880434782608703\n",
            "Working on fold: 5\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 65ms/step - loss: 48.1066 - accuracy: 0.3495 - val_loss: 20.1706 - val_accuracy: 0.7692\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 6.1558 - accuracy: 0.8252 - val_loss: 14.5737 - val_accuracy: 0.6154\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 5.9343 - accuracy: 0.8544 - val_loss: 22.5064 - val_accuracy: 0.7308\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 4.2614 - accuracy: 0.8641 - val_loss: 20.4379 - val_accuracy: 0.5385\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 4.3908 - accuracy: 0.9223 - val_loss: 18.0283 - val_accuracy: 0.6923\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Model's custom performance metric: 0.34749263894000726\n",
            "Saving best model to models/best_model_X_smoothed_median_norm_fold_2.keras\n",
            "Best Model Details: X_smoothed_median_norm_fold_2, Performance: 0.560684666210982\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 66.4857 - accuracy: 0.4804 - val_loss: 66.9743 - val_accuracy: 0.7308\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 41.8682 - accuracy: 0.5588 - val_loss: 40.4234 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 21.8001 - accuracy: 0.7255 - val_loss: 46.7746 - val_accuracy: 0.6154\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 16.6983 - accuracy: 0.6961 - val_loss: 29.1354 - val_accuracy: 0.5769\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 10.3839 - accuracy: 0.8725 - val_loss: 37.2304 - val_accuracy: 0.6923\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 5.4483 - accuracy: 0.8824 - val_loss: 20.2141 - val_accuracy: 0.6154\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 2.9037 - accuracy: 0.9314 - val_loss: 27.4506 - val_accuracy: 0.6538\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.9651 - accuracy: 1.0000 - val_loss: 29.4935 - val_accuracy: 0.6538\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.8610 - accuracy: 1.0000 - val_loss: 30.3780 - val_accuracy: 0.6538\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Model's custom performance metric: 0.6308313397129186\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 65ms/step - loss: 77.2756 - accuracy: 0.4951 - val_loss: 41.9221 - val_accuracy: 0.2692\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 47.2305 - accuracy: 0.5728 - val_loss: 89.0154 - val_accuracy: 0.8077\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 50.9673 - accuracy: 0.6893 - val_loss: 71.1878 - val_accuracy: 0.2308\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 23.9728 - accuracy: 0.6699 - val_loss: 51.2353 - val_accuracy: 0.7692\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Model's custom performance metric: 0.7285329485329486\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 65ms/step - loss: 35.9290 - accuracy: 0.5922 - val_loss: 12.3056 - val_accuracy: 0.6154\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 5.3171 - accuracy: 0.7282 - val_loss: 8.5107 - val_accuracy: 0.5385\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 4.5042 - accuracy: 0.7767 - val_loss: 13.9655 - val_accuracy: 0.2692\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4.1750 - accuracy: 0.7767 - val_loss: 8.9612 - val_accuracy: 0.5769\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 2.5099 - accuracy: 0.9320 - val_loss: 13.8678 - val_accuracy: 0.6923\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "Model's custom performance metric: 0.675\n",
            "Working on fold: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 2s 67ms/step - loss: 44.7753 - accuracy: 0.4272 - val_loss: 2.3558 - val_accuracy: 0.3077\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 2.6432 - accuracy: 0.4175 - val_loss: 3.0114 - val_accuracy: 0.3077\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 3.1443 - accuracy: 0.4175 - val_loss: 3.3281 - val_accuracy: 0.3077\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 3.3545 - accuracy: 0.4175 - val_loss: 3.4045 - val_accuracy: 0.3077\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Model's custom performance metric: -0.759375\n",
            "Working on fold: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 67ms/step - loss: 54.6418 - accuracy: 0.5146 - val_loss: 37.5831 - val_accuracy: 0.6923\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 16.0118 - accuracy: 0.6796 - val_loss: 46.2857 - val_accuracy: 0.7692\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 14.2701 - accuracy: 0.7573 - val_loss: 19.3205 - val_accuracy: 0.6154\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 4.1637 - accuracy: 0.9126 - val_loss: 33.5229 - val_accuracy: 0.7692\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 2.0522 - accuracy: 0.9903 - val_loss: 23.9545 - val_accuracy: 0.7308\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 2.2402 - accuracy: 0.9612 - val_loss: 27.7600 - val_accuracy: 0.7308\n",
            "Predicting test set\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "Model's custom performance metric: 0.4343807167491378\n",
            "Saving best model to models/best_model_X_smoothed_median_norm_month_fold_3.keras\n",
            "Best Model Details: X_smoothed_median_norm_month_fold_3, Performance: 0.7285329485329486\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.571780303030303 +/- 0.06068413531686176\n",
            "Sensitivity: 0.5741133770882054 +/- 0.041083970538887404\n",
            "False Positive Rate: 0.3002887653917402 +/- 0.2275876257053818\n",
            "Specificity: 0.6997112346082599 +/- 0.22758762570538182\n",
            "Precision: 0.5446025910364145 +/- 0.1110441589031245\n",
            "Performance: 0.29210879636695697 +/- 0.26841462027976565\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.628030303030303 +/- 0.09090396134518065\n",
            "Sensitivity: 0.622805141083173 +/- 0.05938043901539091\n",
            "False Positive Rate: 0.26797700773673316 +/- 0.17048314200308384\n",
            "Specificity: 0.7320229922632667 +/- 0.17048314200308382\n",
            "Precision: 0.6399570037805333 +/- 0.06475619221642041\n",
            "Performance: 0.38219214090078274 +/- 0.23471132683795062\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.578030303030303 +/- 0.0850789955939561\n",
            "Sensitivity: 0.6261566903729375 +/- 0.1065891962742793\n",
            "False Positive Rate: 0.36898768660782394 +/- 0.1897016612019043\n",
            "Specificity: 0.6310123133921761 +/- 0.1897016612019043\n",
            "Precision: 0.6208813993024519 +/- 0.08106928326172003\n",
            "Performance: 0.23783451521781043 +/- 0.24262857412405145\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5596590909090909 +/- 0.1794591276931789\n",
            "Sensitivity: 0.5364600311968732 +/- 0.06167120099852799\n",
            "False Positive Rate: 0.2411027568922306 +/- 0.38380870878952517\n",
            "Specificity: 0.7588972431077694 +/- 0.38380870878952517\n",
            "Precision: 0.5002083333333334 +/- 0.23053875626733444\n",
            "Performance: 0.341874000999001 +/- 0.5595143020826685\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cnn_dataset_result_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_cnn_model, True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_dataset_result_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_cnn_model, False)\n"
      ],
      "metadata": {
        "id": "oAqA0aGXUBTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dataset_results_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_lstm_model, True)\n"
      ],
      "metadata": {
        "id": "MBAgX9CTT5ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dataset_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_lstm_model, False)\n"
      ],
      "metadata": {
        "id": "YrOkYfJUWFVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_dataset_results_cw = c(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_gru_model, True)\n"
      ],
      "metadata": {
        "id": "bm2O6QumT5q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_dataset_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_gru_model, False)\n"
      ],
      "metadata": {
        "id": "V5dVcbIDWX9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_lstm_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'],create_cnn_lstm_model,False)"
      ],
      "metadata": {
        "id": "ftl5SgVVXONE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_gru_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'],create_cnn_gru_model,False)"
      ],
      "metadata": {
        "id": "NuboM1_Rmr0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_attention_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'],create_lstm_attention_model,False)"
      ],
      "metadata": {
        "id": "Rd9JnSlY1Xys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_and_evaluate_warped(dataset_names, create_model_fn, class_weights):\n",
        "\n",
        "    dataset_results = {}\n",
        "\n",
        "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Find best dataset to train and test model on\n",
        "    #dataset_names = ['X_smoothed_mean_norm']\n",
        "\n",
        "    for dataset_name in dataset_names:\n",
        "\n",
        "        # Initialize variables to track the best model\n",
        "        best_model = None\n",
        "        best_performance = 0\n",
        "        best_model_details = ''\n",
        "\n",
        "\n",
        "         # Load in warped dataset from pickle\n",
        "        with open(f'drive/MyDrive/Pickles/{dataset_name}.pickle', 'rb') as handle:\n",
        "            dataset = pickle.load(handle)\n",
        "\n",
        "        # Load in smoothed mean dataset from pickle\n",
        "        with open(f'drive/MyDrive/Pickles/X_smoothed_mean_norm.pickle', 'rb') as handle:\n",
        "            unwarped = pickle.load(handle)\n",
        "\n",
        "        dataset = np.array(dataset)\n",
        "        unwarped = np.array(unwarped)\n",
        "\n",
        "        dataset_results[dataset_name] = {}\n",
        "\n",
        "        print(f'Working on dataset: {dataset_name}')\n",
        "\n",
        "        accuracies = []\n",
        "        sensitivities = []\n",
        "        false_positive_rates = []\n",
        "        specificities = []\n",
        "        precisions = []\n",
        "        performance = []\n",
        "\n",
        "        fold = 0\n",
        "\n",
        "        unwarped_split = list(outer_cv.split(unwarped))\n",
        "\n",
        "        for train_index, test_index in outer_cv.split(dataset):\n",
        "\n",
        "            unwarped_train_index, unwarped_test_index = unwarped_split[fold]\n",
        "\n",
        "            # Print current progress\n",
        "            print(f'Working on fold: {fold}')\n",
        "            fold += 1\n",
        "\n",
        "            X_train, X_test_warped = dataset[train_index], dataset[test_index]\n",
        "            Y_train, Y_test_warped = abnormal_encoded_warped[train_index], abnormal_encoded_warped[test_index]\n",
        "\n",
        "            X_test = unwarped[unwarped_test_index]\n",
        "            Y_test = abnormal_encoded[unwarped_test_index]\n",
        "\n",
        "            X_train_unwarped, X_val, Y_train_unwarped, Y_val = train_test_split(\n",
        "                unwarped[unwarped_train_index], abnormal_encoded[unwarped_train_index], test_size=0.2, random_state=42)\n",
        "\n",
        "            X_train = X_train.astype('float32')\n",
        "            Y_train = Y_train.astype('float32')\n",
        "            X_test = X_test.astype('float32')\n",
        "            Y_test = Y_test.astype('float32')\n",
        "\n",
        "            model = create_model_fn(X_train.shape[1:])\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "            if class_weights:\n",
        "\n",
        "                Y_train_classes = np.argmax(Y_train, axis=1)\n",
        "\n",
        "                # Compute class weights\n",
        "                cw = class_weight.compute_class_weight('balanced',\n",
        "                                                    classes=np.unique(Y_train_classes),\n",
        "                                                    y=Y_train_classes)\n",
        "\n",
        "                class_weights_dict = dict(enumerate(cw))\n",
        "\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=15, batch_size=16, callbacks=[early_stopping], verbose=1, class_weight=class_weights_dict, validation_data = (X_val, Y_val))\n",
        "\n",
        "            else:\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=15, batch_size=16,  callbacks=[early_stopping], verbose=1, validation_data = (X_val, Y_val))\n",
        "\n",
        "            # Predict the test set\n",
        "            print('Predicting test set')\n",
        "            Y_pred = model.predict(X_test)\n",
        "\n",
        "            Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "            Y_test_classes = np.argmax(Y_test, axis=1)\n",
        "\n",
        "            # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
        "            accuracy = (accuracy_score(Y_test_classes, Y_pred_classes))\n",
        "            sensitivity = (recall_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "            false_positive_rate = (1 - specificity_score(Y_test, Y_pred))\n",
        "            specificity = (specificity_score(Y_test, Y_pred))\n",
        "            precision = (precision_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "\n",
        "            # Calculate the custom performance metric\n",
        "            model_performance = custom_performance_metric(accuracy, specificity, sensitivity, precision, false_positive_rate)\n",
        "\n",
        "            # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
        "            accuracies.append(accuracy)\n",
        "            sensitivities.append(sensitivity)\n",
        "            false_positive_rates.append(false_positive_rate)\n",
        "            specificities.append(specificity)\n",
        "            precisions.append(precision)\n",
        "            performance.append(model_performance)\n",
        "\n",
        "            print(f\"Model's custom performance metric: {model_performance}\")\n",
        "\n",
        "            # Update the best model if current model is better\n",
        "            '''if model_performance > best_performance:\n",
        "                best_performance = model_performance\n",
        "                best_model = model\n",
        "                best_model_details = f'{dataset_name}_fold_{fold}'''\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        avg_sensitivity = np.mean(sensitivities)\n",
        "        avg_false_positive_rate = np.mean(false_positive_rates)\n",
        "        avg_specificity = np.mean(specificities)\n",
        "        avg_precision = np.mean(precisions)\n",
        "        avg_performance = np.mean(performance)\n",
        "\n",
        "        std_accuracy = np.std(accuracies)\n",
        "        std_sensitivity = np.std(sensitivities)\n",
        "        std_false_positive_rate = np.std(false_positive_rates)\n",
        "        std_specificity = np.std(specificities)\n",
        "        std_precision = np.std(precisions)\n",
        "        std_performance = np.std(performance)\n",
        "\n",
        "        dataset_results[dataset_name]['Accuracy'] = (avg_accuracy, std_accuracy)\n",
        "        dataset_results[dataset_name]['Sensitivity'] = (avg_sensitivity, std_sensitivity)\n",
        "        dataset_results[dataset_name]['False Positive Rate'] = (avg_false_positive_rate, std_false_positive_rate)\n",
        "        dataset_results[dataset_name]['Specificity'] = (avg_specificity, std_specificity)\n",
        "        dataset_results[dataset_name]['Precision'] = (avg_precision, std_precision)\n",
        "        dataset_results[dataset_name]['Performance'] = (avg_performance, std_performance)\n",
        "\n",
        "        '''if best_model:\n",
        "            model_save_path = f'models/best_model_{best_model_details}.keras'\n",
        "            print(f'Saving best model to {model_save_path}')\n",
        "            best_model.save(model_save_path)\n",
        "            print(f'Best Model Details: {best_model_details}, Performance: {best_performance}')'''\n",
        "\n",
        "        # Delete dataset to free up memory\n",
        "        del dataset\n",
        "        del Y_pred\n",
        "\n",
        "    for dataset_name, results in dataset_results.items():\n",
        "        print(f'Dataset: {dataset_name}')\n",
        "        for metric, (avg, std) in results.items():\n",
        "            print(f'{metric}: {avg} +/- {std}')\n",
        "        print('\\n')\n",
        "\n",
        "    return dataset_results"
      ],
      "metadata": {
        "id": "5_sEsPccoaxr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Load in dataset from pickle\n",
        "with open('drive/MyDrive/Pickles/labels_magnitude_warped.pickle', 'rb') as handle:\n",
        "    abnormal_encoded_warped = pickle.load(handle)\n",
        "\n",
        "\n",
        "\n",
        "# Use the sklearn OneHotEncoder to one-hot encode the data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Create the OneHotEncoder object\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# One-hot encode the data\n",
        "abnormal_encoded_warped = onehot_encoder.fit_transform(np.array(abnormal_encoded_warped).reshape(-1, 1))\n",
        "\n",
        "print(abnormal_encoded_warped)"
      ],
      "metadata": {
        "id": "-pz-NfcpokD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warped_cnn_dataset_result_ncw = train_and_evaluate_warped(['X_magnitude_warped'], create_cnn_model, False)\n"
      ],
      "metadata": {
        "id": "By284i0YpadH",
        "outputId": "bbcd1912-5021-4d41-e65a-2c48cfd8d819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_magnitude_warped\n",
            "Working on fold: 0\n",
            "Fitting model\n",
            "Epoch 1/15\n",
            "17/17 [==============================] - 2s 81ms/step - loss: 12.9067 - accuracy: 0.6187 - val_loss: 160.0587 - val_accuracy: 0.6538\n",
            "Epoch 2/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 3.3571 - accuracy: 0.8988 - val_loss: 158.9882 - val_accuracy: 0.5769\n",
            "Epoch 3/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 2.0006 - accuracy: 0.9689 - val_loss: 150.6693 - val_accuracy: 0.6154\n",
            "Epoch 4/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 1.6626 - accuracy: 0.9844 - val_loss: 144.0360 - val_accuracy: 0.6923\n",
            "Epoch 5/15\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 1.4010 - accuracy: 0.9883 - val_loss: 135.3915 - val_accuracy: 0.6923\n",
            "Epoch 6/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 1.1464 - accuracy: 1.0000 - val_loss: 128.4753 - val_accuracy: 0.6923\n",
            "Epoch 7/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.9659 - accuracy: 1.0000 - val_loss: 121.8124 - val_accuracy: 0.6923\n",
            "Epoch 8/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.8099 - accuracy: 1.0000 - val_loss: 115.4622 - val_accuracy: 0.6923\n",
            "Epoch 9/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.6840 - accuracy: 1.0000 - val_loss: 109.4218 - val_accuracy: 0.6923\n",
            "Epoch 10/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.5824 - accuracy: 1.0000 - val_loss: 103.6692 - val_accuracy: 0.6923\n",
            "Epoch 11/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.4992 - accuracy: 1.0000 - val_loss: 98.2040 - val_accuracy: 0.6923\n",
            "Epoch 12/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.4304 - accuracy: 1.0000 - val_loss: 93.0143 - val_accuracy: 0.6923\n",
            "Epoch 13/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.3728 - accuracy: 1.0000 - val_loss: 88.0803 - val_accuracy: 0.6923\n",
            "Epoch 14/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.3243 - accuracy: 1.0000 - val_loss: 83.3965 - val_accuracy: 0.6923\n",
            "Epoch 15/15\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.2830 - accuracy: 1.0000 - val_loss: 78.9567 - val_accuracy: 0.6923\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Model's custom performance metric: 0.28450216450216437\n",
            "Working on fold: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/15\n",
            "17/17 [==============================] - 2s 38ms/step - loss: 9.6305 - accuracy: 0.5992 - val_loss: 115.4482 - val_accuracy: 0.6538\n",
            "Epoch 2/15\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 2.3849 - accuracy: 0.9144 - val_loss: 102.8027 - val_accuracy: 0.2692\n",
            "Epoch 3/15\n",
            "10/17 [================>.............] - ETA: 0s - loss: 2.0414 - accuracy: 0.9625"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b1489857e750>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwarped_cnn_dataset_result_ncw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_warped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_magnitude_warped'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_cnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-572a0024d1c4>\u001b[0m in \u001b[0;36mtrain_and_evaluate_warped\u001b[0;34m(dataset_names, create_model_fn, class_weights)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m#Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Predict the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}