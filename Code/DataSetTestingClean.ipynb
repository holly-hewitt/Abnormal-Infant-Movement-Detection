{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holly-hewitt/Abnormal-Infant-Movement-Detection/blob/main/Code/DataSetTestingClean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T4ilQacfTSVa"
      },
      "outputs": [],
      "source": [
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.enable_eager_execution(tf.ConfigProto(log_device_placement=False))\n",
        "#tf.test.gpu_device_name()\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Masking, LSTM, GRU\n",
        "from sklearn.model_selection import KFold\n",
        "# import early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from tensorflow.keras.layers import Input, Concatenate, Permute, Reshape, Multiply, Lambda, Add\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCwbTCmKTYQQ",
        "outputId": "7d511abb-9bcb-4138-829c-2e117cf341e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def specificity_score(y_true, y_pred):\n",
        "\n",
        "    # Convert probabilities to binary predictions\n",
        "    y_pred_bin = np.argmax(y_pred, axis=1)\n",
        "    y_true_bin = np.argmax(y_true, axis=1)\n",
        "\n",
        "    tn = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n",
        "    fp = np.sum((y_true_bin == 0) & (y_pred_bin != 0))\n",
        "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
        "    return specificity"
      ],
      "metadata": {
        "id": "g4GzeYlTUia-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BVVJb1gkTSVb"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(dataset_names, create_model_fn, class_weights):\n",
        "\n",
        "    outer_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    # Find best dataset to train and test model on\n",
        "    #dataset_names = ['X_smoothed_mean_norm']\n",
        "\n",
        "    for dataset_name in dataset_names:\n",
        "\n",
        "         # Load in dataset from pickle\n",
        "        with open(f'drive/MyDrive/Pickles/{dataset_name}.pickle', 'rb') as handle:\n",
        "            dataset = pickle.load(handle)\n",
        "\n",
        "        dataset = np.array(dataset)\n",
        "\n",
        "        print(f'Working on dataset: {dataset_name}')\n",
        "\n",
        "        accuracies = []\n",
        "        sensitivities = []\n",
        "        false_positive_rates = []\n",
        "        specificities = []\n",
        "        precisions = []\n",
        "\n",
        "        fold = 1\n",
        "\n",
        "        for train_index, test_index in outer_cv.split(dataset):\n",
        "\n",
        "            # Print current progress\n",
        "            print(f'Working on fold: {fold}')\n",
        "            fold += 1\n",
        "\n",
        "            X_train, X_test = dataset[train_index], dataset[test_index]\n",
        "            Y_train, Y_test = abnormal_encoded[train_index], abnormal_encoded[test_index]\n",
        "\n",
        "            X_train = X_train.astype('float32')\n",
        "            Y_train = Y_train.astype('float32')\n",
        "            X_test = X_test.astype('float32')\n",
        "            Y_test = Y_test.astype('float32')\n",
        "\n",
        "            model = create_model_fn(X_train.shape[1:])\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "            if class_weights:\n",
        "\n",
        "                Y_train_classes = np.argmax(Y_train, axis=1)\n",
        "\n",
        "                # Compute class weights\n",
        "                cw = class_weight.compute_class_weight('balanced',\n",
        "                                                    classes=np.unique(Y_train_classes),\n",
        "                                                    y=Y_train_classes)\n",
        "\n",
        "                class_weights_dict = dict(enumerate(cw))\n",
        "\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=5, batch_size=4, validation_split=0.2, callbacks=[early_stopping], verbose=1, class_weight=class_weights_dict)\n",
        "\n",
        "            else:\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=5, batch_size=4, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "            # Predict the test set\n",
        "            print('Predicting test set')\n",
        "            Y_pred = model.predict(X_test)\n",
        "\n",
        "            Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "            Y_test_classes = np.argmax(Y_test, axis=1)\n",
        "\n",
        "            # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
        "            accuracies.append(accuracy_score(Y_test_classes, Y_pred_classes))\n",
        "            sensitivities.append(recall_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "            false_positive_rates.append(1 - specificity_score(Y_test, Y_pred))\n",
        "            specificities.append(specificity_score(Y_test, Y_pred))\n",
        "            precisions.append(precision_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "\n",
        "\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        avg_sensitivity = np.mean(sensitivities)\n",
        "        avg_false_positive_rate = np.mean(false_positive_rates)\n",
        "        avg_specificity = np.mean(specificities)\n",
        "        avg_precision = np.mean(precisions)\n",
        "\n",
        "        std_accuracy = np.std(accuracies)\n",
        "        std_sensitivity = np.std(sensitivities)\n",
        "        std_false_positive_rate = np.std(false_positive_rates)\n",
        "        std_specificity = np.std(specificities)\n",
        "        std_precision = np.std(precisions)\n",
        "\n",
        "        dataset_results[dataset_name]['Accuracy'] = (avg_accuracy, std_accuracy)\n",
        "        dataset_results[dataset_name]['Sensitivity'] = (avg_sensitivity, std_sensitivity)\n",
        "        dataset_results[dataset_name]['False Positive Rate'] = (avg_false_positive_rate, std_false_positive_rate)\n",
        "        dataset_results[dataset_name]['Specificity'] = (avg_specificity, std_specificity)\n",
        "        dataset_results[dataset_name]['Precision'] = (avg_precision, std_precision)\n",
        "\n",
        "        for dataset_name, results in dataset_results.items():\n",
        "            print(f'Dataset: {dataset_name}')\n",
        "            for metric, (avg, std) in results.items():\n",
        "                print(f'{metric}: {avg} +/- {std}')\n",
        "            print('\\n')\n",
        "\n",
        "\n",
        "        # Delete dataset to free up memory\n",
        "        del dataset\n",
        "        del Y_pred\n",
        "    return dataset_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gL1-AspcTSVb"
      },
      "outputs": [],
      "source": [
        "# Model functions\n",
        "\n",
        "def create_cnn_model(shape, filters=32, kernel_size=3, dropout_rate=0.5):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))  # Adjust the input_shape to match your dataset\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(19301, 16)))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation='relu'))  # Reduced the number of neurons in the dense layer\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_lstm_model(shape, lstm_units=32, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(LSTM(lstm_units, return_sequences=False))  # 'return_sequences=False' because we only need the last output\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(lstm_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_gru_model(shape, gru_units=32, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(GRU(gru_units, return_sequences=False))  # return_sequences=False because we only need the last output\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(gru_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_lstm_model(shape, filters=32, kernel_size=3, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(LSTM(lstm_units, return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(lstm_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_gru_model(shape, filters=32, kernel_size=3, gru_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(GRU(gru_units, return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(gru_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_lstm_attention_model(shape, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    inputs = Input(shape=shape)\n",
        "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    attention = Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = Flatten()(attention)\n",
        "    attention = Activation('softmax')(attention)\n",
        "    attention = RepeatVector(lstm_units)(attention)\n",
        "    attention = Permute([2, 1])(attention)\n",
        "    sent_representation = Multiply()([lstm_out, attention])\n",
        "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(lstm_units,))(sent_representation)\n",
        "    dropout = Dropout(dropout_rate)(sent_representation)\n",
        "    dense = Dense(lstm_units, activation='relu')(dropout)\n",
        "    outputs = Dense(output_classes, activation='softmax')(dense)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Load in dataset from pickle\n",
        "with open('drive/MyDrive/Pickles/abnormal_encoded.pickle', 'rb') as handle:\n",
        "    abnormal_encoded = pickle.load(handle)\n",
        "dataset_results = {'X_smoothed_mean_norm_month': {}, 'X_smoothed_median_norm_month': {}, 'X_smoothed_mean_norm': {}, 'X_smoothed_median_norm': {}}"
      ],
      "metadata": {
        "id": "-YsRAY00UNnG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVb3aj0TTSVb",
        "outputId": "7633eea4-d805-4412-e30d-011155573867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 30ms/step - loss: 22.3467 - accuracy: 0.4235 - val_loss: 10.9162 - val_accuracy: 0.5909\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 7.6254 - accuracy: 0.7412 - val_loss: 26.1706 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.9040 - accuracy: 0.9059 - val_loss: 27.9859 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.5618 - accuracy: 0.9059 - val_loss: 28.5547 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 21ms/step - loss: 46.1282 - accuracy: 0.5412 - val_loss: 6.0454 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.9497 - accuracy: 0.7176 - val_loss: 10.0646 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.4074 - accuracy: 0.7412 - val_loss: 6.0894 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.5195 - accuracy: 0.9529 - val_loss: 6.3230 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 26ms/step - loss: 46.0135 - accuracy: 0.4651 - val_loss: 37.8708 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 6.9466 - accuracy: 0.8023 - val_loss: 21.8819 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.0126 - accuracy: 0.9419 - val_loss: 38.5756 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.5546 - accuracy: 0.9767 - val_loss: 26.5844 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9489 - accuracy: 0.9419 - val_loss: 32.0481 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 54ms/step - loss: 76.3911 - accuracy: 0.5176 - val_loss: 79.9712 - val_accuracy: 0.2727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 54.5821 - accuracy: 0.4824 - val_loss: 37.4107 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 7.3997 - accuracy: 0.7294 - val_loss: 38.2822 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.5012 - accuracy: 0.9294 - val_loss: 36.6740 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.1571 - accuracy: 0.9765 - val_loss: 25.2022 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 35ms/step - loss: 55.8808 - accuracy: 0.5529 - val_loss: 30.1985 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 15.5205 - accuracy: 0.6235 - val_loss: 8.4225 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.5697 - accuracy: 0.9176 - val_loss: 7.8450 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8415 - accuracy: 0.9059 - val_loss: 10.1286 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8877 - accuracy: 0.9059 - val_loss: 15.2040 - val_accuracy: 0.3636\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 5s 96ms/step - loss: 66.0465 - accuracy: 0.4651 - val_loss: 42.9594 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 26.9324 - accuracy: 0.7326 - val_loss: 60.9355 - val_accuracy: 0.4545\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.6442 - accuracy: 0.8023 - val_loss: 44.1150 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 4.0480 - accuracy: 0.9070 - val_loss: 46.5847 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 27ms/step - loss: 26.0726 - accuracy: 0.4471 - val_loss: 8.8134 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.9932 - accuracy: 0.7882 - val_loss: 18.1387 - val_accuracy: 0.5455\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.5853 - accuracy: 0.8706 - val_loss: 20.8299 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.6966 - accuracy: 0.9294 - val_loss: 21.7234 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 23ms/step - loss: 19.2372 - accuracy: 0.5176 - val_loss: 36.9696 - val_accuracy: 0.3182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 5.4883 - accuracy: 0.8588 - val_loss: 8.4544 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.8579 - accuracy: 0.8353 - val_loss: 5.5356 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7122 - accuracy: 0.8824 - val_loss: 6.2783 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6620 - accuracy: 0.9412 - val_loss: 12.1920 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 32ms/step - loss: 6.3287 - accuracy: 0.5465 - val_loss: 7.3701 - val_accuracy: 0.2727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.6477 - accuracy: 0.6977 - val_loss: 3.3907 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8953 - val_loss: 2.4375 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0794 - accuracy: 0.9767 - val_loss: 2.3532 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.4417 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 31.8793 - accuracy: 0.5529 - val_loss: 1.6784 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7180 - accuracy: 0.6824 - val_loss: 0.6530 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3003 - accuracy: 0.9059 - val_loss: 0.9127 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1814 - accuracy: 0.9647 - val_loss: 0.7232 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 30.2546 - accuracy: 0.5294 - val_loss: 122.6305 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 27.8967 - accuracy: 0.7529 - val_loss: 55.0733 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 21.1827 - accuracy: 0.8118 - val_loss: 33.1586 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.1159 - accuracy: 0.9529 - val_loss: 55.8359 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.9184 - accuracy: 0.8706 - val_loss: 43.5183 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 22ms/step - loss: 37.7312 - accuracy: 0.5930 - val_loss: 32.8900 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 22.5131 - accuracy: 0.6744 - val_loss: 45.5256 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.0733 - accuracy: 0.8140 - val_loss: 26.8875 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.1225 - accuracy: 0.8953 - val_loss: 28.1037 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.5288 - accuracy: 0.8953 - val_loss: 27.9516 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "cnn_dataset_result_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_cnn_model, True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_dataset_result_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_cnn_model, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAqA0aGXUBTp",
        "outputId": "6c9bd3e8-d462-44b8-92e9-d0462a4fb256"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 15.8563 - accuracy: 0.5529 - val_loss: 5.4335 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.6145 - accuracy: 0.8000 - val_loss: 8.6626 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.8578 - accuracy: 0.8824 - val_loss: 19.0609 - val_accuracy: 0.4091\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1123 - accuracy: 0.9412 - val_loss: 19.5823 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 25ms/step - loss: 30.6900 - accuracy: 0.4588 - val_loss: 8.9566 - val_accuracy: 0.7727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.8553 - accuracy: 0.8824 - val_loss: 5.5423 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.9529 - val_loss: 4.0455 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.9529 - val_loss: 5.3524 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2669 - accuracy: 0.9529 - val_loss: 8.9192 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 17.3586 - accuracy: 0.5698 - val_loss: 44.6831 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.9374 - accuracy: 0.7674 - val_loss: 14.6169 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.8936 - accuracy: 0.8837 - val_loss: 13.4980 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1422 - accuracy: 0.9767 - val_loss: 18.8622 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2587 - accuracy: 0.9651 - val_loss: 22.1837 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 41.3797 - accuracy: 0.4941 - val_loss: 11.2520 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.3222 - accuracy: 0.7529 - val_loss: 8.0133 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.3902 - accuracy: 0.7412 - val_loss: 14.1096 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1232 - accuracy: 0.8941 - val_loss: 15.6849 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.9176 - val_loss: 10.7852 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 27ms/step - loss: 23.9669 - accuracy: 0.5176 - val_loss: 15.2598 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.7404 - accuracy: 0.7294 - val_loss: 8.8192 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0465 - accuracy: 0.9294 - val_loss: 9.1877 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.7265 - accuracy: 0.9647 - val_loss: 11.5666 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 12.3177 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 35.9553 - accuracy: 0.6047 - val_loss: 52.3138 - val_accuracy: 0.5909\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.4408 - accuracy: 0.7326 - val_loss: 66.6741 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.5184 - accuracy: 0.8372 - val_loss: 51.5205 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 12.5526 - accuracy: 0.8372 - val_loss: 28.4660 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.5182 - accuracy: 0.9186 - val_loss: 37.3039 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 30.5103 - accuracy: 0.5176 - val_loss: 31.7640 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.0701 - accuracy: 0.8000 - val_loss: 20.5982 - val_accuracy: 0.5455\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 3.0367 - accuracy: 0.9059 - val_loss: 19.4865 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.7986 - accuracy: 0.8941 - val_loss: 19.7983 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.1228 - accuracy: 0.9765 - val_loss: 18.7418 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 28ms/step - loss: 26.6241 - accuracy: 0.4824 - val_loss: 18.2730 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.3390 - accuracy: 0.8235 - val_loss: 13.8726 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 3.4191 - accuracy: 0.9294 - val_loss: 52.9660 - val_accuracy: 0.3182\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.6003 - accuracy: 0.8706 - val_loss: 19.5940 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.2060 - accuracy: 0.9882 - val_loss: 29.3516 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 21ms/step - loss: 20.9521 - accuracy: 0.5581 - val_loss: 22.4353 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.4225 - accuracy: 0.8256 - val_loss: 24.4814 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.2947 - accuracy: 0.9070 - val_loss: 29.1618 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0421 - accuracy: 0.9884 - val_loss: 21.1498 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.3703e-07 - accuracy: 1.0000 - val_loss: 20.1069 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 26.7900 - accuracy: 0.5176 - val_loss: 1.0789 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0694 - accuracy: 0.6824 - val_loss: 1.0791 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0744 - accuracy: 0.6706 - val_loss: 1.0643 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0611 - accuracy: 0.6706 - val_loss: 1.0496 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0479 - accuracy: 0.6706 - val_loss: 1.0365 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 29ms/step - loss: 99.9923 - accuracy: 0.4824 - val_loss: 36.3889 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 21.3106 - accuracy: 0.7412 - val_loss: 19.0500 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.9842 - accuracy: 0.8941 - val_loss: 64.2622 - val_accuracy: 0.1818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.1491 - accuracy: 0.7529 - val_loss: 30.6916 - val_accuracy: 0.8182\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.5561 - accuracy: 0.8471 - val_loss: 41.8483 - val_accuracy: 0.4091\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 32.6569 - accuracy: 0.4419 - val_loss: 9.9448 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.4041 - accuracy: 0.7442 - val_loss: 10.2015 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.7982 - accuracy: 0.7907 - val_loss: 11.9288 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.8071 - accuracy: 0.9070 - val_loss: 14.3448 - val_accuracy: 0.4545\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dataset_results_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_lstm_model, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBAgX9CTT5ec",
        "outputId": "e3117448-bcdb-4e56-f2ad-5a7c02dcd7a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 19s 539ms/step - loss: 1.0659 - accuracy: 0.4824 - val_loss: 0.8730 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 512ms/step - loss: 0.8162 - accuracy: 0.6471 - val_loss: 0.8216 - val_accuracy: 0.2727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 9s 428ms/step - loss: 0.7692 - accuracy: 0.5529 - val_loss: 0.8627 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.7146 - accuracy: 0.5765 - val_loss: 0.7524 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.7599 - accuracy: 0.5647 - val_loss: 0.8375 - val_accuracy: 0.2727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 188ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 524ms/step - loss: 0.9982 - accuracy: 0.4588 - val_loss: 0.8210 - val_accuracy: 0.5909\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 9s 425ms/step - loss: 0.8482 - accuracy: 0.5294 - val_loss: 0.7614 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.7796 - accuracy: 0.5529 - val_loss: 0.7631 - val_accuracy: 0.4091\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7328 - accuracy: 0.5765 - val_loss: 0.7401 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.6885 - accuracy: 0.5765 - val_loss: 0.7358 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 529ms/step - loss: 1.0734 - accuracy: 0.3721 - val_loss: 0.8975 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.9002 - accuracy: 0.5349 - val_loss: 0.7638 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.8624 - accuracy: 0.5000 - val_loss: 0.7015 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 448ms/step - loss: 0.7549 - accuracy: 0.5698 - val_loss: 0.6869 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 436ms/step - loss: 0.7003 - accuracy: 0.5698 - val_loss: 0.6571 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 191ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 494ms/step - loss: 0.8677 - accuracy: 0.4471 - val_loss: 0.7278 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.7254 - accuracy: 0.6235 - val_loss: 0.6742 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.7732 - accuracy: 0.5765 - val_loss: 0.6625 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.6505 - accuracy: 0.6353 - val_loss: 0.6817 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 12s 531ms/step - loss: 0.6792 - accuracy: 0.5647 - val_loss: 0.6801 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 188ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 503ms/step - loss: 0.9392 - accuracy: 0.4706 - val_loss: 0.8371 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 452ms/step - loss: 0.7524 - accuracy: 0.5647 - val_loss: 0.6903 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.7115 - accuracy: 0.6235 - val_loss: 0.7292 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.6498 - accuracy: 0.6118 - val_loss: 0.7373 - val_accuracy: 0.5455\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.6602 - accuracy: 0.6588 - val_loss: 0.7272 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 206ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 532ms/step - loss: 1.0808 - accuracy: 0.4535 - val_loss: 0.9228 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.9825 - accuracy: 0.5000 - val_loss: 0.8795 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8102 - accuracy: 0.5930 - val_loss: 0.8396 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 515ms/step - loss: 0.7258 - accuracy: 0.5814 - val_loss: 0.8177 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 9s 434ms/step - loss: 0.7039 - accuracy: 0.6395 - val_loss: 0.7597 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 190ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 513ms/step - loss: 1.0076 - accuracy: 0.5882 - val_loss: 0.7936 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.8280 - accuracy: 0.6118 - val_loss: 0.7046 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.8139 - accuracy: 0.5176 - val_loss: 0.6906 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.7146 - accuracy: 0.5176 - val_loss: 0.6971 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.6723 - accuracy: 0.6706 - val_loss: 0.6560 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 198ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 560ms/step - loss: 1.1668 - accuracy: 0.2941 - val_loss: 1.0379 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 433ms/step - loss: 0.9518 - accuracy: 0.5529 - val_loss: 0.9931 - val_accuracy: 0.1818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.8586 - accuracy: 0.5294 - val_loss: 0.9224 - val_accuracy: 0.1818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.8062 - accuracy: 0.5412 - val_loss: 0.8242 - val_accuracy: 0.2273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7988 - accuracy: 0.5176 - val_loss: 0.7873 - val_accuracy: 0.2273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 197ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 537ms/step - loss: 1.0776 - accuracy: 0.5465 - val_loss: 0.9313 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.9343 - accuracy: 0.5233 - val_loss: 0.9278 - val_accuracy: 0.1818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.7833 - accuracy: 0.5116 - val_loss: 0.8477 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 523ms/step - loss: 0.7651 - accuracy: 0.5814 - val_loss: 0.7430 - val_accuracy: 0.5455\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 9s 430ms/step - loss: 0.7284 - accuracy: 0.6512 - val_loss: 0.7805 - val_accuracy: 0.4091\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 507ms/step - loss: 1.0633 - accuracy: 0.5882 - val_loss: 0.8215 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 456ms/step - loss: 0.8842 - accuracy: 0.6471 - val_loss: 0.7586 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.7663 - accuracy: 0.6000 - val_loss: 0.7284 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.7444 - accuracy: 0.6118 - val_loss: 0.7137 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6663 - accuracy: 0.6353 - val_loss: 0.7203 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 558ms/step - loss: 1.0385 - accuracy: 0.4235 - val_loss: 0.9636 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 9s 426ms/step - loss: 0.8059 - accuracy: 0.5176 - val_loss: 0.8143 - val_accuracy: 0.5455\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.7563 - accuracy: 0.5765 - val_loss: 0.6983 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6792 - accuracy: 0.6000 - val_loss: 0.6909 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.7249 - accuracy: 0.5765 - val_loss: 0.7853 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 579ms/step - loss: 0.9671 - accuracy: 0.5465 - val_loss: 0.8391 - val_accuracy: 0.4545\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.7895 - accuracy: 0.6047 - val_loss: 0.8320 - val_accuracy: 0.3182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.7160 - accuracy: 0.5581 - val_loss: 0.7657 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.7299 - accuracy: 0.5698 - val_loss: 0.7461 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.7133 - accuracy: 0.5698 - val_loss: 0.7359 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 190ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dataset_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_lstm_model, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrOkYfJUWFVU",
        "outputId": "3112742e-b5ad-46ce-e358-7e3026210d8e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 537ms/step - loss: 0.9327 - accuracy: 0.5765 - val_loss: 0.6746 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.7313 - accuracy: 0.6588 - val_loss: 0.6212 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 436ms/step - loss: 0.7432 - accuracy: 0.6471 - val_loss: 0.6027 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.6954 - accuracy: 0.6588 - val_loss: 0.6037 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6717 - accuracy: 0.6706 - val_loss: 0.5987 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 271ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.1442 - accuracy: 0.4000 - val_loss: 0.9542 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8762 - accuracy: 0.5412 - val_loss: 0.7848 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 444ms/step - loss: 0.7804 - accuracy: 0.5059 - val_loss: 0.6480 - val_accuracy: 0.7727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 446ms/step - loss: 0.7752 - accuracy: 0.4824 - val_loss: 0.6296 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.6755 - accuracy: 0.6235 - val_loss: 0.6434 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 194ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 556ms/step - loss: 1.1507 - accuracy: 0.3953 - val_loss: 0.9789 - val_accuracy: 0.3182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 436ms/step - loss: 0.8904 - accuracy: 0.5930 - val_loss: 0.7810 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.7641 - accuracy: 0.6279 - val_loss: 0.6741 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7487 - accuracy: 0.5581 - val_loss: 0.6571 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.6925 - accuracy: 0.6279 - val_loss: 0.6404 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 195ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 507ms/step - loss: 0.8953 - accuracy: 0.5882 - val_loss: 0.6715 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.7497 - accuracy: 0.6471 - val_loss: 0.6446 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.6525 - accuracy: 0.6824 - val_loss: 0.6414 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.6721 - accuracy: 0.6588 - val_loss: 0.6517 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6600 - accuracy: 0.6706 - val_loss: 0.6722 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 497ms/step - loss: 1.0404 - accuracy: 0.4118 - val_loss: 0.7738 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 442ms/step - loss: 0.8157 - accuracy: 0.5882 - val_loss: 0.6784 - val_accuracy: 0.8182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.7581 - accuracy: 0.5882 - val_loss: 0.6159 - val_accuracy: 0.7727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6800 - accuracy: 0.6824 - val_loss: 0.6582 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6236 - accuracy: 0.6353 - val_loss: 0.7021 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 195ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 523ms/step - loss: 1.0899 - accuracy: 0.4070 - val_loss: 0.7938 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.8500 - accuracy: 0.5698 - val_loss: 0.6715 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.7139 - accuracy: 0.6279 - val_loss: 0.6555 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 434ms/step - loss: 0.6998 - accuracy: 0.6395 - val_loss: 0.6682 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 458ms/step - loss: 0.6606 - accuracy: 0.6395 - val_loss: 0.6892 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 598ms/step - loss: 0.8939 - accuracy: 0.6471 - val_loss: 0.6836 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.7541 - accuracy: 0.6706 - val_loss: 0.6142 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.7006 - accuracy: 0.6353 - val_loss: 0.5998 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 443ms/step - loss: 0.6816 - accuracy: 0.6353 - val_loss: 0.5971 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6753 - accuracy: 0.5882 - val_loss: 0.6252 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 196ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 599ms/step - loss: 1.0389 - accuracy: 0.3765 - val_loss: 0.8271 - val_accuracy: 0.7727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.8565 - accuracy: 0.5647 - val_loss: 0.7638 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.7969 - accuracy: 0.4588 - val_loss: 0.7289 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.7480 - accuracy: 0.5412 - val_loss: 0.6802 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.7209 - accuracy: 0.5765 - val_loss: 0.6900 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 529ms/step - loss: 0.9257 - accuracy: 0.5581 - val_loss: 0.7363 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 439ms/step - loss: 0.7672 - accuracy: 0.6163 - val_loss: 0.6571 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 456ms/step - loss: 0.7944 - accuracy: 0.6279 - val_loss: 0.6392 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.6632 - accuracy: 0.6395 - val_loss: 0.6254 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 476ms/step - loss: 0.7031 - accuracy: 0.6163 - val_loss: 0.6257 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 268ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 546ms/step - loss: 1.1009 - accuracy: 0.3176 - val_loss: 0.9155 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.7847 - accuracy: 0.7059 - val_loss: 0.7166 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 442ms/step - loss: 0.6975 - accuracy: 0.6824 - val_loss: 0.6516 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 461ms/step - loss: 0.6636 - accuracy: 0.6588 - val_loss: 0.6527 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6715 - accuracy: 0.7176 - val_loss: 0.6677 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 197ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 538ms/step - loss: 0.8927 - accuracy: 0.5176 - val_loss: 0.7964 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 511ms/step - loss: 0.7713 - accuracy: 0.5176 - val_loss: 0.7066 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 437ms/step - loss: 0.7302 - accuracy: 0.5647 - val_loss: 0.7123 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6979 - accuracy: 0.6235 - val_loss: 0.6758 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.6805 - accuracy: 0.5765 - val_loss: 0.7105 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 275ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.0611 - accuracy: 0.4070 - val_loss: 0.8673 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.8221 - accuracy: 0.5465 - val_loss: 0.7347 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 446ms/step - loss: 0.7845 - accuracy: 0.5233 - val_loss: 0.6943 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.6865 - accuracy: 0.6744 - val_loss: 0.6614 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.6393 - accuracy: 0.6628 - val_loss: 0.7210 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 276ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_dataset_results_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_gru_model, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm2O6QumT5q6",
        "outputId": "ef13c022-cbe9-41e8-bc1b-fa51fe18e304"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 519ms/step - loss: 0.9785 - accuracy: 0.5294 - val_loss: 0.7485 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.9469 - accuracy: 0.4353 - val_loss: 0.7703 - val_accuracy: 0.4545\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7939 - accuracy: 0.4824 - val_loss: 0.7746 - val_accuracy: 0.3182\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.7175 - accuracy: 0.5882 - val_loss: 0.7024 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 509ms/step - loss: 0.7059 - accuracy: 0.6118 - val_loss: 0.7018 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 196ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 520ms/step - loss: 1.2310 - accuracy: 0.4000 - val_loss: 0.8971 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.9657 - accuracy: 0.5529 - val_loss: 0.9118 - val_accuracy: 0.2727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 472ms/step - loss: 0.8814 - accuracy: 0.5294 - val_loss: 1.0553 - val_accuracy: 0.1818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.8079 - accuracy: 0.5059 - val_loss: 0.9417 - val_accuracy: 0.2273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 209ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 614ms/step - loss: 1.1093 - accuracy: 0.3837 - val_loss: 0.9494 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.9535 - accuracy: 0.5233 - val_loss: 0.8861 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.8813 - accuracy: 0.4884 - val_loss: 0.8690 - val_accuracy: 0.3636\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.7917 - accuracy: 0.5465 - val_loss: 0.7847 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.7615 - accuracy: 0.5814 - val_loss: 0.7740 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 201ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 523ms/step - loss: 0.9479 - accuracy: 0.6471 - val_loss: 0.7712 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.8284 - accuracy: 0.5412 - val_loss: 0.7937 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.7464 - accuracy: 0.5647 - val_loss: 0.7742 - val_accuracy: 0.3636\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.7576 - accuracy: 0.5882 - val_loss: 0.7289 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 524ms/step - loss: 0.6866 - accuracy: 0.6588 - val_loss: 0.7736 - val_accuracy: 0.3182\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 535ms/step - loss: 1.0456 - accuracy: 0.4000 - val_loss: 0.7881 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 472ms/step - loss: 0.7993 - accuracy: 0.5412 - val_loss: 0.8057 - val_accuracy: 0.3182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.8643 - accuracy: 0.4471 - val_loss: 0.7474 - val_accuracy: 0.4091\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 455ms/step - loss: 0.7650 - accuracy: 0.5647 - val_loss: 0.7913 - val_accuracy: 0.3182\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 458ms/step - loss: 0.7170 - accuracy: 0.5529 - val_loss: 0.6800 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 297ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 532ms/step - loss: 1.0865 - accuracy: 0.4884 - val_loss: 0.9031 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.9153 - accuracy: 0.5814 - val_loss: 0.9020 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 9s 429ms/step - loss: 0.7486 - accuracy: 0.5930 - val_loss: 0.7968 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 465ms/step - loss: 0.7884 - accuracy: 0.5814 - val_loss: 0.7637 - val_accuracy: 0.5455\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.7864 - accuracy: 0.5581 - val_loss: 0.7952 - val_accuracy: 0.4545\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 278ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 531ms/step - loss: 1.0923 - accuracy: 0.5882 - val_loss: 0.7512 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.9041 - accuracy: 0.5176 - val_loss: 0.7436 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 512ms/step - loss: 0.7671 - accuracy: 0.6353 - val_loss: 0.6605 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 9s 432ms/step - loss: 0.8389 - accuracy: 0.5294 - val_loss: 0.6699 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.7121 - accuracy: 0.5765 - val_loss: 0.6641 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 189ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 543ms/step - loss: 0.9767 - accuracy: 0.4941 - val_loss: 1.0417 - val_accuracy: 0.1364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8983 - accuracy: 0.4941 - val_loss: 0.9671 - val_accuracy: 0.1364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.8323 - accuracy: 0.4824 - val_loss: 0.8741 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 459ms/step - loss: 0.7543 - accuracy: 0.5412 - val_loss: 0.8623 - val_accuracy: 0.2727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.7842 - accuracy: 0.4471 - val_loss: 0.7904 - val_accuracy: 0.3182\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 289ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 537ms/step - loss: 1.1121 - accuracy: 0.3605 - val_loss: 0.9535 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.9900 - accuracy: 0.5000 - val_loss: 0.8990 - val_accuracy: 0.2273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 518ms/step - loss: 0.8612 - accuracy: 0.4651 - val_loss: 0.8371 - val_accuracy: 0.3182\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 449ms/step - loss: 0.7697 - accuracy: 0.5349 - val_loss: 0.7795 - val_accuracy: 0.3636\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.8016 - accuracy: 0.5233 - val_loss: 0.8221 - val_accuracy: 0.2273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 193ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 537ms/step - loss: 0.9464 - accuracy: 0.3647 - val_loss: 0.7492 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.7917 - accuracy: 0.4588 - val_loss: 0.6935 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7069 - accuracy: 0.6235 - val_loss: 0.7070 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 457ms/step - loss: 0.7010 - accuracy: 0.5412 - val_loss: 0.6913 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 460ms/step - loss: 0.6749 - accuracy: 0.6588 - val_loss: 0.6722 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 534ms/step - loss: 1.1124 - accuracy: 0.3647 - val_loss: 0.8024 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8836 - accuracy: 0.5294 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8048 - accuracy: 0.4824 - val_loss: 0.7401 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 520ms/step - loss: 0.7171 - accuracy: 0.6000 - val_loss: 0.6601 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 442ms/step - loss: 0.7853 - accuracy: 0.5176 - val_loss: 0.6983 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 285ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 532ms/step - loss: 0.9851 - accuracy: 0.4884 - val_loss: 0.7735 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8127 - accuracy: 0.5581 - val_loss: 0.7906 - val_accuracy: 0.3182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 454ms/step - loss: 0.7811 - accuracy: 0.5000 - val_loss: 0.6883 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 432ms/step - loss: 0.7199 - accuracy: 0.5814 - val_loss: 0.7284 - val_accuracy: 0.4091\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.7686 - accuracy: 0.5000 - val_loss: 0.7231 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 191ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_dataset_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_gru_model, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5dVcbIDWX9S",
        "outputId": "32a2465f-f716-46c4-bd3d-c3c064d82eb5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.0175 - accuracy: 0.5294 - val_loss: 0.7850 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7630 - accuracy: 0.6588 - val_loss: 0.6883 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.7079 - accuracy: 0.6588 - val_loss: 0.6519 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.6852 - accuracy: 0.6118 - val_loss: 0.6507 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.6604 - accuracy: 0.6941 - val_loss: 0.6394 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 4s 203ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 576ms/step - loss: 1.2260 - accuracy: 0.2941 - val_loss: 0.9084 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 445ms/step - loss: 0.9263 - accuracy: 0.4353 - val_loss: 0.7567 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.8210 - accuracy: 0.4235 - val_loss: 0.6919 - val_accuracy: 0.7727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.8126 - accuracy: 0.4588 - val_loss: 0.6656 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.8311 - accuracy: 0.4118 - val_loss: 0.7063 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 197ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 519ms/step - loss: 1.1640 - accuracy: 0.3837 - val_loss: 0.9749 - val_accuracy: 0.3182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 444ms/step - loss: 0.8998 - accuracy: 0.5349 - val_loss: 0.7584 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8203 - accuracy: 0.5116 - val_loss: 0.6784 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7287 - accuracy: 0.5814 - val_loss: 0.6562 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7475 - accuracy: 0.5233 - val_loss: 0.6397 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 201ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 533ms/step - loss: 0.8185 - accuracy: 0.6235 - val_loss: 0.6881 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.7326 - accuracy: 0.6941 - val_loss: 0.6749 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.7116 - accuracy: 0.6118 - val_loss: 0.6787 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.6092 - accuracy: 0.7059 - val_loss: 0.6842 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.5970 - accuracy: 0.6941 - val_loss: 0.6880 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 192ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 505ms/step - loss: 1.1613 - accuracy: 0.4235 - val_loss: 0.7669 - val_accuracy: 0.7727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.8603 - accuracy: 0.6706 - val_loss: 0.6545 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.8522 - accuracy: 0.5059 - val_loss: 0.6917 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7381 - accuracy: 0.6000 - val_loss: 0.7331 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.7015 - accuracy: 0.6118 - val_loss: 0.6816 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 204ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 499ms/step - loss: 0.9217 - accuracy: 0.5349 - val_loss: 0.7608 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.7910 - accuracy: 0.5814 - val_loss: 0.7011 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 482ms/step - loss: 0.6962 - accuracy: 0.6512 - val_loss: 0.6777 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.7438 - accuracy: 0.5814 - val_loss: 0.6691 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 505ms/step - loss: 0.7285 - accuracy: 0.5814 - val_loss: 0.6812 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 205ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6275331935709295 +/- 0.02771269149772272\n",
            "Sensitivity: 0.5793561959196634 +/- 0.01595531015240577\n",
            "False Positive Rate: 0.1405228758169935 +/- 0.14101600660386548\n",
            "Specificity: 0.8594771241830065 +/- 0.14101600660386548\n",
            "Precision: 0.6623621306230002 +/- 0.08463595278638435\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 526ms/step - loss: 0.9618 - accuracy: 0.4000 - val_loss: 0.8150 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7782 - accuracy: 0.6118 - val_loss: 0.7144 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.7397 - accuracy: 0.6824 - val_loss: 0.6557 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.6820 - accuracy: 0.6706 - val_loss: 0.6422 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 9s 431ms/step - loss: 0.6645 - accuracy: 0.6706 - val_loss: 0.6270 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 5s 198ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 549ms/step - loss: 0.8612 - accuracy: 0.5765 - val_loss: 0.7338 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.8490 - accuracy: 0.4000 - val_loss: 0.6544 - val_accuracy: 0.8636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.7290 - accuracy: 0.5294 - val_loss: 0.6374 - val_accuracy: 0.8636\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 12s 536ms/step - loss: 0.7392 - accuracy: 0.4588 - val_loss: 0.6246 - val_accuracy: 0.8636\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 457ms/step - loss: 0.7263 - accuracy: 0.5529 - val_loss: 0.5854 - val_accuracy: 0.8182\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 210ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.1375 - accuracy: 0.5116 - val_loss: 0.7151 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.7742 - accuracy: 0.5698 - val_loss: 0.6928 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.7284 - accuracy: 0.5581 - val_loss: 0.6786 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7486 - accuracy: 0.6047 - val_loss: 0.6641 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.6950 - accuracy: 0.6279 - val_loss: 0.6444 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 187ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6275331935709295 +/- 0.02771269149772272\n",
            "Sensitivity: 0.5793561959196634 +/- 0.01595531015240577\n",
            "False Positive Rate: 0.1405228758169935 +/- 0.14101600660386548\n",
            "Specificity: 0.8594771241830065 +/- 0.14101600660386548\n",
            "Precision: 0.6623621306230002 +/- 0.08463595278638435\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.639878872583275 +/- 0.09187244764967799\n",
            "Sensitivity: 0.5383305548940224 +/- 0.027267119784076164\n",
            "False Positive Rate: 0.03795877325289091 +/- 0.03705996907427321\n",
            "Specificity: 0.9620412267471091 +/- 0.03705996907427321\n",
            "Precision: 0.529270806551284 +/- 0.1939256164596628\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 507ms/step - loss: 1.1054 - accuracy: 0.4118 - val_loss: 0.7756 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.8147 - accuracy: 0.6588 - val_loss: 0.7289 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7587 - accuracy: 0.6824 - val_loss: 0.7134 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.7035 - accuracy: 0.6471 - val_loss: 0.6983 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 501ms/step - loss: 0.6574 - accuracy: 0.7294 - val_loss: 0.7164 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 194ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 496ms/step - loss: 1.0508 - accuracy: 0.4000 - val_loss: 0.6974 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7738 - accuracy: 0.6235 - val_loss: 0.6517 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.7483 - accuracy: 0.5765 - val_loss: 0.6435 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.7483 - accuracy: 0.5765 - val_loss: 0.5989 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 520ms/step - loss: 0.6843 - accuracy: 0.6588 - val_loss: 0.5759 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 190ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 492ms/step - loss: 0.9319 - accuracy: 0.4884 - val_loss: 0.7280 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8278 - accuracy: 0.5465 - val_loss: 0.6767 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7487 - accuracy: 0.6047 - val_loss: 0.6681 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.6995 - accuracy: 0.6395 - val_loss: 0.6700 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 523ms/step - loss: 0.6876 - accuracy: 0.5581 - val_loss: 0.6768 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 202ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6275331935709295 +/- 0.02771269149772272\n",
            "Sensitivity: 0.5793561959196634 +/- 0.01595531015240577\n",
            "False Positive Rate: 0.1405228758169935 +/- 0.14101600660386548\n",
            "Specificity: 0.8594771241830065 +/- 0.14101600660386548\n",
            "Precision: 0.6623621306230002 +/- 0.08463595278638435\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6460517120894479 +/- 0.024839793972293772\n",
            "Sensitivity: 0.5913458230795693 +/- 0.013646419596990384\n",
            "False Positive Rate: 0.12468577174459528 +/- 0.10479730437939784\n",
            "Specificity: 0.8753142282554047 +/- 0.10479730437939784\n",
            "Precision: 0.6673917997447409 +/- 0.0841010997693549\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.639878872583275 +/- 0.09187244764967799\n",
            "Sensitivity: 0.5383305548940224 +/- 0.027267119784076164\n",
            "False Positive Rate: 0.03795877325289091 +/- 0.03705996907427321\n",
            "Specificity: 0.9620412267471091 +/- 0.03705996907427321\n",
            "Precision: 0.529270806551284 +/- 0.1939256164596628\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_lstm_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'],create_cnn_lstm_model,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "ftl5SgVVXONE",
        "outputId": "d489630f-5dbf-4ec2-f86b-7591c9e8e54b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 364s 16s/step - loss: 0.9430 - accuracy: 0.6118 - val_loss: 0.7097 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "10/22 [============>.................] - ETA: 3:13 - loss: 0.7284 - accuracy: 0.7250"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-488ce65bcb88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_lstm_results_ncw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_smoothed_mean_norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X_smoothed_mean_norm_month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X_smoothed_median_norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X_smoothed_median_norm_month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcreate_cnn_lstm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-313ea2859978>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(dataset_names, create_model_fn, class_weights)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m#Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# Predict the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_gru_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'],create_cnn_gru_model,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NuboM1_Rmr0Y",
        "outputId": "720da80c-33c7-482a-8a3b-7c79d628503e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 422s 16s/step - loss: 0.8457 - accuracy: 0.6588 - val_loss: 0.6468 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 369s 17s/step - loss: 0.6894 - accuracy: 0.6471 - val_loss: 0.6139 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 360s 16s/step - loss: 0.6412 - accuracy: 0.6588 - val_loss: 0.5940 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 365s 17s/step - loss: 0.6533 - accuracy: 0.6235 - val_loss: 0.5888 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 370s 17s/step - loss: 0.6124 - accuracy: 0.6824 - val_loss: 0.5966 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 3s 889ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 364s 16s/step - loss: 1.0524 - accuracy: 0.3765 - val_loss: 0.7463 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 353s 16s/step - loss: 0.7760 - accuracy: 0.4471 - val_loss: 0.6324 - val_accuracy: 0.8182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 354s 16s/step - loss: 0.7507 - accuracy: 0.4941 - val_loss: 0.7345 - val_accuracy: 0.1818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 351s 16s/step - loss: 0.7102 - accuracy: 0.5882 - val_loss: 0.6926 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 357s 16s/step - loss: 0.6923 - accuracy: 0.5529 - val_loss: 0.6665 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 872ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 382s 17s/step - loss: 1.0183 - accuracy: 0.5116 - val_loss: 0.6898 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 366s 17s/step - loss: 0.7915 - accuracy: 0.6047 - val_loss: 0.6315 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 362s 16s/step - loss: 0.7917 - accuracy: 0.5000 - val_loss: 0.6097 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 358s 16s/step - loss: 0.6989 - accuracy: 0.6279 - val_loss: 0.6041 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 358s 16s/step - loss: 0.6987 - accuracy: 0.5581 - val_loss: 0.6153 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 3s 849ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5780340088516188 +/- 0.045516158865198796\n",
            "Sensitivity: 0.5294871794871795 +/- 0.02917899147882317\n",
            "False Positive Rate: 0.15384615384615385 +/- 0.2175713172881685\n",
            "Specificity: 0.8461538461538461 +/- 0.2175713172881685\n",
            "Precision: 0.5468204053109713 +/- 0.18112110228082753\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 377s 17s/step - loss: 0.8426 - accuracy: 0.6588 - val_loss: 0.6673 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "11/22 [==============>...............] - ETA: 3:07 - loss: 0.6913 - accuracy: 0.7273"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b7ee1ea584a8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_gru_results_ncw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_smoothed_mean_norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X_smoothed_mean_norm_month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X_smoothed_median_norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X_smoothed_median_norm_month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcreate_cnn_gru_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-313ea2859978>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(dataset_names, create_model_fn, class_weights)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m#Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# Predict the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}