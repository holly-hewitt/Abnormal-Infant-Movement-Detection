{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holly-hewitt/Abnormal-Infant-Movement-Detection/blob/main/Code/DataSetTestingClean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T4ilQacfTSVa"
      },
      "outputs": [],
      "source": [
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.enable_eager_execution(tf.ConfigProto(log_device_placement=False))\n",
        "#tf.test.gpu_device_name()\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Masking, LSTM, GRU\n",
        "from sklearn.model_selection import KFold\n",
        "# import early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from tensorflow.keras.layers import Input, Concatenate, Permute, Reshape, Multiply, Lambda, Add\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCwbTCmKTYQQ",
        "outputId": "9b6705d1-3107-49b3-896f-e37154c8fa2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def specificity_score(y_true, y_pred):\n",
        "\n",
        "    # Convert probabilities to binary predictions\n",
        "    y_pred_bin = np.argmax(y_pred, axis=1)\n",
        "    y_true_bin = np.argmax(y_true, axis=1)\n",
        "\n",
        "    tn = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n",
        "    fp = np.sum((y_true_bin == 0) & (y_pred_bin != 0))\n",
        "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
        "    return specificity"
      ],
      "metadata": {
        "id": "g4GzeYlTUia-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BVVJb1gkTSVb"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(dataset_names, create_model_fn, class_weights):\n",
        "\n",
        "    outer_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    # Find best dataset to train and test model on\n",
        "    #dataset_names = ['X_smoothed_mean_norm']\n",
        "\n",
        "    for dataset_name in dataset_names:\n",
        "\n",
        "         # Load in dataset from pickle\n",
        "        with open(f'drive/MyDrive/Pickles/{dataset_name}.pickle', 'rb') as handle:\n",
        "            dataset = pickle.load(handle)\n",
        "\n",
        "        dataset = np.array(dataset)\n",
        "\n",
        "        print(f'Working on dataset: {dataset_name}')\n",
        "\n",
        "        accuracies = []\n",
        "        sensitivities = []\n",
        "        false_positive_rates = []\n",
        "        specificities = []\n",
        "        precisions = []\n",
        "\n",
        "        fold = 1\n",
        "\n",
        "        for train_index, test_index in outer_cv.split(dataset):\n",
        "\n",
        "            # Print current progress\n",
        "            print(f'Working on fold: {fold}')\n",
        "            fold += 1\n",
        "\n",
        "            X_train, X_test = dataset[train_index], dataset[test_index]\n",
        "            Y_train, Y_test = abnormal_encoded[train_index], abnormal_encoded[test_index]\n",
        "\n",
        "            X_train = X_train.astype('float32')\n",
        "            Y_train = Y_train.astype('float32')\n",
        "            X_test = X_test.astype('float32')\n",
        "            Y_test = Y_test.astype('float32')\n",
        "\n",
        "            model = create_model_fn(X_train.shape[1:])\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "            if class_weights:\n",
        "\n",
        "                Y_train_classes = np.argmax(Y_train, axis=1)\n",
        "\n",
        "                # Compute class weights\n",
        "                cw = class_weight.compute_class_weight('balanced',\n",
        "                                                    classes=np.unique(Y_train_classes),\n",
        "                                                    y=Y_train_classes)\n",
        "\n",
        "                class_weights_dict = dict(enumerate(cw))\n",
        "\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=5, batch_size=4, validation_split=0.2, callbacks=[early_stopping], verbose=1, class_weight=class_weights_dict)\n",
        "\n",
        "            else:\n",
        "                #Fit the model\n",
        "                print('Fitting model')\n",
        "                model.fit(X_train, Y_train, epochs=5, batch_size=4, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "            # Predict the test set\n",
        "            print('Predicting test set')\n",
        "            Y_pred = model.predict(X_test)\n",
        "\n",
        "            Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "            Y_test_classes = np.argmax(Y_test, axis=1)\n",
        "\n",
        "            # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
        "            accuracies.append(accuracy_score(Y_test_classes, Y_pred_classes))\n",
        "            sensitivities.append(recall_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "            false_positive_rates.append(1 - specificity_score(Y_test, Y_pred))\n",
        "            specificities.append(specificity_score(Y_test, Y_pred))\n",
        "            precisions.append(precision_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
        "\n",
        "\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies)\n",
        "        avg_sensitivity = np.mean(sensitivities)\n",
        "        avg_false_positive_rate = np.mean(false_positive_rates)\n",
        "        avg_specificity = np.mean(specificities)\n",
        "        avg_precision = np.mean(precisions)\n",
        "\n",
        "        std_accuracy = np.std(accuracies)\n",
        "        std_sensitivity = np.std(sensitivities)\n",
        "        std_false_positive_rate = np.std(false_positive_rates)\n",
        "        std_specificity = np.std(specificities)\n",
        "        std_precision = np.std(precisions)\n",
        "\n",
        "        dataset_results[dataset_name]['Accuracy'] = (avg_accuracy, std_accuracy)\n",
        "        dataset_results[dataset_name]['Sensitivity'] = (avg_sensitivity, std_sensitivity)\n",
        "        dataset_results[dataset_name]['False Positive Rate'] = (avg_false_positive_rate, std_false_positive_rate)\n",
        "        dataset_results[dataset_name]['Specificity'] = (avg_specificity, std_specificity)\n",
        "        dataset_results[dataset_name]['Precision'] = (avg_precision, std_precision)\n",
        "\n",
        "        for dataset_name, results in dataset_results.items():\n",
        "            print(f'Dataset: {dataset_name}')\n",
        "            for metric, (avg, std) in results.items():\n",
        "                print(f'{metric}: {avg} +/- {std}')\n",
        "            print('\\n')\n",
        "\n",
        "\n",
        "        # Delete dataset to free up memory\n",
        "        del dataset\n",
        "        del Y_pred\n",
        "    return dataset_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gL1-AspcTSVb"
      },
      "outputs": [],
      "source": [
        "# Model functions\n",
        "\n",
        "def create_cnn_model(shape, filters=32, kernel_size=3, dropout_rate=0.5):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))  # Adjust the input_shape to match your dataset\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(19301, 16)))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation='relu'))  # Reduced the number of neurons in the dense layer\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_lstm_model(shape, lstm_units=32, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(LSTM(lstm_units, return_sequences=False))  # 'return_sequences=False' because we only need the last output\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(lstm_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_gru_model(shape, gru_units=32, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(GRU(gru_units, return_sequences=False))  # return_sequences=False because we only need the last output\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(gru_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_lstm_model(shape, filters=32, kernel_size=3, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(LSTM(lstm_units, return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(lstm_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_gru_model(shape, filters=32, kernel_size=3, gru_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=shape))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(GRU(gru_units, return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(gru_units, activation='relu'))\n",
        "    model.add(Dense(output_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_lstm_attention_model(shape, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
        "    inputs = Input(shape=shape)\n",
        "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    attention = Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = Flatten()(attention)\n",
        "    attention = Activation('softmax')(attention)\n",
        "    attention = RepeatVector(lstm_units)(attention)\n",
        "    attention = Permute([2, 1])(attention)\n",
        "    sent_representation = Multiply()([lstm_out, attention])\n",
        "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(lstm_units,))(sent_representation)\n",
        "    dropout = Dropout(dropout_rate)(sent_representation)\n",
        "    dense = Dense(lstm_units, activation='relu')(dropout)\n",
        "    outputs = Dense(output_classes, activation='softmax')(dense)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Load in dataset from pickle\n",
        "with open('drive/MyDrive/Pickles/abnormal_encoded.pickle', 'rb') as handle:\n",
        "    abnormal_encoded = pickle.load(handle)\n",
        "dataset_results = {'X_smoothed_mean_norm_month': {}, 'X_smoothed_median_norm_month': {}, 'X_smoothed_mean_norm': {}, 'X_smoothed_median_norm': {}}"
      ],
      "metadata": {
        "id": "-YsRAY00UNnG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVb3aj0TTSVb",
        "outputId": "7633eea4-d805-4412-e30d-011155573867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 30ms/step - loss: 22.3467 - accuracy: 0.4235 - val_loss: 10.9162 - val_accuracy: 0.5909\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 7.6254 - accuracy: 0.7412 - val_loss: 26.1706 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.9040 - accuracy: 0.9059 - val_loss: 27.9859 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.5618 - accuracy: 0.9059 - val_loss: 28.5547 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 21ms/step - loss: 46.1282 - accuracy: 0.5412 - val_loss: 6.0454 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.9497 - accuracy: 0.7176 - val_loss: 10.0646 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.4074 - accuracy: 0.7412 - val_loss: 6.0894 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.5195 - accuracy: 0.9529 - val_loss: 6.3230 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 26ms/step - loss: 46.0135 - accuracy: 0.4651 - val_loss: 37.8708 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 6.9466 - accuracy: 0.8023 - val_loss: 21.8819 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.0126 - accuracy: 0.9419 - val_loss: 38.5756 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.5546 - accuracy: 0.9767 - val_loss: 26.5844 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9489 - accuracy: 0.9419 - val_loss: 32.0481 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 54ms/step - loss: 76.3911 - accuracy: 0.5176 - val_loss: 79.9712 - val_accuracy: 0.2727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 54.5821 - accuracy: 0.4824 - val_loss: 37.4107 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 7.3997 - accuracy: 0.7294 - val_loss: 38.2822 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.5012 - accuracy: 0.9294 - val_loss: 36.6740 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.1571 - accuracy: 0.9765 - val_loss: 25.2022 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 35ms/step - loss: 55.8808 - accuracy: 0.5529 - val_loss: 30.1985 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 15.5205 - accuracy: 0.6235 - val_loss: 8.4225 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.5697 - accuracy: 0.9176 - val_loss: 7.8450 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8415 - accuracy: 0.9059 - val_loss: 10.1286 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8877 - accuracy: 0.9059 - val_loss: 15.2040 - val_accuracy: 0.3636\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 5s 96ms/step - loss: 66.0465 - accuracy: 0.4651 - val_loss: 42.9594 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 26.9324 - accuracy: 0.7326 - val_loss: 60.9355 - val_accuracy: 0.4545\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.6442 - accuracy: 0.8023 - val_loss: 44.1150 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 4.0480 - accuracy: 0.9070 - val_loss: 46.5847 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 27ms/step - loss: 26.0726 - accuracy: 0.4471 - val_loss: 8.8134 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.9932 - accuracy: 0.7882 - val_loss: 18.1387 - val_accuracy: 0.5455\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.5853 - accuracy: 0.8706 - val_loss: 20.8299 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.6966 - accuracy: 0.9294 - val_loss: 21.7234 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 23ms/step - loss: 19.2372 - accuracy: 0.5176 - val_loss: 36.9696 - val_accuracy: 0.3182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 5.4883 - accuracy: 0.8588 - val_loss: 8.4544 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.8579 - accuracy: 0.8353 - val_loss: 5.5356 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7122 - accuracy: 0.8824 - val_loss: 6.2783 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6620 - accuracy: 0.9412 - val_loss: 12.1920 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 32ms/step - loss: 6.3287 - accuracy: 0.5465 - val_loss: 7.3701 - val_accuracy: 0.2727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.6477 - accuracy: 0.6977 - val_loss: 3.3907 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8953 - val_loss: 2.4375 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0794 - accuracy: 0.9767 - val_loss: 2.3532 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.4417 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 31.8793 - accuracy: 0.5529 - val_loss: 1.6784 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7180 - accuracy: 0.6824 - val_loss: 0.6530 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3003 - accuracy: 0.9059 - val_loss: 0.9127 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1814 - accuracy: 0.9647 - val_loss: 0.7232 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 30.2546 - accuracy: 0.5294 - val_loss: 122.6305 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 27.8967 - accuracy: 0.7529 - val_loss: 55.0733 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 21.1827 - accuracy: 0.8118 - val_loss: 33.1586 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.1159 - accuracy: 0.9529 - val_loss: 55.8359 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.9184 - accuracy: 0.8706 - val_loss: 43.5183 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 22ms/step - loss: 37.7312 - accuracy: 0.5930 - val_loss: 32.8900 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 22.5131 - accuracy: 0.6744 - val_loss: 45.5256 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.0733 - accuracy: 0.8140 - val_loss: 26.8875 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.1225 - accuracy: 0.8953 - val_loss: 28.1037 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.5288 - accuracy: 0.8953 - val_loss: 27.9516 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.022698545586030232\n",
            "Sensitivity: 0.5954031005114596 +/- 0.026547838177203346\n",
            "False Positive Rate: 0.35944121238238885 +/- 0.05336288150401101\n",
            "Specificity: 0.6405587876176112 +/- 0.05336288150401101\n",
            "Precision: 0.5906391501219087 +/- 0.03294091467480022\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "cnn_dataset_result_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_cnn_model, True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_dataset_result_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_cnn_model, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAqA0aGXUBTp",
        "outputId": "6c9bd3e8-d462-44b8-92e9-d0462a4fb256"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 15.8563 - accuracy: 0.5529 - val_loss: 5.4335 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.6145 - accuracy: 0.8000 - val_loss: 8.6626 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.8578 - accuracy: 0.8824 - val_loss: 19.0609 - val_accuracy: 0.4091\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1123 - accuracy: 0.9412 - val_loss: 19.5823 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 25ms/step - loss: 30.6900 - accuracy: 0.4588 - val_loss: 8.9566 - val_accuracy: 0.7727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.8553 - accuracy: 0.8824 - val_loss: 5.5423 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.9529 - val_loss: 4.0455 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.9529 - val_loss: 5.3524 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2669 - accuracy: 0.9529 - val_loss: 8.9192 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 17.3586 - accuracy: 0.5698 - val_loss: 44.6831 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.9374 - accuracy: 0.7674 - val_loss: 14.6169 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.8936 - accuracy: 0.8837 - val_loss: 13.4980 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1422 - accuracy: 0.9767 - val_loss: 18.8622 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2587 - accuracy: 0.9651 - val_loss: 22.1837 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5284183554623806 +/- 0.12529679807062674\n",
            "Sensitivity: 0.6054122863720387 +/- 0.05393824439757144\n",
            "False Positive Rate: 0.5861164978812038 +/- 0.2138975519880295\n",
            "Specificity: 0.41388350211879626 +/- 0.2138975519880295\n",
            "Precision: 0.6159892094489617 +/- 0.03942193675566511\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 41.3797 - accuracy: 0.4941 - val_loss: 11.2520 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.3222 - accuracy: 0.7529 - val_loss: 8.0133 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.3902 - accuracy: 0.7412 - val_loss: 14.1096 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1232 - accuracy: 0.8941 - val_loss: 15.6849 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.9176 - val_loss: 10.7852 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 27ms/step - loss: 23.9669 - accuracy: 0.5176 - val_loss: 15.2598 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.7404 - accuracy: 0.7294 - val_loss: 8.8192 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0465 - accuracy: 0.9294 - val_loss: 9.1877 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.7265 - accuracy: 0.9647 - val_loss: 11.5666 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 12.3177 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 35.9553 - accuracy: 0.6047 - val_loss: 52.3138 - val_accuracy: 0.5909\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.4408 - accuracy: 0.7326 - val_loss: 66.6741 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.5184 - accuracy: 0.8372 - val_loss: 51.5205 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 12.5526 - accuracy: 0.8372 - val_loss: 28.4660 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.5182 - accuracy: 0.9186 - val_loss: 37.3039 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6583973911017936 +/- 0.06805578421456863\n",
            "Sensitivity: 0.5871742894188714 +/- 0.020542103304235802\n",
            "False Positive Rate: 0.1061732385261797 +/- 0.07248435114464193\n",
            "Specificity: 0.8938267614738202 +/- 0.07248435114464193\n",
            "Precision: 0.6553776792538591 +/- 0.023814390249551697\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 30.5103 - accuracy: 0.5176 - val_loss: 31.7640 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.0701 - accuracy: 0.8000 - val_loss: 20.5982 - val_accuracy: 0.5455\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 3.0367 - accuracy: 0.9059 - val_loss: 19.4865 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.7986 - accuracy: 0.8941 - val_loss: 19.7983 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.1228 - accuracy: 0.9765 - val_loss: 18.7418 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 28ms/step - loss: 26.6241 - accuracy: 0.4824 - val_loss: 18.2730 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.3390 - accuracy: 0.8235 - val_loss: 13.8726 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 3.4191 - accuracy: 0.9294 - val_loss: 52.9660 - val_accuracy: 0.3182\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.6003 - accuracy: 0.8706 - val_loss: 19.5940 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.2060 - accuracy: 0.9882 - val_loss: 29.3516 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 21ms/step - loss: 20.9521 - accuracy: 0.5581 - val_loss: 22.4353 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.4225 - accuracy: 0.8256 - val_loss: 24.4814 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.2947 - accuracy: 0.9070 - val_loss: 29.1618 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0421 - accuracy: 0.9884 - val_loss: 21.1498 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.3703e-07 - accuracy: 1.0000 - val_loss: 20.1069 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6087817377125554 +/- 0.024707284922990343\n",
            "Sensitivity: 0.5496908750004725 +/- 0.022459985618095736\n",
            "False Positive Rate: 0.21487825899590607 +/- 0.025739180275967184\n",
            "Specificity: 0.7851217410040939 +/- 0.025739180275967184\n",
            "Precision: 0.5611061738147746 +/- 0.029737200420561147\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 26.7900 - accuracy: 0.5176 - val_loss: 1.0789 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0694 - accuracy: 0.6824 - val_loss: 1.0791 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0744 - accuracy: 0.6706 - val_loss: 1.0643 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0611 - accuracy: 0.6706 - val_loss: 1.0496 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0479 - accuracy: 0.6706 - val_loss: 1.0365 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 29ms/step - loss: 99.9923 - accuracy: 0.4824 - val_loss: 36.3889 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 21.3106 - accuracy: 0.7412 - val_loss: 19.0500 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.9842 - accuracy: 0.8941 - val_loss: 64.2622 - val_accuracy: 0.1818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.1491 - accuracy: 0.7529 - val_loss: 30.6916 - val_accuracy: 0.8182\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.5561 - accuracy: 0.8471 - val_loss: 41.8483 - val_accuracy: 0.4091\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 32.6569 - accuracy: 0.4419 - val_loss: 9.9448 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.4041 - accuracy: 0.7442 - val_loss: 10.2015 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.7982 - accuracy: 0.7907 - val_loss: 11.9288 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.8071 - accuracy: 0.9070 - val_loss: 14.3448 - val_accuracy: 0.4545\n",
            "Predicting test set\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5159562077801071 +/- 0.1165314296316961\n",
            "Sensitivity: 0.5244137871072856 +/- 0.05672229597543082\n",
            "False Positive Rate: 0.3939524527759821 +/- 0.30286980063280217\n",
            "Specificity: 0.6060475472240178 +/- 0.30286980063280217\n",
            "Precision: 0.5217549598623767 +/- 0.07099989175088521\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dataset_results_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_lstm_model, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBAgX9CTT5ec",
        "outputId": "e3117448-bcdb-4e56-f2ad-5a7c02dcd7a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 19s 539ms/step - loss: 1.0659 - accuracy: 0.4824 - val_loss: 0.8730 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 512ms/step - loss: 0.8162 - accuracy: 0.6471 - val_loss: 0.8216 - val_accuracy: 0.2727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 9s 428ms/step - loss: 0.7692 - accuracy: 0.5529 - val_loss: 0.8627 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.7146 - accuracy: 0.5765 - val_loss: 0.7524 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.7599 - accuracy: 0.5647 - val_loss: 0.8375 - val_accuracy: 0.2727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 188ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 524ms/step - loss: 0.9982 - accuracy: 0.4588 - val_loss: 0.8210 - val_accuracy: 0.5909\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 9s 425ms/step - loss: 0.8482 - accuracy: 0.5294 - val_loss: 0.7614 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.7796 - accuracy: 0.5529 - val_loss: 0.7631 - val_accuracy: 0.4091\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7328 - accuracy: 0.5765 - val_loss: 0.7401 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.6885 - accuracy: 0.5765 - val_loss: 0.7358 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 529ms/step - loss: 1.0734 - accuracy: 0.3721 - val_loss: 0.8975 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.9002 - accuracy: 0.5349 - val_loss: 0.7638 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.8624 - accuracy: 0.5000 - val_loss: 0.7015 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 448ms/step - loss: 0.7549 - accuracy: 0.5698 - val_loss: 0.6869 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 436ms/step - loss: 0.7003 - accuracy: 0.5698 - val_loss: 0.6571 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 191ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5893314698346145 +/- 0.08317934416473478\n",
            "Sensitivity: 0.5943452144690534 +/- 0.02854351557406235\n",
            "False Positive Rate: 0.3501759678230267 +/- 0.3309075558924957\n",
            "Specificity: 0.6498240321769734 +/- 0.3309075558924957\n",
            "Precision: 0.6681504292646508 +/- 0.09588601144841005\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 494ms/step - loss: 0.8677 - accuracy: 0.4471 - val_loss: 0.7278 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.7254 - accuracy: 0.6235 - val_loss: 0.6742 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.7732 - accuracy: 0.5765 - val_loss: 0.6625 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.6505 - accuracy: 0.6353 - val_loss: 0.6817 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 12s 531ms/step - loss: 0.6792 - accuracy: 0.5647 - val_loss: 0.6801 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 188ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 503ms/step - loss: 0.9392 - accuracy: 0.4706 - val_loss: 0.8371 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 452ms/step - loss: 0.7524 - accuracy: 0.5647 - val_loss: 0.6903 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.7115 - accuracy: 0.6235 - val_loss: 0.7292 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.6498 - accuracy: 0.6118 - val_loss: 0.7373 - val_accuracy: 0.5455\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.6602 - accuracy: 0.6588 - val_loss: 0.7272 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 206ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 532ms/step - loss: 1.0808 - accuracy: 0.4535 - val_loss: 0.9228 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.9825 - accuracy: 0.5000 - val_loss: 0.8795 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8102 - accuracy: 0.5930 - val_loss: 0.8396 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 515ms/step - loss: 0.7258 - accuracy: 0.5814 - val_loss: 0.8177 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 9s 434ms/step - loss: 0.7039 - accuracy: 0.6395 - val_loss: 0.7597 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 190ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5967854647099929 +/- 0.07387437977059848\n",
            "Sensitivity: 0.5408485391457528 +/- 0.06638688144502103\n",
            "False Positive Rate: 0.17790706026000144 +/- 0.0780662910400039\n",
            "Specificity: 0.8220929397399986 +/- 0.07806629104000391\n",
            "Precision: 0.524346878390996 +/- 0.09264883782655675\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 513ms/step - loss: 1.0076 - accuracy: 0.5882 - val_loss: 0.7936 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.8280 - accuracy: 0.6118 - val_loss: 0.7046 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.8139 - accuracy: 0.5176 - val_loss: 0.6906 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.7146 - accuracy: 0.5176 - val_loss: 0.6971 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.6723 - accuracy: 0.6706 - val_loss: 0.6560 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 198ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 560ms/step - loss: 1.1668 - accuracy: 0.2941 - val_loss: 1.0379 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 433ms/step - loss: 0.9518 - accuracy: 0.5529 - val_loss: 0.9931 - val_accuracy: 0.1818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.8586 - accuracy: 0.5294 - val_loss: 0.9224 - val_accuracy: 0.1818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.8062 - accuracy: 0.5412 - val_loss: 0.8242 - val_accuracy: 0.2273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7988 - accuracy: 0.5176 - val_loss: 0.7873 - val_accuracy: 0.2273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 197ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 537ms/step - loss: 1.0776 - accuracy: 0.5465 - val_loss: 0.9313 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.9343 - accuracy: 0.5233 - val_loss: 0.9278 - val_accuracy: 0.1818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.7833 - accuracy: 0.5116 - val_loss: 0.8477 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 523ms/step - loss: 0.7651 - accuracy: 0.5814 - val_loss: 0.7430 - val_accuracy: 0.5455\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 9s 430ms/step - loss: 0.7284 - accuracy: 0.6512 - val_loss: 0.7805 - val_accuracy: 0.4091\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.47262986256696954 +/- 0.1003897780199082\n",
            "Sensitivity: 0.55306686777275 +/- 0.07686810635873144\n",
            "False Positive Rate: 0.516088486676722 +/- 0.3735401705280771\n",
            "Specificity: 0.48391151332327803 +/- 0.37354017052807703\n",
            "Precision: 0.49363015497767265 +/- 0.19062817030587245\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 507ms/step - loss: 1.0633 - accuracy: 0.5882 - val_loss: 0.8215 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 456ms/step - loss: 0.8842 - accuracy: 0.6471 - val_loss: 0.7586 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.7663 - accuracy: 0.6000 - val_loss: 0.7284 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.7444 - accuracy: 0.6118 - val_loss: 0.7137 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6663 - accuracy: 0.6353 - val_loss: 0.7203 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 558ms/step - loss: 1.0385 - accuracy: 0.4235 - val_loss: 0.9636 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 9s 426ms/step - loss: 0.8059 - accuracy: 0.5176 - val_loss: 0.8143 - val_accuracy: 0.5455\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.7563 - accuracy: 0.5765 - val_loss: 0.6983 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6792 - accuracy: 0.6000 - val_loss: 0.6909 - val_accuracy: 0.5909\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.7249 - accuracy: 0.5765 - val_loss: 0.7853 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 579ms/step - loss: 0.9671 - accuracy: 0.5465 - val_loss: 0.8391 - val_accuracy: 0.4545\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.7895 - accuracy: 0.6047 - val_loss: 0.8320 - val_accuracy: 0.3182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.7160 - accuracy: 0.5581 - val_loss: 0.7657 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.7299 - accuracy: 0.5698 - val_loss: 0.7461 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.7133 - accuracy: 0.5698 - val_loss: 0.7359 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 190ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5280689494525972 +/- 0.03311972529639176\n",
            "Sensitivity: 0.5568772988277632 +/- 0.06722002227409395\n",
            "False Positive Rate: 0.6488185017596783 +/- 0.2591711981016694\n",
            "Specificity: 0.3511814982403218 +/- 0.2591711981016694\n",
            "Precision: 0.46414154599461616 +/- 0.16473705155816443\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dataset_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_lstm_model, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrOkYfJUWFVU",
        "outputId": "3112742e-b5ad-46ce-e358-7e3026210d8e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 537ms/step - loss: 0.9327 - accuracy: 0.5765 - val_loss: 0.6746 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.7313 - accuracy: 0.6588 - val_loss: 0.6212 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 436ms/step - loss: 0.7432 - accuracy: 0.6471 - val_loss: 0.6027 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.6954 - accuracy: 0.6588 - val_loss: 0.6037 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6717 - accuracy: 0.6706 - val_loss: 0.5987 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 271ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.1442 - accuracy: 0.4000 - val_loss: 0.9542 - val_accuracy: 0.1818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8762 - accuracy: 0.5412 - val_loss: 0.7848 - val_accuracy: 0.5909\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 444ms/step - loss: 0.7804 - accuracy: 0.5059 - val_loss: 0.6480 - val_accuracy: 0.7727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 446ms/step - loss: 0.7752 - accuracy: 0.4824 - val_loss: 0.6296 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.6755 - accuracy: 0.6235 - val_loss: 0.6434 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 194ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 556ms/step - loss: 1.1507 - accuracy: 0.3953 - val_loss: 0.9789 - val_accuracy: 0.3182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 436ms/step - loss: 0.8904 - accuracy: 0.5930 - val_loss: 0.7810 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.7641 - accuracy: 0.6279 - val_loss: 0.6741 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7487 - accuracy: 0.5581 - val_loss: 0.6571 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.6925 - accuracy: 0.6279 - val_loss: 0.6404 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 195ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.559748427672956 +/- 0.09590287997503089\n",
            "Sensitivity: 0.5528515859785209 +/- 0.053436968970002365\n",
            "False Positive Rate: 0.3115707821590175 +/- 0.21526665614530438\n",
            "Specificity: 0.6884292178409824 +/- 0.21526665614530438\n",
            "Precision: 0.5703074703074703 +/- 0.06174356804196348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 507ms/step - loss: 0.8953 - accuracy: 0.5882 - val_loss: 0.6715 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.7497 - accuracy: 0.6471 - val_loss: 0.6446 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.6525 - accuracy: 0.6824 - val_loss: 0.6414 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.6721 - accuracy: 0.6588 - val_loss: 0.6517 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6600 - accuracy: 0.6706 - val_loss: 0.6722 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 497ms/step - loss: 1.0404 - accuracy: 0.4118 - val_loss: 0.7738 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 442ms/step - loss: 0.8157 - accuracy: 0.5882 - val_loss: 0.6784 - val_accuracy: 0.8182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.7581 - accuracy: 0.5882 - val_loss: 0.6159 - val_accuracy: 0.7727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6800 - accuracy: 0.6824 - val_loss: 0.6582 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.6236 - accuracy: 0.6353 - val_loss: 0.7021 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 195ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 523ms/step - loss: 1.0899 - accuracy: 0.4070 - val_loss: 0.7938 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.8500 - accuracy: 0.5698 - val_loss: 0.6715 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.7139 - accuracy: 0.6279 - val_loss: 0.6555 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 434ms/step - loss: 0.6998 - accuracy: 0.6395 - val_loss: 0.6682 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 458ms/step - loss: 0.6606 - accuracy: 0.6395 - val_loss: 0.6892 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.5223619846261355 +/- 0.10928795922520232\n",
            "Sensitivity: 0.5805419468732163 +/- 0.04006911304130092\n",
            "False Positive Rate: 0.4550204697263521 +/- 0.3032464413630669\n",
            "Specificity: 0.5449795302736479 +/- 0.3032464413630669\n",
            "Precision: 0.6046582784171437 +/- 0.020059904637667103\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 598ms/step - loss: 0.8939 - accuracy: 0.6471 - val_loss: 0.6836 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.7541 - accuracy: 0.6706 - val_loss: 0.6142 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.7006 - accuracy: 0.6353 - val_loss: 0.5998 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 443ms/step - loss: 0.6816 - accuracy: 0.6353 - val_loss: 0.5971 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6753 - accuracy: 0.5882 - val_loss: 0.6252 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 196ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 599ms/step - loss: 1.0389 - accuracy: 0.3765 - val_loss: 0.8271 - val_accuracy: 0.7727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.8565 - accuracy: 0.5647 - val_loss: 0.7638 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.7969 - accuracy: 0.4588 - val_loss: 0.7289 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.7480 - accuracy: 0.5412 - val_loss: 0.6802 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.7209 - accuracy: 0.5765 - val_loss: 0.6900 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 529ms/step - loss: 0.9257 - accuracy: 0.5581 - val_loss: 0.7363 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 439ms/step - loss: 0.7672 - accuracy: 0.6163 - val_loss: 0.6571 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 456ms/step - loss: 0.7944 - accuracy: 0.6279 - val_loss: 0.6392 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.6632 - accuracy: 0.6395 - val_loss: 0.6254 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 476ms/step - loss: 0.7031 - accuracy: 0.6163 - val_loss: 0.6257 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 268ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5903796878639646 +/- 0.0640918529483853\n",
            "Sensitivity: 0.6072387794524018 +/- 0.041595051676493154\n",
            "False Positive Rate: 0.35119945414063053 +/- 0.18784913851642496\n",
            "Specificity: 0.6488005458593694 +/- 0.18784913851642496\n",
            "Precision: 0.6180405242905244 +/- 0.05508382986407725\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 546ms/step - loss: 1.1009 - accuracy: 0.3176 - val_loss: 0.9155 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.7847 - accuracy: 0.7059 - val_loss: 0.7166 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 442ms/step - loss: 0.6975 - accuracy: 0.6824 - val_loss: 0.6516 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 461ms/step - loss: 0.6636 - accuracy: 0.6588 - val_loss: 0.6527 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6715 - accuracy: 0.7176 - val_loss: 0.6677 - val_accuracy: 0.6818\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 197ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 538ms/step - loss: 0.8927 - accuracy: 0.5176 - val_loss: 0.7964 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 511ms/step - loss: 0.7713 - accuracy: 0.5176 - val_loss: 0.7066 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 437ms/step - loss: 0.7302 - accuracy: 0.5647 - val_loss: 0.7123 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6979 - accuracy: 0.6235 - val_loss: 0.6758 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.6805 - accuracy: 0.5765 - val_loss: 0.7105 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 275ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.0611 - accuracy: 0.4070 - val_loss: 0.8673 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.8221 - accuracy: 0.5465 - val_loss: 0.7347 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 446ms/step - loss: 0.7845 - accuracy: 0.5233 - val_loss: 0.6943 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.6865 - accuracy: 0.6744 - val_loss: 0.6614 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.6393 - accuracy: 0.6628 - val_loss: 0.7210 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 276ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.6024924295364547 +/- 0.08316662289228618\n",
            "Sensitivity: 0.47997019320548734 +/- 0.006945394695744081\n",
            "False Positive Rate: 0.04005961358902536 +/- 0.013890789391488162\n",
            "Specificity: 0.9599403864109747 +/- 0.013890789391488162\n",
            "Precision: 0.3089776791219632 +/- 0.04249820006807891\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_dataset_results_cw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_gru_model, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm2O6QumT5q6",
        "outputId": "ef13c022-cbe9-41e8-bc1b-fa51fe18e304"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 519ms/step - loss: 0.9785 - accuracy: 0.5294 - val_loss: 0.7485 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.9469 - accuracy: 0.4353 - val_loss: 0.7703 - val_accuracy: 0.4545\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7939 - accuracy: 0.4824 - val_loss: 0.7746 - val_accuracy: 0.3182\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.7175 - accuracy: 0.5882 - val_loss: 0.7024 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 509ms/step - loss: 0.7059 - accuracy: 0.6118 - val_loss: 0.7018 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 196ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 520ms/step - loss: 1.2310 - accuracy: 0.4000 - val_loss: 0.8971 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.9657 - accuracy: 0.5529 - val_loss: 0.9118 - val_accuracy: 0.2727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 472ms/step - loss: 0.8814 - accuracy: 0.5294 - val_loss: 1.0553 - val_accuracy: 0.1818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.8079 - accuracy: 0.5059 - val_loss: 0.9417 - val_accuracy: 0.2273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 209ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 17s 614ms/step - loss: 1.1093 - accuracy: 0.3837 - val_loss: 0.9494 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.9535 - accuracy: 0.5233 - val_loss: 0.8861 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.8813 - accuracy: 0.4884 - val_loss: 0.8690 - val_accuracy: 0.3636\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.7917 - accuracy: 0.5465 - val_loss: 0.7847 - val_accuracy: 0.4545\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.7615 - accuracy: 0.5814 - val_loss: 0.7740 - val_accuracy: 0.5000\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 201ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6276496622408572 +/- 0.04295878645766445\n",
            "Sensitivity: 0.5846855071313276 +/- 0.026396153565996467\n",
            "False Positive Rate: 0.13926596279537454 +/- 0.15720238848221604\n",
            "Specificity: 0.8607340372046254 +/- 0.15720238848221604\n",
            "Precision: 0.6823822165114839 +/- 0.07196020197182483\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 523ms/step - loss: 0.9479 - accuracy: 0.6471 - val_loss: 0.7712 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.8284 - accuracy: 0.5412 - val_loss: 0.7937 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.7464 - accuracy: 0.5647 - val_loss: 0.7742 - val_accuracy: 0.3636\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.7576 - accuracy: 0.5882 - val_loss: 0.7289 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 524ms/step - loss: 0.6866 - accuracy: 0.6588 - val_loss: 0.7736 - val_accuracy: 0.3182\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 199ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 535ms/step - loss: 1.0456 - accuracy: 0.4000 - val_loss: 0.7881 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 472ms/step - loss: 0.7993 - accuracy: 0.5412 - val_loss: 0.8057 - val_accuracy: 0.3182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.8643 - accuracy: 0.4471 - val_loss: 0.7474 - val_accuracy: 0.4091\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 455ms/step - loss: 0.7650 - accuracy: 0.5647 - val_loss: 0.7913 - val_accuracy: 0.3182\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 458ms/step - loss: 0.7170 - accuracy: 0.5529 - val_loss: 0.6800 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 297ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 532ms/step - loss: 1.0865 - accuracy: 0.4884 - val_loss: 0.9031 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.9153 - accuracy: 0.5814 - val_loss: 0.9020 - val_accuracy: 0.3636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 9s 429ms/step - loss: 0.7486 - accuracy: 0.5930 - val_loss: 0.7968 - val_accuracy: 0.5455\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 465ms/step - loss: 0.7884 - accuracy: 0.5814 - val_loss: 0.7637 - val_accuracy: 0.5455\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.7864 - accuracy: 0.5581 - val_loss: 0.7952 - val_accuracy: 0.4545\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 278ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.6150710458886559 +/- 0.07056290676832261\n",
            "Sensitivity: 0.5119658119658119 +/- 0.01692221356685754\n",
            "False Positive Rate: 0.04273504273504273 +/- 0.06043647702449124\n",
            "Specificity: 0.9572649572649573 +/- 0.06043647702449124\n",
            "Precision: 0.37902639787723186 +/- 0.12837130720577453\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 531ms/step - loss: 1.0923 - accuracy: 0.5882 - val_loss: 0.7512 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.9041 - accuracy: 0.5176 - val_loss: 0.7436 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 512ms/step - loss: 0.7671 - accuracy: 0.6353 - val_loss: 0.6605 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 9s 432ms/step - loss: 0.8389 - accuracy: 0.5294 - val_loss: 0.6699 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 471ms/step - loss: 0.7121 - accuracy: 0.5765 - val_loss: 0.6641 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 189ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 543ms/step - loss: 0.9767 - accuracy: 0.4941 - val_loss: 1.0417 - val_accuracy: 0.1364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8983 - accuracy: 0.4941 - val_loss: 0.9671 - val_accuracy: 0.1364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.8323 - accuracy: 0.4824 - val_loss: 0.8741 - val_accuracy: 0.2727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 459ms/step - loss: 0.7543 - accuracy: 0.5412 - val_loss: 0.8623 - val_accuracy: 0.2727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.7842 - accuracy: 0.4471 - val_loss: 0.7904 - val_accuracy: 0.3182\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 289ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 537ms/step - loss: 1.1121 - accuracy: 0.3605 - val_loss: 0.9535 - val_accuracy: 0.3636\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.9900 - accuracy: 0.5000 - val_loss: 0.8990 - val_accuracy: 0.2273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 518ms/step - loss: 0.8612 - accuracy: 0.4651 - val_loss: 0.8371 - val_accuracy: 0.3182\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 449ms/step - loss: 0.7697 - accuracy: 0.5349 - val_loss: 0.7795 - val_accuracy: 0.3636\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.8016 - accuracy: 0.5233 - val_loss: 0.8221 - val_accuracy: 0.2273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 193ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5781504775215467 +/- 0.06553720102813265\n",
            "Sensitivity: 0.5594136169987564 +/- 0.05760092169261973\n",
            "False Positive Rate: 0.25062845651080945 +/- 0.1991391366538692\n",
            "Specificity: 0.7493715434891906 +/- 0.1991391366538692\n",
            "Precision: 0.632357666413394 +/- 0.1154380632326368\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 537ms/step - loss: 0.9464 - accuracy: 0.3647 - val_loss: 0.7492 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.7917 - accuracy: 0.4588 - val_loss: 0.6935 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7069 - accuracy: 0.6235 - val_loss: 0.7070 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 457ms/step - loss: 0.7010 - accuracy: 0.5412 - val_loss: 0.6913 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 460ms/step - loss: 0.6749 - accuracy: 0.6588 - val_loss: 0.6722 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 200ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 534ms/step - loss: 1.1124 - accuracy: 0.3647 - val_loss: 0.8024 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8836 - accuracy: 0.5294 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8048 - accuracy: 0.4824 - val_loss: 0.7401 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 520ms/step - loss: 0.7171 - accuracy: 0.6000 - val_loss: 0.6601 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 442ms/step - loss: 0.7853 - accuracy: 0.5176 - val_loss: 0.6983 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 285ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 532ms/step - loss: 0.9851 - accuracy: 0.4884 - val_loss: 0.7735 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8127 - accuracy: 0.5581 - val_loss: 0.7906 - val_accuracy: 0.3182\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 454ms/step - loss: 0.7811 - accuracy: 0.5000 - val_loss: 0.6883 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 432ms/step - loss: 0.7199 - accuracy: 0.5814 - val_loss: 0.7284 - val_accuracy: 0.4091\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.7686 - accuracy: 0.5000 - val_loss: 0.7231 - val_accuracy: 0.5455\n",
            "Predicting test set\n",
            "2/2 [==============================] - 1s 191ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.4785697647332867 +/- 0.13324677577112923\n",
            "Sensitivity: 0.5526743895938943 +/- 0.04575077538169334\n",
            "False Positive Rate: 0.5620376355670473 +/- 0.314419214300729\n",
            "Specificity: 0.43796236443295267 +/- 0.31441921430072906\n",
            "Precision: 0.5530204068807011 +/- 0.06455057647151348\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_dataset_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'], create_gru_model, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5dVcbIDWX9S",
        "outputId": "32a2465f-f716-46c4-bd3d-c3c064d82eb5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.0175 - accuracy: 0.5294 - val_loss: 0.7850 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7630 - accuracy: 0.6588 - val_loss: 0.6883 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.7079 - accuracy: 0.6588 - val_loss: 0.6519 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.6852 - accuracy: 0.6118 - val_loss: 0.6507 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.6604 - accuracy: 0.6941 - val_loss: 0.6394 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 4s 203ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 18s 576ms/step - loss: 1.2260 - accuracy: 0.2941 - val_loss: 0.9084 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 445ms/step - loss: 0.9263 - accuracy: 0.4353 - val_loss: 0.7567 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.8210 - accuracy: 0.4235 - val_loss: 0.6919 - val_accuracy: 0.7727\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.8126 - accuracy: 0.4588 - val_loss: 0.6656 - val_accuracy: 0.7727\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.8311 - accuracy: 0.4118 - val_loss: 0.7063 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 197ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 519ms/step - loss: 1.1640 - accuracy: 0.3837 - val_loss: 0.9749 - val_accuracy: 0.3182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 444ms/step - loss: 0.8998 - accuracy: 0.5349 - val_loss: 0.7584 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8203 - accuracy: 0.5116 - val_loss: 0.6784 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7287 - accuracy: 0.5814 - val_loss: 0.6562 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7475 - accuracy: 0.5233 - val_loss: 0.6397 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 201ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.5965525273701374 +/- 0.055391108437102834\n",
            "Sensitivity: 0.5955782177918401 +/- 0.06616608909669772\n",
            "False Positive Rate: 0.4360590390002155 +/- 0.037992504146691586\n",
            "Specificity: 0.5639409609997845 +/- 0.037992504146691586\n",
            "Precision: 0.5929139817717404 +/- 0.06423871043928871\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 533ms/step - loss: 0.8185 - accuracy: 0.6235 - val_loss: 0.6881 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.7326 - accuracy: 0.6941 - val_loss: 0.6749 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.7116 - accuracy: 0.6118 - val_loss: 0.6787 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.6092 - accuracy: 0.7059 - val_loss: 0.6842 - val_accuracy: 0.6818\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.5970 - accuracy: 0.6941 - val_loss: 0.6880 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 192ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 505ms/step - loss: 1.1613 - accuracy: 0.4235 - val_loss: 0.7669 - val_accuracy: 0.7727\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.8603 - accuracy: 0.6706 - val_loss: 0.6545 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.8522 - accuracy: 0.5059 - val_loss: 0.6917 - val_accuracy: 0.6364\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7381 - accuracy: 0.6000 - val_loss: 0.7331 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.7015 - accuracy: 0.6118 - val_loss: 0.6816 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 204ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 499ms/step - loss: 0.9217 - accuracy: 0.5349 - val_loss: 0.7608 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.7910 - accuracy: 0.5814 - val_loss: 0.7011 - val_accuracy: 0.6818\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 482ms/step - loss: 0.6962 - accuracy: 0.6512 - val_loss: 0.6777 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.7438 - accuracy: 0.5814 - val_loss: 0.6691 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 505ms/step - loss: 0.7285 - accuracy: 0.5814 - val_loss: 0.6812 - val_accuracy: 0.5909\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 205ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6275331935709295 +/- 0.02771269149772272\n",
            "Sensitivity: 0.5793561959196634 +/- 0.01595531015240577\n",
            "False Positive Rate: 0.1405228758169935 +/- 0.14101600660386548\n",
            "Specificity: 0.8594771241830065 +/- 0.14101600660386548\n",
            "Precision: 0.6623621306230002 +/- 0.08463595278638435\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.46529233636151873 +/- 0.11629931782656827\n",
            "Sensitivity: 0.5391577548698292 +/- 0.05691355277418913\n",
            "False Positive Rate: 0.597303023773612 +/- 0.35585846473479793\n",
            "Specificity: 0.40269697622638795 +/- 0.355858464734798\n",
            "Precision: 0.5601984126984126 +/- 0.07985876216598779\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 526ms/step - loss: 0.9618 - accuracy: 0.4000 - val_loss: 0.8150 - val_accuracy: 0.6364\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7782 - accuracy: 0.6118 - val_loss: 0.7144 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 474ms/step - loss: 0.7397 - accuracy: 0.6824 - val_loss: 0.6557 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.6820 - accuracy: 0.6706 - val_loss: 0.6422 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 9s 431ms/step - loss: 0.6645 - accuracy: 0.6706 - val_loss: 0.6270 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 5s 198ms/step\n",
            "Working on fold: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 549ms/step - loss: 0.8612 - accuracy: 0.5765 - val_loss: 0.7338 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.8490 - accuracy: 0.4000 - val_loss: 0.6544 - val_accuracy: 0.8636\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.7290 - accuracy: 0.5294 - val_loss: 0.6374 - val_accuracy: 0.8636\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 12s 536ms/step - loss: 0.7392 - accuracy: 0.4588 - val_loss: 0.6246 - val_accuracy: 0.8636\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 457ms/step - loss: 0.7263 - accuracy: 0.5529 - val_loss: 0.5854 - val_accuracy: 0.8182\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 210ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 538ms/step - loss: 1.1375 - accuracy: 0.5116 - val_loss: 0.7151 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 481ms/step - loss: 0.7742 - accuracy: 0.5698 - val_loss: 0.6928 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.7284 - accuracy: 0.5581 - val_loss: 0.6786 - val_accuracy: 0.5909\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7486 - accuracy: 0.6047 - val_loss: 0.6641 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 10s 438ms/step - loss: 0.6950 - accuracy: 0.6279 - val_loss: 0.6444 - val_accuracy: 0.7273\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 187ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6275331935709295 +/- 0.02771269149772272\n",
            "Sensitivity: 0.5793561959196634 +/- 0.01595531015240577\n",
            "False Positive Rate: 0.1405228758169935 +/- 0.14101600660386548\n",
            "Specificity: 0.8594771241830065 +/- 0.14101600660386548\n",
            "Precision: 0.6623621306230002 +/- 0.08463595278638435\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.5588166783135337 +/- 0.03714930675588375\n",
            "Sensitivity: 0.5722104091299137 +/- 0.01808470913867713\n",
            "False Positive Rate: 0.3605724341018459 +/- 0.23156400069554658\n",
            "Specificity: 0.6394275658981542 +/- 0.23156400069554658\n",
            "Precision: 0.6071343328657158 +/- 0.07708371887837626\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.639878872583275 +/- 0.09187244764967799\n",
            "Sensitivity: 0.5383305548940224 +/- 0.027267119784076164\n",
            "False Positive Rate: 0.03795877325289091 +/- 0.03705996907427321\n",
            "Specificity: 0.9620412267471091 +/- 0.03705996907427321\n",
            "Precision: 0.529270806551284 +/- 0.1939256164596628\n",
            "\n",
            "\n",
            "Working on dataset: X_smoothed_median_norm_month\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 507ms/step - loss: 1.1054 - accuracy: 0.4118 - val_loss: 0.7756 - val_accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.8147 - accuracy: 0.6588 - val_loss: 0.7289 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 480ms/step - loss: 0.7587 - accuracy: 0.6824 - val_loss: 0.7134 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.7035 - accuracy: 0.6471 - val_loss: 0.6983 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 501ms/step - loss: 0.6574 - accuracy: 0.7294 - val_loss: 0.7164 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 194ms/step\n",
            "Working on fold: 2\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 496ms/step - loss: 1.0508 - accuracy: 0.4000 - val_loss: 0.6974 - val_accuracy: 0.8182\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 10s 475ms/step - loss: 0.7738 - accuracy: 0.6235 - val_loss: 0.6517 - val_accuracy: 0.7727\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 478ms/step - loss: 0.7483 - accuracy: 0.5765 - val_loss: 0.6435 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.7483 - accuracy: 0.5765 - val_loss: 0.5989 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 520ms/step - loss: 0.6843 - accuracy: 0.6588 - val_loss: 0.5759 - val_accuracy: 0.7727\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 190ms/step\n",
            "Working on fold: 3\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 492ms/step - loss: 0.9319 - accuracy: 0.4884 - val_loss: 0.7280 - val_accuracy: 0.6818\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8278 - accuracy: 0.5465 - val_loss: 0.6767 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 10s 477ms/step - loss: 0.7487 - accuracy: 0.6047 - val_loss: 0.6681 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 10s 473ms/step - loss: 0.6995 - accuracy: 0.6395 - val_loss: 0.6700 - val_accuracy: 0.6364\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 11s 523ms/step - loss: 0.6876 - accuracy: 0.5581 - val_loss: 0.6768 - val_accuracy: 0.6364\n",
            "Predicting test set\n",
            "2/2 [==============================] - 2s 202ms/step\n",
            "Dataset: X_smoothed_mean_norm_month\n",
            "Accuracy: 0.6275331935709295 +/- 0.02771269149772272\n",
            "Sensitivity: 0.5793561959196634 +/- 0.01595531015240577\n",
            "False Positive Rate: 0.1405228758169935 +/- 0.14101600660386548\n",
            "Specificity: 0.8594771241830065 +/- 0.14101600660386548\n",
            "Precision: 0.6623621306230002 +/- 0.08463595278638435\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm_month\n",
            "Accuracy: 0.6460517120894479 +/- 0.024839793972293772\n",
            "Sensitivity: 0.5913458230795693 +/- 0.013646419596990384\n",
            "False Positive Rate: 0.12468577174459528 +/- 0.10479730437939784\n",
            "Specificity: 0.8753142282554047 +/- 0.10479730437939784\n",
            "Precision: 0.6673917997447409 +/- 0.0841010997693549\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_mean_norm\n",
            "Accuracy: 0.5842068483577917 +/- 0.05055974584720714\n",
            "Sensitivity: 0.5042735042735043 +/- 0.0060436477024491024\n",
            "False Positive Rate: 0.10256410256410257 +/- 0.145047544858779\n",
            "Specificity: 0.8974358974358975 +/- 0.145047544858779\n",
            "Precision: 0.3639792215448893 +/- 0.10758282633586011\n",
            "\n",
            "\n",
            "Dataset: X_smoothed_median_norm\n",
            "Accuracy: 0.639878872583275 +/- 0.09187244764967799\n",
            "Sensitivity: 0.5383305548940224 +/- 0.027267119784076164\n",
            "False Positive Rate: 0.03795877325289091 +/- 0.03705996907427321\n",
            "Specificity: 0.9620412267471091 +/- 0.03705996907427321\n",
            "Precision: 0.529270806551284 +/- 0.1939256164596628\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_lstm_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'],create_cnn_lstm_model,False)"
      ],
      "metadata": {
        "id": "ftl5SgVVXONE",
        "outputId": "b2e9d07a-4dec-4b67-9f1d-27c8a4dcb2b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on dataset: X_smoothed_mean_norm\n",
            "Working on fold: 1\n",
            "Fitting model\n",
            "Epoch 1/5\n",
            " 3/22 [===>..........................] - ETA: 4:44 - loss: 1.0460 - accuracy: 0.3333"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_gru_results_ncw = train_and_evaluate(['X_smoothed_mean_norm', 'X_smoothed_mean_norm_month','X_smoothed_median_norm', 'X_smoothed_median_norm_month'],create_cnn_gru_model,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NuboM1_Rmr0Y",
        "outputId": "69280935-9c93-4f1b-a3d3-57e12646c2e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Invalid object type at position 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid object type",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-2e0f1da08482>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_dataset_result_cw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CNN with Class Weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_dataset_result_ncw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CNN without Class Weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_dataset_results_cw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LSTM with Class Weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-2e0f1da08482>\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(results, title, ylabel)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Metric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, seed, units, weights, orient, color, palette, saturation, fill, hue_norm, width, dodge, gap, log_scale, native_scale, formatter, legend, capsize, err_kws, ci, errcolor, errwidth, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2377\u001b[0m     \u001b[0merr_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_err_kws_backcompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2379\u001b[0;31m     p.plot_bars(\n\u001b[0m\u001b[1;32m   2380\u001b[0m         \u001b[0maggregator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mdodge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdodge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mplot_bars\u001b[0;34m(self, aggregator, dodge, gap, width, fill, color, capsize, err_kws, plot_kws)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0merr_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"linewidth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lines.linewidth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m         for sub_vars, sub_data in self.iter_data(iter_vars,\n\u001b[0m\u001b[1;32m   1273\u001b[0m                                                  \u001b[0mfrom_comp_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                                  allow_empty=True):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36miter_data\u001b[0;34m(self, grouping_vars, reverse, from_comp_data, by_facet, allow_empty, dropna)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_comp_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36mcomp_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    998\u001b[0m                         \u001b[0;31m# supporting `order` in categorical plots is tricky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m                         \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_levels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                     \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m                     \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                     \u001b[0mparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             values, _ = lib.maybe_convert_numeric(\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid object type at position 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9UAAAKZCAYAAAC2pwi8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqdklEQVR4nO3de5DV9Xn48WdBWUCyiKjLJVvWREWMchEQwdpoJCKNVMexYdQIMt6jaNymKhFBYuJqq0CnklKNokk1YNJWjToYs40akQkKxRrDRbwEqrBATFhEA8p+f39kPHbDRc6jXPT3es2cmZzP+X7O9zmH/SNvz62iKIoiAAAAgLK12t0DAAAAwCeVqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACApFRUT5s2LWpra6Nt27YxaNCgmDdv3naP//GPfxyHHXZYtG3bNo488sh49NFHU8MCAADAnqTsqJ41a1bU1dXFxIkTY8GCBdGnT58YNmxYrF69eqvHP/PMM3HmmWfGeeedF//93/8dp512Wpx22mnx61//+iMPDwAAALtTRVEURTkbBg0aFAMHDozbbrstIiKam5ujpqYmxo4dG9dcc80Wx48cOTI2bNgQDz/8cGntmGOOib59+8b06dM/4vgAAACw++xVzsGbNm2K+fPnx7hx40prrVq1iqFDh8bcuXO3umfu3LlRV1fXYm3YsGHxwAMPbPM8GzdujI0bN5auNzc3x5tvvhmdO3eOioqKckYGAACAshVFEevXr49u3bpFq1bbfpN3WVG9du3a2Lx5c1RXV7dYr66ujsWLF291z6pVq7Z6/KpVq7Z5nvr6+pg0aVI5owEAAMDHbsWKFfHZz352m7eXFdW7yrhx41q8ur1u3br4i7/4i1ixYkVUVVXtxskAAAD4/0FTU1PU1NTEZz7zme0eV1ZU77///tG6detobGxssd7Y2BhdunTZ6p4uXbqUdXxERGVlZVRWVm6xXlVVJaoBAADYZT7sI8hlfft3mzZton///tHQ0FBaa25ujoaGhhg8ePBW9wwePLjF8RERjz/++DaPBwAAgE+Kst/+XVdXF6NHj44BAwbE0UcfHVOnTo0NGzbEmDFjIiJi1KhR0b1796ivr4+IiCuuuCK++MUvxq233hpf+cpXYubMmfHcc8/F7bff/vE+EgAAANjFyo7qkSNHxpo1a2LChAmxatWq6Nu3b8yePbv0ZWTLly9v8c1oQ4YMifvuuy/Gjx8f3/rWt+KQQw6JBx54II444oiP71EAAADAblD271TvDk1NTdGxY8dYt26dz1QDAACw0+1oh5b1mWoAAADgA6IaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAICkVFRPmzYtamtro23btjFo0KCYN2/eNo+944474rjjjotOnTpFp06dYujQods9HgAAAD4pyo7qWbNmRV1dXUycODEWLFgQffr0iWHDhsXq1au3evwTTzwRZ555ZvziF7+IuXPnRk1NTZx00knx+uuvf+ThAQAAYHeqKIqiKGfDoEGDYuDAgXHbbbdFRERzc3PU1NTE2LFj45prrvnQ/Zs3b45OnTrFbbfdFqNGjdqhczY1NUXHjh1j3bp1UVVVVc64AAAAULYd7dCyXqnetGlTzJ8/P4YOHfrBHbRqFUOHDo25c+fu0H28/fbb8e6778Z+++23zWM2btwYTU1NLS4AAACwpykrqteuXRubN2+O6urqFuvV1dWxatWqHbqPq6++Orp169YizP9cfX19dOzYsXSpqakpZ0wAAADYJXbpt3/fdNNNMXPmzPjP//zPaNu27TaPGzduXKxbt650WbFixS6cEgAAAHbMXuUcvP/++0fr1q2jsbGxxXpjY2N06dJlu3tvueWWuOmmm+LnP/959O7de7vHVlZWRmVlZTmjAQAAwC5X1ivVbdq0if79+0dDQ0Nprbm5ORoaGmLw4MHb3PcP//APccMNN8Ts2bNjwIAB+WkBAABgD1LWK9UREXV1dTF69OgYMGBAHH300TF16tTYsGFDjBkzJiIiRo0aFd27d4/6+vqIiLj55ptjwoQJcd9990VtbW3ps9cdOnSIDh06fIwPBQAAAHatsqN65MiRsWbNmpgwYUKsWrUq+vbtG7Nnzy59edny5cujVasPXgD/l3/5l9i0aVOcccYZLe5n4sSJcf3113+06QEAAGA3Kvt3qncHv1MNAADArrRTfqcaAAAA+ICoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgKRXV06ZNi9ra2mjbtm0MGjQo5s2bt0P7Zs6cGRUVFXHaaadlTgsAAAB7lLKjetasWVFXVxcTJ06MBQsWRJ8+fWLYsGGxevXq7e577bXX4pvf/GYcd9xx6WEBAABgT1J2VE+ePDkuuOCCGDNmTBx++OExffr0aN++fdx1113b3LN58+Y4++yzY9KkSfG5z33uIw0MAAAAe4qyonrTpk0xf/78GDp06Ad30KpVDB06NObOnbvNfd/+9rfjwAMPjPPOOy8/KQAAAOxh9irn4LVr18bmzZujurq6xXp1dXUsXrx4q3uefvrpuPPOO2PhwoU7fJ6NGzfGxo0bS9ebmprKGRMAAAB2iZ367d/r16+Pc845J+64447Yf//9d3hffX19dOzYsXSpqanZiVMCAABATlmvVO+///7RunXraGxsbLHe2NgYXbp02eL4l19+OV577bUYMWJEaa25uflPJ95rr1iyZEl8/vOf32LfuHHjoq6urnS9qalJWAMAALDHKSuq27RpE/3794+GhobSz2I1NzdHQ0NDXHbZZVscf9hhh8ULL7zQYm38+PGxfv36+Kd/+qdthnJlZWVUVlaWMxoAAADscmVFdUREXV1djB49OgYMGBBHH310TJ06NTZs2BBjxoyJiIhRo0ZF9+7do76+Ptq2bRtHHHFEi/377rtvRMQW6wAAAPBJU3ZUjxw5MtasWRMTJkyIVatWRd++fWP27NmlLy9bvnx5tGq1Uz+qDQAAAHuEiqIoit09xIdpamqKjh07xrp166Kqqmp3jwMAAMCn3I52qJeUAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgKRXV06ZNi9ra2mjbtm0MGjQo5s2bt93j//CHP8Sll14aXbt2jcrKyjj00EPj0UcfTQ0MAAAAe4q9yt0wa9asqKuri+nTp8egQYNi6tSpMWzYsFiyZEkceOCBWxy/adOm+PKXvxwHHnhg/OQnP4nu3bvHb3/729h3330/jvkBAABgt6koiqIoZ8OgQYNi4MCBcdttt0VERHNzc9TU1MTYsWPjmmuu2eL46dOnxz/+4z/G4sWLY++9904N2dTUFB07dox169ZFVVVV6j4AAABgR+1oh5b19u9NmzbF/PnzY+jQoR/cQatWMXTo0Jg7d+5W9zz00EMxePDguPTSS6O6ujqOOOKIuPHGG2Pz5s3bPM/GjRujqampxQUAAAD2NGVF9dq1a2Pz5s1RXV3dYr26ujpWrVq11T2vvPJK/OQnP4nNmzfHo48+Gtddd13ceuut8Z3vfGeb56mvr4+OHTuWLjU1NeWMCQAAALvETv/27+bm5jjwwAPj9ttvj/79+8fIkSPj2muvjenTp29zz7hx42LdunWly4oVK3b2mAAAAFC2sr6obP/994/WrVtHY2Nji/XGxsbo0qXLVvd07do19t5772jdunVprVevXrFq1arYtGlTtGnTZos9lZWVUVlZWc5oAAAAsMuV9Up1mzZton///tHQ0FBaa25ujoaGhhg8ePBW9xx77LGxbNmyaG5uLq0tXbo0unbtutWgBgAAgE+Kst/+XVdXF3fccUfcc889sWjRorjkkktiw4YNMWbMmIiIGDVqVIwbN650/CWXXBJvvvlmXHHFFbF06dJ45JFH4sYbb4xLL73043sUAAAAsBuU/TvVI0eOjDVr1sSECRNi1apV0bdv35g9e3bpy8uWL18erVp90Oo1NTXx2GOPxZVXXhm9e/eO7t27xxVXXBFXX331x/coAAAAYDco+3eqdwe/Uw0AAMCutFN+pxoAAAD4gKgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACApFdXTpk2L2traaNu2bQwaNCjmzZu33eOnTp0aPXv2jHbt2kVNTU1ceeWV8cc//jE1MAAAAOwpyo7qWbNmRV1dXUycODEWLFgQffr0iWHDhsXq1au3evx9990X11xzTUycODEWLVoUd955Z8yaNSu+9a1vfeThAQAAYHcqO6onT54cF1xwQYwZMyYOP/zwmD59erRv3z7uuuuurR7/zDPPxLHHHhtnnXVW1NbWxkknnRRnnnnmh766DQAAAHu6sqJ606ZNMX/+/Bg6dOgHd9CqVQwdOjTmzp271T1DhgyJ+fPnlyL6lVdeiUcffTT++q//epvn2bhxYzQ1NbW4AAAAwJ5mr3IOXrt2bWzevDmqq6tbrFdXV8fixYu3uuess86KtWvXxl/+5V9GURTx3nvvxcUXX7zdt3/X19fHpEmTyhkNAAAAdrmd/u3fTzzxRNx4443xve99LxYsWBD/8R//EY888kjccMMN29wzbty4WLduXemyYsWKnT0mAAAAlK2sV6r333//aN26dTQ2NrZYb2xsjC5dumx1z3XXXRfnnHNOnH/++RERceSRR8aGDRviwgsvjGuvvTZatdqy6ysrK6OysrKc0QAAAGCXK+uV6jZt2kT//v2joaGhtNbc3BwNDQ0xePDgre55++23twjn1q1bR0REURTlzgsAAAB7jLJeqY6IqKuri9GjR8eAAQPi6KOPjqlTp8aGDRtizJgxERExatSo6N69e9TX10dExIgRI2Ly5MnRr1+/GDRoUCxbtiyuu+66GDFiRCmuAQAA4JOo7KgeOXJkrFmzJiZMmBCrVq2Kvn37xuzZs0tfXrZ8+fIWr0yPHz8+KioqYvz48fH666/HAQccECNGjIjvfve7H9+jAAAAgN2govgEvAe7qakpOnbsGOvWrYuqqqrdPQ4AAACfcjvaoTv9278BAADg00pUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQJKoBAAAgSVQDAABAkqgGAACAJFENAAAASaIaAAAAkkQ1AAAAJIlqAAAASBLVAAAAkCSqAQAAIElUAwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACBJVAMAAECSqAYAAIAkUQ0AAABJohoAAACSRDUAAAAkiWoAAABIEtUAAACQVHZUP/XUUzFixIjo1q1bVFRUxAMPPPChe5544ok46qijorKyMg4++OC4++67E6MCAADAnqXsqN6wYUP06dMnpk2btkPHv/rqq/GVr3wlTjjhhFi4cGF84xvfiPPPPz8ee+yxsocFAACAPcle5W4YPnx4DB8+fIePnz59ehx00EFx6623RkREr1694umnn44pU6bEsGHDyj09AAAA7DHKjupyzZ07N4YOHdpibdiwYfGNb3xjm3s2btwYGzduLF1ft25dREQ0NTXtlBkBAADg/3q/P4ui2O5xOz2qV61aFdXV1S3Wqquro6mpKd55551o167dFnvq6+tj0qRJW6zX1NTstDkBAADgz61fvz46duy4zdt3elRnjBs3Lurq6krXm5ub480334zOnTtHRUXFbpwMAD5ZmpqaoqamJlasWBFVVVW7exwA+MQoiiLWr18f3bp12+5xOz2qu3TpEo2NjS3WGhsbo6qqaquvUkdEVFZWRmVlZYu1fffdd2eNCACfelVVVaIaAMq0vVeo37fTf6d68ODB0dDQ0GLt8ccfj8GDB+/sUwMAAMBOVXZUv/XWW7Fw4cJYuHBhRPzpJ7MWLlwYy5cvj4g/vXV71KhRpeMvvvjieOWVV+Kqq66KxYsXx/e+9724//7748orr/x4HgEAAADsJmVH9XPPPRf9+vWLfv36RUREXV1d9OvXLyZMmBAREStXriwFdkTEQQcdFI888kg8/vjj0adPn7j11lvj+9//vp/TAoBdoLKyMiZOnLjFx6oAgI9HRfFh3w8OAAAAbNVO/0w1AAAAfFqJagAAAEgS1QAAAJAkqgEgIl577bWoqKgo/brFx6m2tjamTp36sd8vnw47828PgJ1PVAOwTZs3b44hQ4bE6aef3mJ93bp1UVNTE9dee+1umuyjOffcc+O0007b3WPw/yF/ewCfPqIagG1q3bp13H333TF79uy49957S+tjx46N/fbbLyZOnLgbp+PTbvPmzdHc3Ly7xwCA7RLVAGzXoYceGjfddFOMHTs2Vq5cGQ8++GDMnDkzfvCDH0SbNm22u/f3v/99nH322XHAAQdEu3bt4pBDDokZM2ZExAdveb3//vvjuOOOi3bt2sXAgQNj6dKl8eyzz8aAAQOiQ4cOMXz48FizZk3pPpubm+Pb3/52fPazn43Kysro27dvzJ49u8V5X3jhhfjSl74U7dq1i86dO8eFF14Yb731VkREXH/99XHPPffEgw8+GBUVFVFRURFPPPFEae8rr7wSJ5xwQrRv3z769OkTc+fObXHfTz/9dGnempqauPzyy2PDhg2l21evXh0jRoyIdu3axUEHHdTiP0bsiIqKivjXf/3XOOWUU6J9+/bRq1evmDt3bixbtiyOP/742GeffWLIkCHx8ssvt9j34IMPxlFHHRVt27aNz33uczFp0qR47733SrdPnjw5jjzyyNhnn32ipqYmvv71r5eek4iIu+++O/bdd9947LHHolevXtGhQ4c4+eSTY+XKlTs09/uvwN5yyy3RtWvX6Ny5c1x66aXx7rvvlo75/e9/H6NGjYpOnTpF+/btY/jw4fHSSy9tMcNDDz0Uhx9+eFRWVsby5cujtrY2vvOd78SoUaOiQ4cO0aNHj3jooYdizZo1ceqpp0aHDh2id+/e8dxzz+3QrO+f5+GHH46ePXtG+/bt44wzzoi333477rnnnqitrY1OnTrF5ZdfHps3by57/m09hx/1bw+APVQBAB+iubm5OP7444sTTzyxOPDAA4sbbrhhh/ZdeumlRd++fYtnn322ePXVV4vHH3+8eOihh4qiKIpXX321iIjisMMOK2bPnl385je/KY455piif//+xfHHH188/fTTxYIFC4qDDz64uPjii0v3OXny5KKqqqr40Y9+VCxevLi46qqrir333rtYunRpURRF8dZbbxVdu3YtTj/99OKFF14oGhoaioMOOqgYPXp0URRFsX79+uKrX/1qcfLJJxcrV64sVq5cWWzcuLHFPA8//HCxZMmS4owzzih69OhRvPvuu0VRFMWyZcuKffbZp5gyZUqxdOnSYs6cOUW/fv2Kc889tzTf8OHDiz59+hRz584tnnvuuWLIkCFFu3btiilTpuzQcxYRRffu3YtZs2YVS5YsKU477bSitra2+NKXvtTieTr55JNLe5566qmiqqqquPvuu4uXX365+NnPflbU1tYW119/femYKVOmFP/1X/9VvPrqq0VDQ0PRs2fP4pJLLindPmPGjGLvvfcuhg4dWjz77LPF/Pnzi169ehVnnXXWDs09evTooqqqqrj44ouLRYsWFT/96U+L9u3bF7fffnvpmL/5m78pevXqVTz11FPFwoULi2HDhhUHH3xwsWnTphYzDBkypJgzZ06xePHiYsOGDUWPHj2K/fbbr5g+fXqxdOnS4pJLLimqqqqKk08+ubj//vtLz1OvXr2K5ubmD531/fN8+ctfLhYsWFA8+eSTRefOnYuTTjqp+OpXv1q8+OKLxU9/+tOiTZs2xcyZM8uef1vP4Uf52wNgzyWqAdghixYtKiKiOPLII3f4/+iPGDGiGDNmzFZvez8kvv/975fWfvSjHxURUTQ0NJTW6uvri549e5aud+vWrfjud7/b4r4GDhxYfP3rXy+Koihuv/32olOnTsVbb71Vuv2RRx4pWrVqVaxataooij8F4Kmnnvqh87z44otFRBSLFi0qiqIozjvvvOLCCy9sse+Xv/xl0apVq+Kdd94plixZUkREMW/evNLt7z9v5UT1+PHjS9fnzp1bRERx5513tnie2rZtW7p+4oknFjfeeGOL+/nhD39YdO3adZvn+fGPf1x07ty5dH3GjBlFRBTLli0rrU2bNq2orq7eoblHjx5d9OjRo3jvvfdKa3/7t39bjBw5siiKoli6dGkREcWcOXNKt69du7Zo165dcf/997eYYeHChS3uu0ePHsXXvva10vWVK1cWEVFcd911pbX3n6eVK1d+6Kxbe6wXXXRR0b59+2L9+vWltWHDhhUXXXRR2fNv7znM/u0BsOfy9m8Adshdd90V7du3j1dffTX+93//d4f2XHLJJTFz5szo27dvXHXVVfHMM89scUzv3r1L/7u6ujoiIo488sgWa6tXr46IiKampnjjjTfi2GOPbXEfxx57bCxatCgiIhYtWhR9+vSJffbZp8Xtzc3NsWTJkg+d+f/O07Vr14iI0vmff/75uPvuu6NDhw6ly7Bhw6K5uTleffXVWLRoUey1117Rv3//0n0cdthhse+++37oebc1w7aekz/+8Y/R1NRUmuvb3/52i7kuuOCCWLlyZbz99tsREfHzn/88TjzxxOjevXt85jOfiXPOOSd+97vflW6PiGjfvn18/vOfb/H433/sO+ILX/hCtG7deqv7339uBg0aVLq9c+fO0bNnz9K/XUREmzZtWjz+cp6TiNjhef/8sVZXV0dtbW106NChxVq583+U53B7f3sA7LlENQAf6plnnokpU6bEww8/HEcffXScd955URTFh+4bPnx4/Pa3v40rr7wy3njjjTjxxBPjm9/8Zotj9t5779L/rqio2Orarvyyqq3N8/7533rrrbjoooti4cKFpcvzzz8fL730UouQ2hkzfNhckyZNajHXCy+8EC+99FK0bds2XnvttTjllFOid+/e8e///u8xf/78mDZtWkREbNq0aavnff88O/LvvL395f7btWvXrvT4tnXfO/KcZGb9OOb/KM/hR3k8AOw+ohqA7Xr77bfj3HPPjUsuuSROOOGEuPPOO2PevHkxffr0Hdp/wAEHxOjRo+Pf/u3fYurUqXH77benZ6mqqopu3brFnDlzWqzPmTMnDj/88IiI6NWrVzz//PMtvjxszpw50apVq+jZs2dE/OnV0P/7BVQ76qijjorf/OY3cfDBB29xadOmTRx22GHx3nvvxfz580t7lixZEn/4wx8Sj7a8uZYsWbLVuVq1ahXz58+P5ubmuPXWW+OYY46JQw89NN54442dOtOf69WrV7z33nvxq1/9qrT2u9/9LpYsWVL6t9uTfVzzZ//2ANhziWoAtmvcuHFRFEXcdNNNERFRW1sbt9xyS1x11VXx2muvbXfvhAkT4sEHH4xly5bFiy++GA8//HD06tXrI83z93//93HzzTfHrFmzYsmSJXHNNdfEwoUL44orroiIiLPPPjvatm0bo0ePjl//+tfxi1/8IsaOHRvnnHNO6S3CtbW18T//8z+xZMmSWLt2bYtvqN6eq6++Op555pm47LLLYuHChfHSSy/Fgw8+GJdddllERPTs2TNOPvnkuOiii+JXv/pVzJ8/P84///xo167dR3rMH2bChAnxgx/8ICZNmhQvvvhiLFq0KGbOnBnjx4+PiIiDDz443n333fjnf/7neOWVV+KHP/zhDv9HkY/LIYccEqeeempccMEF8fTTT8fzzz8fX/va16J79+5x6qmn7tJZMj6u+bN/ewDsuUQ1ANv05JNPxrRp02LGjBnRvn370vpFF10UQ4YM+dC3gbdp0ybGjRsXvXv3jr/6q7+K1q1bx8yZMz/STJdffnnU1dXF3/3d38WRRx4Zs2fPjoceeigOOeSQiPjTZ1ofe+yxePPNN2PgwIFxxhlnxIknnhi33XZb6T4uuOCC6NmzZwwYMCAOOOCALV753pbevXvHk08+GUuXLo3jjjsu+vXrFxMmTIhu3bqVjpkxY0Z069YtvvjFL8bpp58eF154YRx44IEf6TF/mGHDhsXDDz8cP/vZz2LgwIFxzDHHxJQpU6JHjx4REdGnT5+YPHly3HzzzXHEEUfEvffeG/X19Tt1pq2ZMWNG9O/fP0455ZQYPHhwFEURjz766BZvmd5TfRzzZ//2ANhzVRTlfFgKAAAAKPFKNQAAACSJagDSLr744hY/4/R/LxdffPHuHm+Pc++9927z+frCF76wu8fbrm3N3aFDh/jlL3+5u8drYfjw4duc9cYbb9zd4wHwKePt3wCkrV69uvRbyX+uqqpqp3+W+JNm/fr10djYuNXb9t5779JnoPdEy5Yt2+Zt3bt33+lfxlaO119/Pd55552t3rbffvvFfvvtt4snAuDTTFQDAABAkrd/AwAAQJKoBgAAgCRRDQAAAEmiGgAAAJJENQAAACSJagAAAEgS1QAAAJAkqgEAACDp/wEQjOXSMZRisQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}