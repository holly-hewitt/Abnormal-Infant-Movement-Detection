{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.enable_eager_execution(tf.ConfigProto(log_device_placement=False))\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.enable_eager_execution(tf.ConfigProto(log_device_placement=False))\n",
    "#tf.test.gpu_device_name()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Masking, LSTM, GRU\n",
    "from sklearn.model_selection import KFold\n",
    "# import early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from tensorflow.keras.layers import Input, Concatenate, Permute, Reshape, Multiply, Lambda, Add\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_score(y_true, y_pred):\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred_bin = np.argmax(y_pred, axis=1)\n",
    "    y_true_bin = np.argmax(y_true, axis=1)\n",
    "\n",
    "    tn = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n",
    "    fp = np.sum((y_true_bin == 0) & (y_pred_bin != 0))\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(dataset_names, create_model_fn, class_weights):\n",
    "\n",
    "    outer_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    # Find best dataset to train and test model on\n",
    "    #dataset_names = ['X_smoothed_mean_norm']\n",
    "    dataset_results = {}\n",
    "\n",
    "    for dataset_name in dataset_names:\n",
    "\n",
    "        dataset_results[dataset_name] = {}\n",
    "\n",
    "         # Load in dataset from pickle\n",
    "        with open(f'drive/MyDrive/Pickles/{dataset_name}.pickle', 'rb') as handle:\n",
    "            dataset = pickle.load(handle)\n",
    "\n",
    "        dataset = np.array(dataset)\n",
    "\n",
    "        print(f'Working on dataset: {dataset_name}')\n",
    "\n",
    "        accuracies = []\n",
    "        sensitivities = []\n",
    "        false_positive_rates = []\n",
    "        specificities = []\n",
    "        precisions = []\n",
    "\n",
    "        fold = 1\n",
    "\n",
    "        for train_index, test_index in outer_cv.split(dataset):\n",
    "\n",
    "            # Print current progress\n",
    "            print(f'Working on fold: {fold}')\n",
    "            fold += 1\n",
    "\n",
    "            X_train, X_test = dataset[train_index], dataset[test_index]\n",
    "            Y_train, Y_test = abnormal_encoded[train_index], abnormal_encoded[test_index]\n",
    "\n",
    "            X_train = X_train.astype('float32')\n",
    "            Y_train = Y_train.astype('float32')\n",
    "            X_test = X_test.astype('float32')\n",
    "            Y_test = Y_test.astype('float32')\n",
    "\n",
    "            model = create_model_fn(X_train.shape[1:])\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "            if class_weights:\n",
    "\n",
    "                Y_train_classes = np.argmax(Y_train, axis=1)\n",
    "\n",
    "                # Compute class weights\n",
    "                cw = class_weight.compute_class_weight('balanced',\n",
    "                                                    classes=np.unique(Y_train_classes),\n",
    "                                                    y=Y_train_classes)\n",
    "\n",
    "                class_weights_dict = dict(enumerate(cw))\n",
    "\n",
    "                #Fit the model\n",
    "                print('Fitting model')\n",
    "                model.fit(X_train, Y_train, epochs=5, batch_size=4, validation_split=0.2, callbacks=[early_stopping], verbose=1, class_weight=class_weights_dict)\n",
    "\n",
    "            else:\n",
    "                #Fit the model\n",
    "                print('Fitting model')\n",
    "                model.fit(X_train, Y_train, epochs=5, batch_size=4, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "            # Predict the test set\n",
    "            print('Predicting test set')\n",
    "            Y_pred = model.predict(X_test)\n",
    "\n",
    "            Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "            Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "            # Calulate accuracy, sensitivity, false positive rate, specificity and precision\n",
    "            accuracies.append(accuracy_score(Y_test_classes, Y_pred_classes))\n",
    "            sensitivities.append(recall_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
    "            false_positive_rates.append(1 - specificity_score(Y_test, Y_pred))\n",
    "            specificities.append(specificity_score(Y_test, Y_pred))\n",
    "            precisions.append(precision_score(Y_test_classes, Y_pred_classes, average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        avg_sensitivity = np.mean(sensitivities)\n",
    "        avg_false_positive_rate = np.mean(false_positive_rates)\n",
    "        avg_specificity = np.mean(specificities)\n",
    "        avg_precision = np.mean(precisions)\n",
    "\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_sensitivity = np.std(sensitivities)\n",
    "        std_false_positive_rate = np.std(false_positive_rates)\n",
    "        std_specificity = np.std(specificities)\n",
    "        std_precision = np.std(precisions)\n",
    "\n",
    "        dataset_results[dataset_name]['Accuracy'] = (avg_accuracy, std_accuracy)\n",
    "        dataset_results[dataset_name]['Sensitivity'] = (avg_sensitivity, std_sensitivity)\n",
    "        dataset_results[dataset_name]['False Positive Rate'] = (avg_false_positive_rate, std_false_positive_rate)\n",
    "        dataset_results[dataset_name]['Specificity'] = (avg_specificity, std_specificity)\n",
    "        dataset_results[dataset_name]['Precision'] = (avg_precision, std_precision)\n",
    "\n",
    "        for dataset_name, results in dataset_results.items():\n",
    "            print(f'Dataset: {dataset_name}')\n",
    "            for metric, (avg, std) in results.items():\n",
    "                print(f'{metric}: {avg} +/- {std}')\n",
    "            print('\\n')\n",
    "\n",
    "\n",
    "        # Delete dataset to free up memory\n",
    "        del dataset\n",
    "        del Y_pred\n",
    "    return dataset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model functions\n",
    "\n",
    "def create_cnn_model(shape, filters=32, kernel_size=3, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=shape))  # Adjust the input_shape to match your dataset\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(19301, 16)))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))  # Reduced the number of neurons in the dense layer\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model(shape, lstm_units=32, dropout_rate=0.5, output_classes=3):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=shape))\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))  # 'return_sequences=False' because we only need the last output\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(lstm_units, activation='relu'))\n",
    "    model.add(Dense(output_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_gru_model(shape, gru_units=32, dropout_rate=0.5, output_classes=3):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=shape))\n",
    "    model.add(GRU(gru_units, return_sequences=False))  # return_sequences=False because we only need the last output\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(gru_units, activation='relu'))\n",
    "    model.add(Dense(output_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_lstm_model(shape, filters=32, kernel_size=3, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=shape))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(lstm_units, activation='relu'))\n",
    "    model.add(Dense(output_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_gru_model(shape, filters=32, kernel_size=3, gru_units=64, dropout_rate=0.5, output_classes=3):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=shape))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(GRU(gru_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(gru_units, activation='relu'))\n",
    "    model.add(Dense(output_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_lstm_attention_model(shape, lstm_units=64, dropout_rate=0.5, output_classes=3):\n",
    "    inputs = Input(shape=shape)\n",
    "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "    attention = Dense(1, activation='tanh')(lstm_out)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax')(attention)\n",
    "    attention = RepeatVector(lstm_units)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "    sent_representation = Multiply()([lstm_out, attention])\n",
    "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(lstm_units,))(sent_representation)\n",
    "    dropout = Dropout(dropout_rate)(sent_representation)\n",
    "    dense = Dense(lstm_units, activation='relu')(dropout)\n",
    "    outputs = Dense(output_classes, activation='softmax')(dense)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('drive/MyDrive/Pickles/moreTrials/OneHotEncodedAbnormal.pickle', 'rb') as handle:\n",
    "    abnormal_encoded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataset: moreTrials/Normalised Mean\n",
      "Working on fold: 1\n",
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E3FE4D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E3FE4D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "45/46 [============================>.] - ETA: 0s - loss: 95.9356 - accuracy: 0.5944WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E8A839D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E8A839D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - 4s 68ms/step - loss: 93.8639 - accuracy: 0.5924 - val_loss: 2.0046 - val_accuracy: 0.6170\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 2.7663 - accuracy: 0.5978 - val_loss: 1.3226 - val_accuracy: 0.5957\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 1.8493 - accuracy: 0.6848 - val_loss: 0.7816 - val_accuracy: 0.6596\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 1.1514 - accuracy: 0.7065 - val_loss: 0.7329 - val_accuracy: 0.6809\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 0.8617 - accuracy: 0.7011 - val_loss: 0.6855 - val_accuracy: 0.6596\n",
      "Predicting test set\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E9234EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E9234EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "Working on fold: 2\n",
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E8A83708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E8A83708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - ETA: 0s - loss: 19.0795 - accuracy: 0.4239WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4372678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4372678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - 4s 65ms/step - loss: 19.0795 - accuracy: 0.4239 - val_loss: 1.4526 - val_accuracy: 0.5957\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 2.7562 - accuracy: 0.6685 - val_loss: 0.6546 - val_accuracy: 0.7021\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 0.7501 - accuracy: 0.6576 - val_loss: 0.6797 - val_accuracy: 0.6383\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.8468 - accuracy: 0.6413 - val_loss: 0.7144 - val_accuracy: 0.5532\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6949 - accuracy: 0.6793 - val_loss: 0.7310 - val_accuracy: 0.5532\n",
      "Predicting test set\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E4A4D438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E4A4D438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 0s 38ms/step\n",
      "Working on fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E4A4D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E4A4D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/47 [============================>.] - ETA: 0s - loss: 107.0505 - accuracy: 0.5435WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4498F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4498F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "47/47 [==============================] - 4s 62ms/step - loss: 106.4718 - accuracy: 0.5459 - val_loss: 4.7874 - val_accuracy: 0.4894\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 7.7510 - accuracy: 0.6378 - val_loss: 2.9846 - val_accuracy: 0.4894\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 3s 59ms/step - loss: 4.7892 - accuracy: 0.6541 - val_loss: 0.9991 - val_accuracy: 0.5106\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 2.1532 - accuracy: 0.6324 - val_loss: 1.0237 - val_accuracy: 0.5106\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 3s 58ms/step - loss: 0.9977 - accuracy: 0.6324 - val_loss: 1.0053 - val_accuracy: 0.5106\n",
      "Predicting test set\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E49D8D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E49D8D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "Dataset: moreTrials/Normalised Mean\n",
      "Accuracy: 0.637031484257871 +/- 0.035302332553991095\n",
      "Sensitivity: 0.4493098688750863 +/- 0.08222400458788888\n",
      "False Positive Rate: 0.004761904761904745 +/- 0.006734350297014714\n",
      "Specificity: 0.9952380952380953 +/- 0.006734350297014714\n",
      "Precision: 0.39538143907397333 +/- 0.18118886697284114\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataset: moreTrials/Normalised Median\n",
      "Working on fold: 1\n",
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E76A0E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E76A0E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - ETA: 0s - loss: 18.5417 - accuracy: 0.6033WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E469A8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E469A8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - 4s 62ms/step - loss: 18.5417 - accuracy: 0.6033 - val_loss: 3.2344 - val_accuracy: 0.6170\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 2.8721 - accuracy: 0.6630 - val_loss: 1.0414 - val_accuracy: 0.6170\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.0343 - accuracy: 0.6630 - val_loss: 1.0501 - val_accuracy: 0.6170\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.0231 - accuracy: 0.6630 - val_loss: 1.0023 - val_accuracy: 0.6170\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.9894 - accuracy: 0.6630 - val_loss: 0.9826 - val_accuracy: 0.6170\n",
      "Predicting test set\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E6CA2E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E6CA2E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Working on fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E6D0AF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E6D0AF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - ETA: 0s - loss: 23.4634 - accuracy: 0.5435WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4884EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4884EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - 4s 68ms/step - loss: 23.4634 - accuracy: 0.5435 - val_loss: 22.2093 - val_accuracy: 0.4255\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 8.3971 - accuracy: 0.7120 - val_loss: 10.0268 - val_accuracy: 0.6170\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 3.7594 - accuracy: 0.7391 - val_loss: 5.5369 - val_accuracy: 0.5532\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.6386 - accuracy: 0.7935 - val_loss: 3.7852 - val_accuracy: 0.4681\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.4874 - accuracy: 0.7880 - val_loss: 2.4495 - val_accuracy: 0.5532\n",
      "Predicting test set\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E496D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E496D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "Working on fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E6F41EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E6F41EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/47 [============================>.] - ETA: 0s - loss: 3.1142 - accuracy: 0.4728WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E785BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E785BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "47/47 [==============================] - 4s 65ms/step - loss: 3.1015 - accuracy: 0.4757 - val_loss: 0.7651 - val_accuracy: 0.5106\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 3s 60ms/step - loss: 1.5162 - accuracy: 0.5568 - val_loss: 0.8008 - val_accuracy: 0.5319\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 3s 62ms/step - loss: 0.7273 - accuracy: 0.5568 - val_loss: 0.7507 - val_accuracy: 0.4681\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 3s 62ms/step - loss: 1.5692 - accuracy: 0.5676 - val_loss: 0.7389 - val_accuracy: 0.5106\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 3s 63ms/step - loss: 0.7255 - accuracy: 0.6324 - val_loss: 0.7294 - val_accuracy: 0.5319\n",
      "Predicting test set\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E49534C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E49534C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "Dataset: moreTrials/Normalised Mean\n",
      "Accuracy: 0.637031484257871 +/- 0.035302332553991095\n",
      "Sensitivity: 0.4493098688750863 +/- 0.08222400458788888\n",
      "False Positive Rate: 0.004761904761904745 +/- 0.006734350297014714\n",
      "Specificity: 0.9952380952380953 +/- 0.006734350297014714\n",
      "Precision: 0.39538143907397333 +/- 0.18118886697284114\n",
      "\n",
      "\n",
      "Dataset: moreTrials/Normalised Median\n",
      "Accuracy: 0.608095952023988 +/- 0.006572806661704042\n",
      "Sensitivity: 0.4615261787663285 +/- 0.06150334436635511\n",
      "False Positive Rate: 0.1473227550959767 +/- 0.10525679679093004\n",
      "Specificity: 0.8526772449040232 +/- 0.10525679679093004\n",
      "Precision: 0.39767609408240895 +/- 0.08724174397606169\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['moreTrials/Normalised Mean', 'moreTrials/Normalised Median']\n",
    "\n",
    "cnn_dataset_result_ncw = train_and_evaluate(datasets, create_cnn_model, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataset: moreTrials/Normalised Mean\n",
      "Working on fold: 1\n",
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E47E94C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E47E94C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - ETA: 0s - loss: 93.7274 - accuracy: 0.4185WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4605318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002D3E4605318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/46 [==============================] - 4s 62ms/step - loss: 93.7274 - accuracy: 0.4185 - val_loss: 120.4870 - val_accuracy: 0.4894\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 65.6687 - accuracy: 0.5652 - val_loss: 22.9191 - val_accuracy: 0.5957\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 24.2658 - accuracy: 0.6630 - val_loss: 7.8058 - val_accuracy: 0.5532\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 8.2283 - accuracy: 0.5054 - val_loss: 5.7673 - val_accuracy: 0.5532\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5.2402 - accuracy: 0.4891 - val_loss: 4.9358 - val_accuracy: 0.4043\n",
      "Predicting test set\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E4527A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002D3E4527A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 0s 30ms/step\n",
      "Working on fold: 2\n",
      "Fitting model\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E8A83708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002D3E8A83708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nindices[0] = 2 is not in [0, 2)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_28816]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26660\\2792060888.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_dataset_result_cw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_cnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26660\\1007600421.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(dataset_names, create_model_fn, class_weights)\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[1;31m#Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fitting model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 53\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nindices[0] = 2 is not in [0, 2)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_28816]"
     ]
    }
   ],
   "source": [
    "cnn_dataset_result_cw = train_and_evaluate(datasets, create_cnn_model, True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
